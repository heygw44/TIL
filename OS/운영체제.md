> Operationg System Concepts 책을 읽고 정리한 내용입니다.

# 1장

## 운영체제란 무엇인가?

### 정의 및 역할
- 정의: 컴퓨터 하드웨어와 컴퓨터 사용자 사이의 중재자 역할을 하는 프로그램.
- 핵심목표
  - 사용자 프로그램을 실행하고 문제를 쉽게 해결할 수 있게 한다.
  - 컴퓨터 시스템을 편리하게 사용할 수 있게 한다.
  -  컴퓨터 하드웨어를 효율적으로 사용할 수 있게 한다.

### 운영체제의 범위
- 커널: 컴퓨터에서 항상 실행되는 단 하나의 프로그램(OS의 핵심)
- 시스템 프로그램: 커널과함께 제공되지만 커널의 일부는 아닌것들.
- 미들웨어:응용 개발자에게 추가적인 서비스를 제공하는 소프트웨어 프레임워크 (모바일 OS 등에서 중요).

## 컴퓨터 시스템의 구성

### 인터럽트
- 개념: 하드웨어나 소프트웨어가 CPU에 이벤트를 알리는 메커니즘.
- 작동 원리
  - CPU가 작업을 수행하는 중에 인터럽트 발생
  - CPU는 현재 작업을 중지하고 즉시 인터럽트 서비스 루틴(ISR)의 실행 위치로 이동.
  - 서비스 루틴 완료 후, 중단되었던 작업 재개.
- 유형
  - 하드웨어 인터럽트: 시스템 버스를 통해 신호 전달(키보드 입력, 디스크 완료 등)
  - 소프트웨어 인터럽트(Trap/Exception): 오류나 사용자 요청에 의해 발생.

### 저장 장치 구조
- 폰노이만 구조: 모든 명령어와 데이터는 실행전 메인 메모리(RAM)에 있어야한다.
- 저장장치 계층 구조: 상위로 갈 수록 빠름,비쌈,용량 작음,휘발성
   - 레지스터 (Registers)
   - 캐시 (Cache)
   - 메인 메모리 (Main Memory - RAM): 휘발성. CPU가 직접 접근 가능.
   - 비휘발성 메모리 (NVM/SSD): 메인 메모리보다 느리지만 영구 저장.  - 하드 디스크 드라이브 (HDD)
   - 광학 디스크, 자기 테이프

### 입출력 구조
- 장치 컨트롤러: 각 장치 유형을 담당하는 하드웨어 칩. 로컬 버퍼를 가진다.
- 장치 드라이버: OS 내에서 장치 컨트롤러와 통신하는 소프트웨어.
- DMA
  - 대량의 데이터를 이동할 때 CPU의 개입없이 장치 컨트롤러가 직접 메모리에 데이터를 전송하는 방식.
  - 데이터 블록 전송이 끝났을 때만 CPU에 인터럽트를 건다(CPU 부하 감소).

## 컴퓨터 시스템 아키텍처

### 단일 프로세서 시스템
- 하나의 메인 CPU만 존재.

### 멀티 프로세서 시스템
- 장점: 처리량 증가, 규모의 경제(비용 절감), 신뢰성 향상.
- 종류
  - 대칭형 멀티프로세싱(SMP): 모든 프로세서가 대등하며 메모리를 공유함.(가장 일반적)
  - 멀티코어: 하나의 칩안에 여러개의 계산 코어를 내장. 에너지 효율적이고 빠르다.

### 클러스터 시스템
- 여러개의 독립적인 시스템을 네트워크로 연결.
- 높은 가용성 제공이 주목적이다. 하나가 고장나도 서비스 지속이 가능.

## 운영체제의 작동

### 부트스트랩 프로그램
- 전원 켜질 때 실행. 하드웨어를 초기화하고 OS 커널을 메모리 로드하여 실행한다.

### 멀티프로그래밍 vs 멀티태스킹
- 멀티프로그래밍
  - CPU가 쉴 틈을 주지않는다.(효율성 극대화)
  - 여러 작업을 메모리에 올려두고, 하나가 I/O 대기 상태가되면 즉시 다른 작업으로 전환한다.
- 멀티태스킹
  - CPU가 작업을 아주 짧은 시간 간격으로 교체하며 실행.
  - 사용자가 각 프로그램과 상호작용을 할 수 있게 한다.(응답 시간이 중요)

### 이중 모드 운용
- 사용자 프로그램이 시스템에 해를 끼치는 것을 방지하기 위한 하드웨어 지원.
- 모드 비트 (Mode Bit): 0(커널 모드) / 1(사용자 모드).
- 특권 명령 (Privileged Instruction): 커널 모드에서만 실행 가능한 위험한 명령(I/O 제어, 타이머 변경 등).
- 사용자가 특권 명령을 수행하려면 시스템 호출(System Call)을 통해 OS에 요청해야 함.

### 타이머
특정 프로그램이 CPU를 무한정 점유하는 것을 막기 위해 일정 시간 후 인터럽트를 발생시켜 OS에게 제어권을 넘김.

## 자원 관리
OS는 시스템의 자원 관리자(Resource Manager)이다.

1. 프로세스 관리 (Process Management):
   - 프로세스: 실행 중인 프로그램.
   - 역할: 프로세스 생성/삭제, 일시정지/재개, 동기화, 통신, 교착상태 처리.
2. 메모리 관리 (Memory Management):
   - CPU가 처리하려면 데이터가 메모리에 있어야 함.
   - 역할: 메모리의 어느 부분이 사용 중인지 추적, 할당 및 회수.
3. 파일 시스템 관리 (File-System Management):
   - 물리적 저장소를 논리적 단위(파일)로 추상화.
   - 역할: 파일/디렉터리 생성 및 삭제, 접근 제어, 백업.
4. 대용량 저장소 관리 (Mass-Storage Management):
   - 디스크 스케줄링 (헤드 움직임 최적화), 여유 공간 관리.
5. 캐싱 (Caching):
   - 빠른 저장소에 데이터를 임시 복사하여 성능 향상.
   - 캐시 일관성 (Coherency): 멀티태스킹/멀티프로세서 환경에서 여러 캐시의 데이터가 최신 값으로 일치하도록 관리하는 것이 중요.
6. I/O 시스템 관리:
   - 버퍼링, 캐싱, 스풀링, 장치 드라이버 인터페이스 제공.


## 보안과 보호
- 보호 (Protection): 컴퓨터 시스템 자원에 대한 프로세스나 사용자의 접근을 제어하는 내부 메커니즘. (권한 관리)
- 보안 (Security): 바이러스, 웜, 해킹 등 외부의 공격으로부터 시스템을 방어하는 것.

## 가상화와 분산 시스템

### 가상화 (Virtualization)
- 한 컴퓨터의 하드웨어를 여러 실행 환경으로 추상화하는 기술.
- VMM (Virtual Machine Manager): 호스트 OS 위에서 게스트 OS를 실행하게 해줌 (예: VMware, VirtualBox).

### 분산 시스템 (Distributed Systems)
- 물리적으로 떨어져 있는 컴퓨터들이 네트워크로 연결되어 작업을 처리.
- TCP/IP가 가장 일반적인 프로토콜.


## 오늘의 회고
- 운영체제는 단순한 프로그램 실행기가 아니라, 하드웨어의 복잡성을 숨기고(추상화) 자원을 효율적으로 배분하는 거대한 관리자이다.
- 현대의 OS는 멀티코어, 모바일, 클라우드 가상화 환경까지 커버해야 하므로 그 역할이 방대해졌다.

---

# 3장

## 프로세스 개념

### 정의
- 프로세스: 실행중인 프로그램
- 프로그램 vs 프로세스
  - 프로그램: 디스크에 저장된 파일(실행 파일). 수동적인 존재.
  - 프로세스: 메모리에 적재되어 CPU에 실행되는 상태. 능동적인 존재.

### 메모리 내 프로세스 구조
프로세스는 메모리상에서 다음과 같은 섹션으로 구성된다.
1. 텍스트(Text)섹션: 실행 코드가 저장.
2. 데이터(Data)섹션: 전역 변수, 정적 변수
3. 힙(Heap)섹션: 런타임 중에 동적으로 할당되는 메모리.
4. 스택(Stack)섹션: 함수 호출 시 임시 데이터 저장(함수 매개변수, 복귀 주소, 로컬 변수)

## 프로세스 상태
프로세스는 실행되면서 상태가 변한다.
1. New(생성): 프로세스가 막 생성된 상태.
2. Running(실행): 명령어들이 실행되고있는 상태(CPU 점유).
3. Waiting(대기): 특정 이벤트(I/O완료, 신호 수신)를 기다리는 상태.
4. Ready(준비): CPU를 할당받기를 기다리는 상태(메모리에 올라옴)
5. Terminated(종료): 실행을 마치고 제거된 상태.

## 프로세스 제어블록(PCB)
OS가 각 프로세스를 관리하기 위해 유지하는 정보저장소. TCB라고도 한다.

### PCB에 저장된 정보
- 프로세스 상태 (Process State): new, ready, running 등.
- 프로그램 카운터 (Program Counter): 다음에 실행할 명령어의 주소.
- CPU 레지스터: 누산기, 인덱스 레지스터, 스택 포인터 등 문맥 정보.
- CPU 스케줄링 정보: 우선순위, 스케줄링 큐 포인터.
- 메모리 관리 정보: 베이스/리미트 레지스터 값, 페이지 테이블 등.
- 회계(Accounting) 정보: CPU 사용 시간, 프로세스 번호(PID).
- I/O 상태 정보: 할당된 I/O 장치 목록, 열린 파일 목록.

## 프로세스 스케줄링
CPU 활용률을 최대화하고, 프로세스 간 신속한 전환을 위해 스케줄러가 필요.

### 스케줄링 큐
- 준비 큐: 메모리에 있으면서 CPU 할당을 기다리는 프로세스들 집합(주로 연결 리스트).
- 대기 큐: 특정 I/O 장치나 이벤트를 기다리는 프로세스들 집합.

### 문맥 교환
- 개념: CPU를 다른 프로세스로 넘겨주기 위해, 현재 프로세스의 상태(PCB)를 저장하고, 새 프로세스의 상태를 복원하는 작업.
- 특징
  - 문맥교환이 이루어지는 동안 시스템은 유용한 작업이 불가능하다. 따라서 오버헤드가 발생한다.
  - 하드웨어 지원 정도에 따라 속도 차이가 발생한다.

## 프로세스에 대한 연산

### 프로세스 생성
- 트리 구조: 부모 프로세스가 자식 프로세스를 생성하며 트리를 형성한다.
- PID: 각 프로세스를 식별하는 고유 번호(Linux에서는 `systemd`가 모든 프로세스의 조상.)
- UNIX/Linux 시스템 호출
  - `fork()`: 새로운 프로세스를 생성. 부모의 주소 공간을 그대로 복사한다.(부모는 pid > 0, 자식은 pid = 0 반환.)
  - `exec()`: `fork()`후 메모리 공간을 새로운 프로그램으로 덮어쓴다.
  - `wait()`: 자식 프로세스가 종료될 때까지 부모가 기다린다.

### 프로세스 종료
- 정상 종료: 마지막 문장 실행후 `exit()`시스템 호출.
- 좀비 프로세스: 자식이 종료되었으나, 부모가 아직 `wait()`을 호출하지 않아 프로세스 테이블에 정보가 남아있는 상태.
- 고아 프로세스: 부모가 자식보다 먼저 종료되어 버린 상태.

## 프로세스간 통신 (IPC)
프로세스는 독립적일수도 있지만, 협력적일수도 있다. 협력 프로세스간에는 데이터 공유가 필요하다.

### IPC의 두 가지 기본 모델
- 공유 메모리 (Shared Memory)
  - 방식: 특정 메모리 영역을 두 프로세스가 함께 읽고 씀.
  - 장점: 커널을 거치지 않으므로 속도가 매우 빠름.
  - 단점: 동기화(Synchronization) 문제를 응용 프로그램 수준에서 해결해야 함. (예: 생산자-소비자 문제).
- 메시지 전달 (Message Passing)
  - 방식: OS 커널을 통해 메시지를 주고받음 (`send(), receive()`).
  - 장점: 충돌 회피가 쉽고, 분산 시스템(네트워크)에서 구현이 용이.
  - 단점: 시스템 콜(System Call)을 사용하므로 공유 메모리보다 느림.

### 통신 동기화 (Synchronization)
- Blocking(동기식): 메시지가 수신될 때까지 송신자/수신자가 대기.
- Non-blocking(비동기식): 작업을 요청하고 즉시 다른 작업을 수행.

## 클라이언트-서버 환경에서의 통신
### 소켓
- 통신의 끝점(Endpoint)
- 구성: `IP주소` + `포트 번호`
- 저수준 통신 방식으로, 바이트 스트림만 주고받는다.(데이터 구조화는 응용 프로그램의 책임)

### 파이프
- 두 프로세스간의 통신 통로.
- 익명 파이프: 부모-자식 관계에서만 사용이 가능하다. 단방향 통신. 프로세스 종료시 사라진다.
- 지명 파이프: 부모-자식 관계가 아니더라도 통신이 가능하다. 양방향 가능. 프로세스가 종료되어도 유지된다.

## 오늘의 회고
- 프로그램은 코드 덩어리이고, 프로세스는 살아 움직이는 실행 주체이다.
- OS는 PCB라는 명찰을 통해 수많은 프로세스를 관리하며, CPU를 아주 짧게 번갈아 쓰게 함으로써(Context Switch) 사용자가 동시에 여러 작업이 된다고 느끼게 한다.
- 프로세스 생성의 핵심은 `fork()(복제)와 exec()(덮어쓰기)`의 협력이다.
- 프로세스끼리 대화(IPC)하려면 '메모리를 같이 쓰거나(Shared Memory)', '우체부(OS)를 통해 편지를 주고받아야(Message Passing)' 한다.

---

# 4장

## 스레드의 개념

### 정의
- 스레드: CPU 이용의 기본 단위. '경량 프로세스'라고도 불린다.
- 구성 요소
  - 개별 보유: 스레드 ID, 프로그램 카운터(PC), 레지스터 집합, 스택(Stakc).
  - 공유(같은 프로세스 내): 코드 섹션, 데이터 섹션, 운영체제 자원.

### 프로세스와의 차이점
- 프로세스: 실행의 주체, 자원 소유의 단위(무거움)
- 스레드: 프로세스 내의 실행 흐름(가벼움)
- 전통적인 프로세스는 하나의 제어 스레드만 가진다. 그러나 현대적인 시스템은 하나의 프로세스에 다수의 스레드를 가진다.

## 멀티 스레딩의 동기

왜 멀티스레딩을 사용하는가?
1. 응답성: 프로그램의 일부분(예: 이미지로딩)이 차단되거나 긴 작업을 수행하더라도, 사용자 인터페이스(UI)스레드는 계속 동작하여 사용자와 상호작용이 가능하다.
2. 자원 공유: 프로세스 간 통신(IPC)은 공유 메모리나 메시지 전달 설정이 필요하지만, 스레드는 자동으로 자신이 속한 프로세스의 메모리와 자원을 공유한다.
3. 경제성: 프로세스 생성/문맥 교환보다 스레드 생성/문맥 교환이 자원과 시간을 훨씬 적게 소모한다.
4. 확장성: 다중 처리기 구조에서 스레드들이 각각 다른 프로세서(코어)에서 병렬로 실행될 수 있어 성능이 향상된다.

## 멀티코어 프로그래밍

### 병행성(Concurrency) vs 병렬성(Parallelism)
- 병행성: 여러 작업이 겹쳐서 실행되는 것처럼 보이는 것(싱글코어에서도 시분할을 통해 가능하다). "진행 중인 작업이 여러개".
- 병렬성: 실제로 여러 작업이 동시에 물리적으로 실행되는 것(멀티 코어 필요). "동시에 수행되는 작업이 여러개".

### 프로그래밍 과제
멀티코어 시스템을 효율적으로 사용하기 위해 개발자가 고려해야 할점.

1. 작업 식별: 독립된 작업으로 나눌 수 있는 영역 찾기.
2. 균형: 작업량이 각 코어에 균등하게 배분되도록 한다.
3. 데이터 분리: 데이터 또한 코어별로 처리 가능하게 나눈다.
4. 데이터 의존성: 작업간의 동기화 문제를 해결.
5. 테스트 및 디버깅: 병행 실행 시 경로가 다양해져 디버깅이 어려워진다.

### 암달의 법칙
- 코어를 아무리 늘려도 성능 향상에는 한계가 있다는 법칙.
- 순차적으로 실행되어야 하는 부분이 전체 성능 향상의 병목이된다.

$$
\textit{Speedup} \le \frac{1}{S + \frac{(1-S)}{N}}
$$
- $S$: 순차 실행 비율, $N$: 코어수

## 멀티스레딩 모델
스레드는 사용자 스레드와 커널 스레드로 나뉜다. 이 둘을 어떻게 연결 하느냐에 따라 모델이 구분된다.

- 다대일 모델
  - 여러 사용자 스레드를 하나의 커널 스레드로 연결.
  - 커널 개입 없이 관리되므로 빠르지만, 한 스레드가 블로킹(Blocking)시스템 콜을 하면 **전체 프로세스가 막힌다.**(멀티코어 활용 불가). 현재는 거의 사용x
- 일대일 모델
  - 사용자 스레드 1개당 커널 스레드1개
  - 동시성이 뛰어나고 멀티스레드를 활용 가능하다.
  - 사용자 스레드 생성시 커널 스레드도 생성해야하므로 오버헤드가 존재하지만 현대에는 문제 해결 가능. 대부분의 OS에서 채택해서 사용한다.
- 다대다 도멜
  - 여러 사용자 스레드를 그보다 적거나 같은 수의 커널 스레드에 멀티플렉싱.
  - 구현이 복잡하여 현대 OS에서는 잘 사용되지 않는다.

## 스레드 라이브러리
개발자에게 스레드 생성 및 관리 API를 제공한다.
- POSIX Threads
  - 구현이 아닌 사양(Specification). UNIX계얼의 표준이다.
  - 동작 방식을 정의만 할 뿐, 실제 구현은 OS마다 다를 수 있다.
- Windows Threads: Windows 시스템 전용 커널 수준 라이브러리.
- Java Threads: JVM 위에서 동작한다. 호스트 OS 라이브러리를 매핑하여 사용.

## 암묵적 스레딩
수백, 수천개의 스레드를 개발자가 직접 관리하기는 어렵기 때문에 컴파일러나 런타임 라이브러리에게 스레드 생성과 관리를 맡기는 방식이다.

1. 스레드 풀
   - 미리 일정 수의 스레드를 만들어두고(Pool), 작업이 들어오면 할당했다가 끝나면 반납하는 방식이다.
   - 스레드 생성 오버헤드 감소 및 스레드 수 제한이 가능하다.
2. Fork-Join: 메인 스레드가 자식 스레드를 fork하고 나중에 join하는 모델이다.
3. OpenMP: C/C++ 컴파일러 지시어`(#pragma omp parallel)`를 통해 병렬 처리를 쉽게 지시한다.
4. GCD: Apple 기술. 개발자가 블록(작업)을 큐에 넣으면 OS가 스레드에 배분한다.

## 스레딩의 문제점들

### `fork()와 exec()`
- 멀티 스레드에서 `fork()`를 호출하면?
  - 모든 스레드를 복제할 것인가? 아니면 `fork()`를 호출한 스레드만 복제할 것인가?
- `exec()`를 호출하면 보통 모든 스레드를 포함한 전체 프로세스를 대체한다.

### 신호처리
- 특정 스레드에만 신호를 보낼지, 프로세스 내 모든 스레드에 보낼지 결정해야 한다.(동기식 신호 vs 비동기식 신호)

### 스레드 취소
- 스레드가 끝나기전에 강제로 종료시키는 것(예: 웹브라우저 로딩 중지).
- 비동기식 취소: 즉시 종료. 자원 회수가 안될 가능성 존재.
- 지연된 취소: 스레드가 자신이 종료되어도 안전한지 주기적으로 확인후 종료(더 권장하는 방식)

### 스레드 로컬 저장소(TLS)
- 스레드는 데이터를 공유하지만, 때로는 자신만의 고유한 데이터가 필요할 때 사용(예: 각 스레드의 트랜잭션 ID).
- 스택의 로컬 변수와 다르다(TLS는 함수 호출간에도 유지됨).

## 오늘의 회고
- 스레드는 '가벼운 프로세스'다. 프로세스가 '집'이라면 스레드는 그 안에 사는 '가족'들이다. 방(메모리)과 가전제품(자원)은 공유하지만, 각자의 방(스택)과 할 일(PC)이 따로 있다.
- 과거에는 CPU를 효율적으로 나누어 쓰기 위해(Concurrency) 스레드를 썼지만, 지금은 멀티코어의 성능을 풀로 뽑아내기 위해(Parallelism) 쓴다.
- One-to-One 모델이 현대 OS의 표준이 되었다. 스레드 생성 비용이 들어도 동시성 보장이 더 중요하기 때문.
- 직접 `create thread` 하는 것보다 스레드 풀이나 OpenMP 같은 암묵적 스레딩을 활용하는 추세다.

---

# 5장

## CPU 스케줄링 기본 개념

### 스케줄링의 목적
- 멀티프로그래밍: CPU 이용률을 최대화하기 위해 항상 어떤 프로세스가 실행되도록 하는 것.
- CPU-I/O 버스트 사이클: 프로세스의 실행은 CPU 실행과 I/O 대기의 반복이다.
  - I/O Bound 프로세스: 짧은 CPU 버스트가 빈번하다.
  - CPU Bound 프로세스: 드물지만 긴 CPU 버스트를 가진다.

### CPU 스케줄러
- 단기 스케줄러: 준비 큐에있는 프로세스 중 하나를 선택하여 CPU를 할당하는 역할이다.

### 선점형 vs 비선점형
1. 비선점형: 프로세스가 CPU를 잡으면 종료(`terminate`)되거나 대기상태(`wait`)로 갈 때까지 스스로 CPU를 반납하지 않는다.
2. 선점형: OS가 강제로 프로세스로부터 CPU를 뺏을 수 있다.
   - 문제점: 데이터 경쟁 발생 가능서이 있어 동기화가필요하다.

### 디스패처
- 스케줄러가 선택한 프로세스에게 실제로 CPU 제어권을 넘겨주는 모듈이다.
- 문맥교환(Context Switch) 수행, 사용자 모드로 전환, 적절한 위치로 점프.
- 디스패치 지연(Dispatch Latency): 한 프로세스를 멈추고 다른 프로세스를 시작하는데 걸리는 시간(짧을수록 좋다.)

## 스케줄링 기준
좋은 스케줄링 알고리즘인지를 판단하는 지표이다.
- CPU 이용률 (CPU Utilization): CPU를 가능한 한 바쁘게 유지 (↑ 최대화).
- 처리량 (Throughput): 단위 시간당 완료된 프로세스의 개수 (↑ 최대화).
- 반환 시간 (Turnaround Time): 프로세스 제출부터 완료까지 걸린 총 시간 (↓ 최소화).
- 대기 시간 (Waiting Time): 프로세스가 준비 큐(Ready Queue)에서 대기한 시간의 합 (↓ 최소화). (스케줄링 알고리즘 성능 비교의 핵심 지표).
- 응답 시간 (Response Time): 요청을 제출한 후 첫 번째 응답이 나올 때까지의 시간 (↓ 최소화, 대화형 시스템에서 중요).

## 스케줄링 알고리즘

### 선입 선처리(FCFS)
- 방식: 먼저 온 프로세스가 먼저 CPU를 점유한다. (큐 사용, 비선점형).
- 장점: 단순하고 구현이 쉽다.
- 단점: Convoy Effect 효과 발생. 긴 프로세스 하나 때문에 뒤에 짧은 프로세스들이 하염없이 기다리는 현상. 평균 대기 시간이 길어질 수 있다.

### 최단 작업 우선(SJF)
- 방식: 다음 CPU 버스트 길이(실행 시간)이 가장 짧은 프로세스를 선택한다.
- 특징: 평균 대기 시간을 최소화하는 최적(알고리즘).
- 단점: 다음 CPU 버스트 길이를 미리 알 방법이 없다.
- SRTF(Shortest Remaining Time First): SJF의 선점형 버전. 실행 중 더 짧은 작업이 들어오면 교체된다.

### 라운드 로빈(RR)
- 방식: 시분할 시스템을 위해 설계됨. 각 프로세스에 시간 할당량(Time Quantum)을 주고 돌아가며 실행된다.(선점형)
- 특징: 시간 할당량이 끝나면 인터럽트 발생 → 문맥 교환 → 준비 큐의 맨 뒤로 이동.
- 시간 할당량(q)의 딜레마:
  - `q`가 매우크면 → FCFS와 같아짐.
  - `q`가 매우 작으면 → 문맥 교환 오버헤드가 너무 커짐. (보통 10~100ms 사용).

### 우선순위 스케줄링
- 방식: 우선순위가 높은 프로세스에 CPU 할당. (내부적/외부적 정의 가능)
- 문제점: 기아 상태. 우선순위가 낮은 프로세스는 영원히 실행안될수도있음.
- 해결책: 에이징. 오랫동안 대기한 프로세스의 우선순위를 점진적으로 높인다.

### 다단계 큐
- 준비 큐를 여러 개로 분할(예: 전위 큐, 후위 큐)
- 각 큐는 자체 스케줄링 알고리즘을 가진다.
- 큐 사이에도 스케줄링이 필요하다.(보통 고정 우선순위 방식을 사용).

### 다단계 피드백 큐
- 프로세스가 큐 사이를 이동할 수 있다.
- CPU를 많이 쓰면 낮은 우선순위 큐로 강등, 오래 대기하면 높은 우선순위로 승격된다.
- 가장 일반적이고 복잡한 알고리즘.

## 스레드 스케줄링
최신 OS는 프로세스가 아니라 커널 스레드를 스케줄링 한다.
- 경쟁 범위
  - PCS (Process-Contention Scope): 다대일, 다대다 모델에서 스레드 라이브러리가 사용자 스레드를 LWP(가상 프로세서)에 스케줄링. (같은 프로세스 내 스레드끼리 경쟁).
  - SCS (System-Contention Scope): 커널이 커널 스레드를 실제 CPU 코어에 스케줄링. (시스템 내 모든 스레드가 경쟁). Linux, Windows는 SCS 사용. 

## 멀티 프로세서 스케줄링
여러 개의 CPU가 존재할 때 스케줄링은 더 복잡해진다.
- 대칭형 다중 처리(SMP): 각 프로세서가 스스로 스케줄링함(가장 일반적).
- 부하 균등화(Load Balancing): 모든 프로세서에 작업 부하를 고르게 분산.
  - Push Migration: 과부하된 CPU에서 덜 바쁜 CPU로 작업 이동.
  - Pull Migration: 노는 CPU가 바쁜 CPU의 작업을 가져옴.

## 실시간 CPU 스케줄링
- 연성(Soft)실시간 시스템: 중요한 실시간 프로세스가 우선권을 가지지만, 데드라인을 절대적으로 보장하진 않는다.
- 경성(Hard) 실시간 시스템: 태스크가 반드시 마감시간(DeadLine)내에 완료되어야한다.
- 알고리즘
  - Rate Monotonic (RM): 정적 우선순위. 주기가 짧을수록(자주 실행될수록) 높은 우선순위.
  - Earliest Deadline First (EDF): 동적 우선순위. 마감시간이 가까운 프로세스에게 가장 높은 우선순위 부여.

## 운영체제 사례

### Linux 스케줄링
- CFS (Completely Fair Scheduler):
  - 기존의 우선순위 큐 대신 레드-블랙 트리(Red-Black Tree) 구조 사용.
  - vruntime(가상 런타임)이 가장 작은 작업을 선택하여 실행.
  - 모든 작업이 CPU 시간을 공평하게 나누어 갖도록 설계됨.

### Windows 스케줄링
- 우선순위 기반의 선점형 스케줄링.
- 32단계의 우선순위 레벨을 사용(가변 우선순위 클래스 + 실시간 클래스).
- 포그라운드(현재 활성창)프로세스에게 퀀텀을 더 줌으로써 반응성을 향상.

## 오늘의 회고
- 스케줄링의 핵심은 "누구에게(Selection)", "얼마나(Quantum)" CPU를 줄 것인가의 문제다.
- Trade-off: 모든 프로세스를 만족시키는 완벽한 알고리즘은 없다. 응답성을 높이려면(RR) 문맥 교환 비용이 들고, 처리량을 높이려니(FCFS) 짧은 작업이 기다려야 한다.
- 현실에서는 SJF의 아이디어(짧은 것 우선)와 RR의 아이디어(시분할), 그리고 우선순위(중요도)를 적절히 섞은 다단계 피드백 큐나 CFS 같은 복합적인 알고리즘을 사용한다.
- Starvation(기아) 문제는 Aging(에이징)으로 해결한다는 패턴을 기억할 것.

---

# 6장

## 배경

### 경쟁 상황
- 상황: 여러 프로세스(스레드)가 공유 데이터에 동시에 접근하여 조작할때 발생.
- 문제: 실행순서에따라 결과가 달라지는 현상. 데이터의 일관성이 깨질수 있다.
- 예시: `count++`와 `count--`를 기계어 수준에서 보면 '읽기 -> 수정 -> 저장'의 3단계인데, 이 순서가 두 스레드 간에 뒤섞이면 엉뚱한 값이 저장됨.
- 해결책: 프로세스 동기화. 한번에 하나의 프로세스만 공유 데이터를 건드리도록 해야한다.

## 임계 구역 문제

### 임계 구역
- 코드 중에서 공유자원(변수, 테이블, 파일 등)을 접근/수정하는 부분.
- 이 구역에는 한 번에 하나의 프로세스만 진입해야한다.

### 코드 구조
1. 진입 구역: 입계 구역에 들어갈 수 있는지 확인하고 허가를 요청하는 코드.
2. 임계 구역: 실제 작업을 수행하는 코드.
3. 퇴출 구역: 작업을 마치고 나올 때 허가를 반납하는 코드.
4. 나머지 구역: 공유 자원과 상관없는 나머지 코드.

### 해결 조건 (3가지 필수 조건)
1. 상호 배제: 이미 어떤 프로세스가 임계 구역에서 실행중이라면, 다른 어떤 프로세스도 들어갈 수 없다.
2. 진행: 임계 구역이 비어있고 들어가고 싶어하는 프로세스가 있다면, 그중 누가 들어갈지를 결정해줘야 하며 이 결정은 무한정 미루어지면 안된다.(데드락 방지).
3. 한정 대기: 프로세스가 진입 요청을 한 후 수락될 때까지, 다른 프로세스들이 새치기하여 들어가는 횟수에 한계가 있어야한다.(기아 상태 방지).

---

## 하드웨어적 지원
소프트웨어만으로는 완벽한 동기화 구현이 어렵거나 느리기 때문에 하드웨어가 도와줌.

### 메모리 장벽
- 컴파일러나 CPU는 성능 최적화를 위해 명령어 순서를 재배치할 수 있는데, 이는 멀티프로세서 환경에서 데이터 불일치를 유발한다.
- 메모리 장벽 명령어를 사용하면 그 시점에는 모든 변경 사항이 메모리에 전파되도록 강제하여 순서를 보장한다.

### 하드웨어 명령어
- 원자적(Atomic) 연산: "중단되지 않는" 연산. 명령어가 실행되는 도중에 인터럽트가 걸리거나 문맥 교환이 일어나지 않음.
- test_and_set(): 변수 값을 읽고, `true`로 설정하는 과정을 한 번에 수행.
- compare_and_swap() (CAS): 변수의 현재 값이 예상 값과 같으면 새 값으로 교체. (낙관적 잠금 등에 사용).

### 원자적 변수
- `Integer`, `Boolean`같은 기본 타입에 대해 원자적 갱신을 보장하는 특수 변수들.

## 뮤텍스 락
OS 설계자들이 만든 가장 단순한 동기화 도구.

### 작동 원리
- `acquire()`: 락을 얻음. (락이 사용 중이면 얻을 때까지 대기).
- `release()`: 락을 반납.
- Boolean 변수 `available`을 사용하여 구현.

### 스핀락
- Busy Waiting: 락을 얻을 때까지 루프를 돌면서 계속 확인하는 방식.
- 단점: 기다리는 동안 CPU를 계속 소모함.
- 장점: 문맥 교환(Context Switch)이 일어나지 않음.
- 사용처: 락을 기다리는 시간이 문맥 교환 시간보다 짧을 것으로 예상되는 경우(멀티코어 시스템) 유용함.

## 세마포어
뮤텍스보다 더 정교하고 강력한 동기화 도구. 

### 정의
- 정수 변수 `S`(공유 자원의 개수를 나타낸다.)
- 두 가지 원자적 연산으로만 접근이 가능하다.
  - `wait()`(P연산): `S`를 감소시킨다. `S <= 0`이면 대기. (자원 사용 요청).
  - `signal()` (V 연산): `S`를 증가시킴. 대기 중인 프로세스가 있다면 깨움. (자원 반납).

### 종류
1. 카운팅 세마포어: `S`가 가용한 자원의 개수. 0이되면 자원이 바닥난다.
2. 이진 세마포어: `S`가 0또는 1. 뮤텍스락과 유사하게 동작한다.

### 구현방식
- 스피락 대신, 프로세스를 재우는(Sleep/Block)방식을 사용한다.
- 자원이 없으면 프로세스를 대기큐에 넣고 상태를 `waiting`로 변경한다.
- `signal()`이 호출되면 큐에서 프로레스르 꺼내 준비큐로 보낸다.

## 모니터
세마포어는 강력하지만, 프로그래머가 `wait`과 `signal` 순서를 실수로 바꾸면 심각한 오류가 발생할 수 있다. 이를 보완하기 위한 고수준 언어 구조.

### 특징
- 추상 데이터 타입 (ADT): 공유 데이터와 그 데이터를 조작하는 함수들을 하나의 클래스/모듈로 묶음.
- 자동 상호 배제: 모니터 내부에 정의된 프로시저는 한 번에 하나의 프로세스만 실행할 수 있도록 언어 차원에서 보장함. (Java의 `synchronized` 키워드가 이와 유사).
- 조건 변수 (Condition Variables): 모니터 안에서도 특정 조건을 기다려야 할 때 사용.
  - `x.wait()`: 호출한 프로세스는 일시 중지되고 다른 프로세스가 모니터에 들어오게 함.
  - `x.signal()`: 대기 중인 프로세스 하나를 재개시킴.

## 라이브니스
동기화 도구를 썼을때 발생할 수 있는 진행 관련 문제들.

1. 교착 상태 (Deadlock):
   - 두 개 이상의 프로세스가 서로 상대방이 가진 자원을 기다리며 영원히 멈춰 있는 상태. (무한 대기).
2. 기아 (Starvation):
   - 프로세스가 자원을 얻지 못하고 준비 큐에서 무한정 대기하는 상태. (주로 우선순위 스케줄링에서 발생).
3. 우선순위 역전 (Priority Inversion):
   - 높은 우선순위 프로세스가 낮은 우선순위 프로세스가 잡고 있는 락(Lock) 때문에 실행되지 못하는 현상.
   - 해결책: 우선순위 상속 (Priority Inheritance). 락을 가진 낮은 우선순위 프로세스의 우선순위를 임시로 높여서 빨리 작업을 끝내고 락을 내놓게 만듦.

## 오늘의 회고
- 동기화(Synchronization)는 '순서 정하기'다. 여러 스레드가 공유 데이터를 마구잡이로 건드리면 데이터가 망가지므로(Race Condition), 한 번에 하나씩만 건드리게(Critical Section) 하는 것이 목표다.
- 해결 도구는 발전해왔다:
  - 하드웨어: 기계어 레벨에서 원자성(Atomic) 보장.
  - 뮤텍스: "문 잠그고 나만 쓸래" (단순, 상호배제).
  - 세마포어: "신호등/표 5장" (자원 개수 관리 가능).
  - 모니터: "자동 잠금 객체" (개발자 실수 방지, 고수준).
- 바쁜 대기(Busy waiting) vs 봉쇄(Blocking): 짧게 기다릴 거면 문맥 교환 비용이 없는 스핀락이 낫고, 길게 기다릴 거면 CPU를 양보하고 자는 게 낫다.
- 동기화를 잘못 쓰면 프로그램이 멈추는 데드락(Deadlock)에 걸릴 수 있으니 주의해야 한다.

---

# 7장

## 고전적인 동기화 문제들
동기화 기법을 테스트하고 이해하기 위해 사용되는 대표적인 시나리오 3가지.

### 유한 버퍼 문제
- 상황: 생산자는 데이터를 만들어 버퍼에 채우고, 소비자는 버퍼에서 데이터를 꺼냄. 버퍼의 크기는 고정(n개)되어있다.
- 필요한 동기화 도구
  - Mutex Lock: 버퍼 풀(pool) 자체에 대한 접근을 상호 배제하기 위해 (한 번에 한명만 버퍼 조작).
  - Semaphore `full`: 버퍼에 차 있는 아이템 개수 (초기값 0).
  - Semaphore `empty`: 버퍼의 빈 공간 개수 (초기값 n).
- 로직
  - 생산자: `empty` 감소(P) → Mutex 잠금 → 데이터 넣기 → Mutex 해제 → `full` 증가(V).
  - 소비자: `full` 감소(P) → Mutex 잠금 → 데이터 꺼내기 → Mutex 해제 → `empty` 증가(V).

### Readers-Writers 문제
- 상황: DB나 파일같은 데이터베이스를 여러 프로세스가 공유한다.
  - Reader: 읽기만한다. 여러 Reader가 동시에 읽어도 문제x
  - Wirter: 수정한다. Writer가 작업 중일때는 다른 Reader나 Writer가 접근하면 안된다.(상호 배제)
- 변형
  - 제 1문제(Reader 우선): Writer가 기다리고 있어도, 새로운 Reader는 즉시 읽을 수 있다. (Writer 기아 가능성).
  - 제 2문제(Writer 우선): Writer가 준비되면, 새로운 Reader는 진입 불가. Writer가 빨리 쓰도록 배려한다. (Reader 기아 가능성).
- 해결책: Reader-Writer Lock 사용
  - 읽기 모드 락(공유 모드) vs 쓰기 모드 락(배타 모드)구분.

### 식사하는 철학자들 문제
- 상황: 5명의 철학자가 우너탁에 앉아있고, 젓가락은 철학자 사이에 하나씩 총 5개. 식사를 하려면 양손에 젓가락을 들어야한다.
- 문제점(DeadLock): 모든 철학자가 동시에 왼쪽 젓가락을 집으면, 오른쪽 젓가락을 영원히 기다리는 교착 상태가 발생한다.
- 해결책
  - 최대 4명만 테이블에 앉히기.
  - 양쪽 젓가락이 모두 가용 할때만 집게한다.(모니터 사용).
  - 비대칭 해결법: 홀수 번호 철학자는 왼쪽 먼저, 짝수 번호 철학자는 오른쪽 먼저 집게한다.

## 커널 내부의 동기화
실제 운영체제는 어떻게 동기화를 구현하는가?

### Windows의 동기화
- 단일 프로세서: 인터럽트를 잠시 마스킹하여 전역 자원 접근 보호.
- 멀티 프로세서: 스핀락 사용. 짧은 시간 대기시 효율적이다.
- 디스패처 객체
  - Mutex, Semaphore, Event, Timer 등을 객체로 관리한다.
  - 객체 상태: `Signaled` (사용 가능) vs `Non-signaled`(사용 불가, 대기).

### Linux의 동기화
Linux 커널은 다양한 도구를 제공한다.
- Atomic Integers: 정수형 변수에 대한 원자적 연산 (`atomic_t, atomic_inc()`).
- Spinlocks: 짧은 시간 락을 보유할 때 사용. (단일 프로세서에서는 비활성화됨).
- Semaphores: 긴 시간 락을 보유해야 할 때 사용 (잠자는 락).
- RCU (Read-Copy-Update): (중요)
  - 읽기 작업이 많은 상황에서 최적화된 기법.
  - 데이터를 수정할 때, 기존 데이터를 잠그는 대신 새로운 복사본을 만들어 수정(Copy & Update)하고, 포인터를 새 데이터로 바꿈.
  - Reader는 락 없이 빠르게 읽을 수 있음.

## POSIX 동기화
UNIX/Linux 계열의 표준 API인 Pthreads 라이브러리에서 제공하는 동기화.

1. Mutex Locks:
   - `pthread_mutex_init`, `_lock`, `_unlock`.
   - 가장 기본적인 상호 배제 도구.
2. Semaphores:
   - Named Semaphore: 파일 시스템에 이름이 존재하여, 서로 다른 프로세스끼리 공유 가능 (`sem_open`).
   - Unnamed Semaphore: 공유 메모리 영역에 존재하며, 스레드 간 공유 (`sem_init`).
3. Condition Variables:
   - 모니터 방식처럼 특정 조건을 기다림. (`pthread_cond_wait`, `_signal`). 반드시 Mutex와 함께 사용해야 함.

## Java 동기화
Java는 언어 수준과 API 수준에서 풍부한 동기화를 지원한다.

### 언어수준: 모니터(Monitor)
- `synchronized` 키워드: 메서드나 블록에 선언하면, 해당 객체의 락(Lock)을 획득해야만 진입 가능.
- `wait()` / `notify()`:`synchronized` 블록 내부에서 사용. 스레드를 대기시키거나 깨움.

### API 수준: `java.util.concurrent` 패키지
- ReentrantLock: `synchronized`보다 유연한 락 제어 (타임아웃, 공정성 설정 등).
- Semaphores: 카운팅 세마포어 구현.
- Condition: `wait/notify`보다 명시적인 조건 대기 지원.

## 대안적 접근법

복잡한 락과 세마포어를 직접 다루지 않고 동기화하는 최신 기법들.

1.트랜잭션 메모리 (Transactional Memory):
  - DB 트랜잭션 개념을 메모리에 적용.
  - `atomic { S }` 블록 안의 코드는 원자적으로 실행됨. 충돌 시 롤백 후 재시도. (하드웨어적 지원이나 소프트웨어 라이브러리로 구현).
2. OpenMP:
   - 컴파일러 지시어를 사용. `#pragma omp critical` 한 줄만 쓰면 컴파일러가 알아서 락을 걸어줌.
3. 함수형 프로그래밍 (Functional Programming):
   - Erlang, Scala, Haskell 등.
   - 변수의 불변성 (Immutability): 변수를 한 번 설정하면 바꿀 수 없음.
   - 상태 변경이 없으므로 경쟁 상황(Race Condition) 자체가 발생하지 않음. 동기화가 필요 없는 근본적인 해결책.

## 오늘의 회고
- Bounded-Buffer, Readers-Writers, Dining-Philosophers는 모든 동기화 문제의 원형이다. 내가 마주칠 실무 문제도 결국 이 중 하나의 변형일 확률이 높다.
- Reader-Writer Lock은 "읽기는 다 같이 해도 되잖아?"라는 아이디어에서 출발해 성능을 크게 높인 도구다.
- Linux의 RCU나 Java의 Concurrent Package, 함수형 프로그래밍의 부상은 개발자가 직접 저수준의 락(Mutex)을 관리하는 부담을 줄이고 실수를 방지하는 방향으로 기술이 발전하고 있음을 보여준다.
- 핵심: 동기화 도구는 상황에 맞게 골라 써야 한다. (짧은 대기는 스핀락, 긴 대기는 세마포어, 읽기가 많으면 RCU/RWLock).

---

# 8장

## 개요
다중 프로그래밍 환경에서 프로세스(똔느 스레드)들이 한정된 자원을 놓고 경쟁할 때, 특정 자원을 요청했으나 다른 프로세스가 점유하고 있어 대기 상태에 들어가고, 영원히 그 상태를 벗어나지 못하는 상황을 **교착 상태(Deadlock)** 이라 한다.

## 시스템 모델
시스템은 경쟁하는 프로세스들에게 분배할 유한한 자원으로 구성된다.
- 자원 유형: CPU 주기, 메모리 공간, I/O장치 등.
- 인스턴스: 각 자원 유형 $R_i$는 $W_i$개의 인스턴스를 가질 수 있다.
- 자원 사용 순서
  - 요청: 자원 허용을 기다림(시스템 콜: `open()`, `malloc()`, `wait()`)등.
  - 사용: 자원을 점유하여 작업 수행.
  - 방출: 자원 반납(시스템 콜: `close()`, `free()`, `signal()`)등.

## 교착 상태 특성

### 필요 조건
교착 상태가 발생하려면 다음 4가지 조건이 동시에 성립해야 한다. (하나라도 깨지면 발생x)
1. 상호 배제(Mutal Exclusion)
   - 최소 하나의 자원은 비공유 모드로 점유되어야한다.(한 번에 한 프로세스만 사용 가능)
2. 점유 및 대기(Hold and Wait)
   - 자원을 최소 하나 보유하고 있으면서, 다른 프로세스가 점유중인 추가 자원을 얻기 위해 대기하는 프로세스가 존재해야한다.
3. 비선점(No Preemtion)
   - 자원을 강제로 뺏을 수 없다. 자원은 점유하고 있는 프로세스가 태스크를 마친 후 자발적으로 방출해야한다.
4. 순환대기(Circular Wait)
   - 대기 프로세스의 집합 ${P_0,P_1,...,P_n}$이 있을 때, $P_0​→P_1​→...→P_n​→P_0​$ 꼬리를 무는 대기 형태여야 한다.

### 자원 할당 그래프
- 정점(V): 프로세스 집합(P), 자원 집합(R)
- 간선(E)
  - 요청 간선: $Pi_​→R_j$ (프로세스가 자원 요청)
  - 할당 간선: $R_j→P_i$ (자원이 프로세스에 할당)
- 특징
  - 그래프에 사이클이 없다면 → 교착 상태가 절대 아니다.
  - 사이클이 존재한다면
  - 그래프에 사이클이 없다면 →교착 상태가 절대 아니다.
    - 자원 유형마다 인스턴스가 하나라면 → 교착 상태(필요충분조건).
    - 인스턴스가 여러개라면 → 교착 상태일수도, 아닐수도 있다.

## 교착상태 처리방법
1. 예방 & 회피: 시스템이 교착 상태가 되지 않도록 보장한다.
2. 탐지 & 회복: 교착 상태 허용 후, 발생시 탐지하여 복구한다.
3. 무시: 문제가 발생하지 않는척 무시한다. 대부분의 OS가 이를 채택하고 있다. 이를 타조 알고리즘이라 한다.(타조가 땅에 머리를 처박고 있는것에 비유)

## 교착 상태 예방
교착 상태 발생 4가지 필요 조건중 최소 하나를 성립하지 않게 하여 예방한다.
- 상호배제 부정: 읽기 전용 파일처럼 공유 가능한 자원을 사용(현실적으로 불가)
- 점유 및 대기 부정: 프로세스 실행 전 필요한 모든 자원을 한꺼번에 요청하거나, 자원이 없을 때만 요청 허용(자원 이용률 저하, 기아 상태 발생 가능)
- 비선점 부정: 자원을 가진 상태에서 다른 자원 요청이 거절되면, 가진 자원을 모두 반납하고 다시 요청 (상태 저장이/복원이 쉬운 레지스터/메모리 등에 적용한다.)
- 순환 대기 부정: 모든 자원 유형에 순서(번호)를 매기고, 오름차순으로만 자원을 요청하도록 강제한다.(가장 현실적)

## 교착 상태 회피
예방보다 덜 엄격하며, 미래의 요청 정보를 미리 알고 교착 상태 가능성이 없는 경우에만 자원을 할당한다.

### 안전 상태
- 시스템이 프로세스들이 요청하는 자원을 교착 상태 없이 모두 할당해 줄 수 있는 순서(안전 순서열, Safe Sequence)가 존재하면 안전 상태이다.
- 불안전 상태라고해서 반드시 교착상태는 아니지만, 교착 상태가 될 가능성이 존재한다.

### 은행원 알고리즘
자원 인스턴스가 여러 개일 때 사용하는 대표적인 회피 알고리즘.
- 핵심: 프로세스가 자원을 요청했을 때, 그 요청을 들어주고 난 후의 상태가 안전 상태인지 검사한다. 안전하다면 할당, 아니라면 대기시킨다.
- 필요한 자료구조
  - `Available`: 사용 가능한 자원 수
  - `Max`: 프로세스 별 최대 요구 자원 수
  - `Allocation`: 현재 할당된 자원 수
  - `Need`: 앞으로 더 필요한 자우너 수

## 교착 상태 탐지
예방/회피를 안쓴다면 주기적으로 시스템 상태를 검사하여 교착상태인지 파악해야함.
- 단일 인스턴스: 대기 그래프를 유지하고 사이클 찾기.
- 다중 인스턴스: 은행원 알고리즘과 유사한방식으로, 현재 가용 자원으로 어떤 자원도 끝낼 수 없는지 탐지한다.
- 탐지시점: 자원 요청 실패 시 혹은 일정 주기로 탐지(오버헤드를 고려하자).

## 교착 상태 회복
탐지된 교착상태를 끊어내기 위한 방법.
1. 프로세스 종료
   - 교착 상태 프로세스 모두 중지.(확실하지만 큰 비용)
   - 사이클이 없어질때까지 하나씩 중지.(누구를 먼저 중지할지 결정하는 오버헤드가 크다.)
2. 자원 선점
   - 희생자 선택: 비용을 최소화하는 프로세스로부터 자원을 뺏는다.
   - 롤백: 프로세스를 안전한 상태로 돌리고 재시작.
   - 기아: 동일한 프로세스가 계속 희생자로 선택되면 안된다.

## 오늘의 회고
- Deadlock은 상호 배제, 점유 대기, 비선점, 순환 대기 4조건이 모두 만족될 때 발생한다.
- **예방(Prevention)** 은 조건 중 하나를 원천 차단하는 방식이고, **회피(Avoidance)** 는 은행원 알고리즘 등을 통해 안전 상태(Safe State)를 유지하는 방식이다.
- 대부분의 범용 OS는 비용 문제로 데드락을 방치하며, 필요시 사용자가 프로세스를 강제 종료하는 방식으로 해결한다.