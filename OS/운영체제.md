

# Ch 1. Introduction (소개)

## 1. What Operating Systems Do

### 1.1 One-line Summary (한눈에 요약)
- **Operating System (운영체제, OS)** 는 **Hardware (하드웨어)** 를 **Abstraction (추상화)** 하여 사용하기 쉽게 만들고, 제한된 **Resource (자원)** 를 **Resource Management (자원 관리)** 로 배분해 프로그램 실행을 가능하게 한다.
- 핵심 키워드:
  - **Abstraction (추상화)**: 프로세스/파일/가상메모리 같은 “쓰기 쉬운 모델” 제공
  - **Resource Management (자원 관리)**: CPU/Memory/Storage/I/O 자원을 공정·효율적으로 배분
  - **Protection (보호)** / **Security (보안)**: 안정성과 신뢰 경계를 유지

### 1.2 User View (사용자 관점) vs System View (시스템 관점)
- **User View (사용자 관점)**: 시스템은 “편해야 한다”
  - **Convenience (편의성)**, **Responsiveness (응답성)**
- **System View (시스템 관점)**: 시스템은 “관리되어야 한다”
  - **Efficiency (효율)**, **Fairness (공정성)**, **Throughput (처리량)**, **Utilization (자원 활용률)**

### 1.3 OS Services (운영체제 서비스)
- **Program Execution (프로그램 실행)**: 로딩/실행/종료
- **I/O Operations (입출력 처리)**: 장치 접근 표준화
- **File-System Manipulation (파일 시스템 조작)**: 파일/디렉터리 생성·삭제·읽기·쓰기
- **Communication (통신)**: 프로세스 간 통신(**Interprocess Communication (프로세스 간 통신, IPC)**)
- **Error Detection (오류 탐지)**: 하드웨어/소프트웨어 오류 감지 및 대응
- **Resource Allocation (자원 할당)**: CPU/Memory/Storage/I/O 배분
- **Accounting (회계/사용량 추적)**: 모니터링/튜닝/과금 기반
- **Protection & Security (보호 및 보안)**: 권한/격리/인증 등

---

## 2. Computer-System Organization

### 2.1 Components (구성 요소)
- **CPU (중앙처리장치)**, **Main Memory (주기억장치, 메인 메모리)**, **Device (장치)** 는 **Bus (버스)** 또는 **Interconnect (인터커넥트)** 로 연결된다.
- 각 장치에는 보통 **Device Controller (장치 컨트롤러)** 가 붙고, 컨트롤러는 자체 **Local Buffer (로컬 버퍼)** 를 가진다.

### 2.2 Interrupt (인터럽트) driven control (인터럽트 기반 제어)
- 핵심: **I/O (입출력)** 는 느리다 → CPU가 대기하면 낭비 → 완료 시점에 **Interrupt (인터럽트)** 로 알림.
- 전형 흐름:
  1) OS가 **Device Controller (장치 컨트롤러)** 에 I/O 요청
  2) 장치가 작업 수행
  3) 완료 시 **Interrupt (인터럽트)** 발생
  4) CPU가 **Interrupt Handler (인터럽트 핸들러)** 로 진입
  5) 처리 후 복귀 또는 **Scheduling (스케줄링)** 수행

#### Interrupt Vector (인터럽트 벡터) 감각
- OS는 “인터럽트 번호 → 핸들러 주소” 매핑 테이블(**Interrupt Vector (인터럽트 벡터)**)을 관리한다.
- 실무 감각: 핸들러는 짧게, 무거운 처리는 뒤로 미루는 설계가 자주 등장한다.

### 2.3 Storage Hierarchy (저장장치 계층)
- **Storage (저장장치)** 는 속도/가격/용량 트레이드오프가 있고, 시스템은 계층 구조로 구성된다.

| Layer (계층) | Property (특징) | Example (예시) |
|---|---|---|
| Fastest (가장 빠름) | Small/Expensive/Volatile (작음/비쌈/휘발성) | **Register (레지스터)**, **Cache (캐시)** |
| Middle (중간) | Volatile (휘발성) | **Main Memory (메인 메모리, RAM)** |
| Slower (느림) | Non-volatile (비휘발성) | **SSD (SSD)**, **HDD (HDD)** |
| Slowest (가장 느림) | Archive/Backup (보관/백업) | 백업 매체 등 |

### 2.4 Caching (캐싱)
- **Caching (캐싱)**: 느린 계층의 데이터를 빠른 계층에 복사해 두는 것.
- 핵심 이슈:
  - **Consistency (일관성)**: 원본과 캐시가 달라질 수 있음
  - **Replacement Policy (교체 정책)**: 무엇을 버릴지 결정

### 2.5 DMA (Direct Memory Access) (직접 메모리 접근, DMA)
- CPU가 작은 전송을 직접 처리하는 방식은 대량 I/O에서 비효율적이다.
- **Direct Memory Access (직접 메모리 접근, DMA)**:
  - 장치가 메모리로 블록 전송을 수행
  - CPU는 “설정 + 완료 인터럽트 처리” 중심
- 결론: 대량 I/O 시스템에서 DMA는 CPU 효율을 크게 좌우한다.

---

## 3. Computer-System Architecture

### 3.1 Single-Processor System (단일 프로세서 시스템)
- 하나의 **General-Purpose CPU (범용 CPU)** 가 대부분의 작업을 처리한다.

### 3.2 Multiprocessor / Multicore System (다중 프로세서 / 멀티코어 시스템)
- 여러 CPU/코어가 **Shared Memory (공유 메모리)** 를 기반으로 동작하는 구성이 일반적이다.
- 장점:
  - **Parallelism (병렬성)** 으로 **Throughput (처리량)** 증가
  - 일부 고장에도 지속 가능한 **Reliability (신뢰성)** 향상
- 대표 모델:
  - **Symmetric Multiprocessing (대칭형 다중 처리) (SMP)**: CPU들이 동등한 역할

### 3.3 Clustered System (클러스터 시스템)
- 네트워크로 연결된 여러 노드가 하나의 서비스처럼 동작.
- 목적:
  - **High Availability (고가용성, HA)**: 장애 시 서비스 지속
  - **Scalability (확장성)**: 노드 추가로 처리량 증가

---

## 4. Operating-System Operations

### 4.1 Dual-Mode Operation (듀얼 모드 동작)
- **User Mode (사용자 모드)**: 일반 애플리케이션 실행
- **Kernel Mode (커널 모드)**: OS 핵심 기능 실행(권한 높음)
- **Privileged Instruction (특권 명령)** 은 **Kernel Mode (커널 모드)** 에서만 가능.

### 4.2 System Call (시스템 콜)
- 애플리케이션은 커널 기능을 직접 수행할 수 없고 **System Call (시스템 콜)** 로 요청한다.
- 전형 흐름:
  1) **API (응용 프로그래밍 인터페이스)** 호출
  2) 내부에서 **System Call (시스템 콜)** 발생(커널 진입)
  3) 커널 처리 후 결과 반환

#### API (응용 프로그래밍 인터페이스) vs System Call (시스템 콜)
- **API (응용 프로그래밍 인터페이스)**: 개발자가 쓰는 라이브러리 레벨 계약
- **System Call (시스템 콜)**: 커널이 제공하는 권한 있는 기능 단위

### 4.3 Timer (타이머)
- OS가 CPU를 회수하지 못하면 특정 프로세스가 독점할 수 있다.
- **Timer Interrupt (타이머 인터럽트)** 는 **Preemption (선점)** 의 기반이 된다.

### 4.4 Error Detection (오류 탐지)
- OS는 하드웨어/소프트웨어 오류를 감지하고 복구 또는 종료 정책을 적용한다.

---

## 5. Resource Management

### 5.1 Process Management (프로세스 관리)
- **Process (프로세스)** 생성/종료/중단/재개
- **IPC (Interprocess Communication) (프로세스 간 통신)** 제공
- **Synchronization (동기화)** 및 이후 챕터의 **Deadlock (교착상태)** 처리로 확장

### 5.2 Memory Management (메모리 관리)
- 어떤 프로세스가 메모리를 얼마나 쓰는지, 어떻게 보호할지 관리
- 이후 **Virtual Memory (가상 메모리)**로 확장됨

### 5.3 Storage / File Management (저장장치 / 파일 관리)
- **File (파일)** 과 **Directory (디렉터리)** 추상화 제공
- 공간 할당/회수 + 성능을 위한 **Caching (캐싱)**

### 5.4 I/O Subsystem (입출력 서브시스템)
- 장치 다양성을 **Device Driver (장치 드라이버)** 로 흡수
- **Buffering (버퍼링)**, **Caching (캐싱)**, **Spooling (스풀링)** 로 성능/사용성 개선

---

## 6. Security and Protection

### 6.1 Protection (보호) vs Security (보안)
- **Protection (보호)**: 정상 프로그램/사용자 사이의 잘못된 간섭 방지(내부 규율)
- **Security (보안)**: 공격자/악성 행위까지 고려한 방어(외부 위협 포함)

### 6.2 Least Privilege (최소 권한)
- 필요한 권한만 부여하고 나머지는 제한하는 원칙.
- **Dual-Mode Operation (듀얼 모드 동작)** 과 권한 제어 모델로 이어진다.

---

## 7. Virtualization (가상화)
- 물리 자원을 논리 자원처럼 분할/격리해 제공.
- OS가 하던 **Abstraction (추상화)** + **Scheduling (스케줄링)** + **Isolation (격리)** 개념이 확장된 형태.

---

## 8. Distributed Systems (분산 시스템)
- 네트워크로 연결된 컴퓨터들이 협력해 서비스를 제공.
- 특징: **Partial Failure (부분 장애)** 가능성, 통신 지연/손실, 일관성 이슈.

---

## 9. Kernel Data Structures (커널 자료구조)
- OS는 상태를 관리하는 프로그램 → 자료구조가 정책/성능과 직결.
- 예:
  - **Queue (큐)**: Ready Queue (준비 큐), I/O Wait Queue (입출력 대기 큐)
  - **Hash Table (해시 테이블)**: 빠른 탐색
  - **Bitmap (비트맵)**: 자원 할당 상태 추적

---

## 10. Computing Environments (컴퓨팅 환경)
- **Traditional (전통적 환경)**, **Mobile (모바일)**, **Client-Server (클라이언트-서버)**, **Peer-to-Peer (P2P)**, **Cloud (클라우드)**, **Real-Time Embedded (실시간 임베디드)** 등 환경에 따라 OS의 설계 포인트가 달라진다.

---

## 11. Open-Source Operating Systems (오픈소스 운영체제)
- 개념을 구현과 연결할 수 있어 학습에 유리.
- 대표적으로 **Linux (리눅스)** 는 관측 도구와 자료가 풍부해 “개념 → 실험” 연결에 좋다.

---

# Ch 3. Process Concept (프로세스 개념)

> 큰 흐름: **Process (프로세스)** 를 “실행 단위”로 정의하고, OS가 이를 어떻게 **Scheduling (스케줄링)**·**Creation/Termination (생성/종료)**·**IPC (프로세스 간 통신)** 관점에서 다루는지 정리한다.

## 1. Process (프로세스)란?
- **Program (프로그램)**: 저장장치에 존재하는 정적인 **Executable File (실행 파일)** 및 명령어 집합
- **Process (프로세스)**: 메모리에 적재되어 **Execution (실행)** 중인 프로그램 인스턴스
- 하나의 **Program (프로그램)** 이 여러 **Process (프로세스)** 로 실행될 수 있음  
  - 예: 같은 브라우저를 두 번 실행 → 서로 다른 프로세스(주소 공간/상태가 분리)

### 1.1 Process (프로세스)의 구성(메모리 관점)
- 전형적으로 프로세스는 다음을 포함(개념적 구분):
  - **Text Section (코드 영역)**: 실행 코드
  - **Data Section (데이터 영역)**: 전역/정적 변수
  - **Heap (힙)**: 동적 할당 영역
  - **Stack (스택)**: 함수 호출 프레임/지역 변수/리턴 주소 등
- 핵심: **Process (프로세스)** 는 “코드만”이 아니라, 실행에 필요한 **State (상태)** 전체를 가진다.

---

## 2. Process State (프로세스 상태)
OS는 프로세스를 상태 기계처럼 다룬다.

| State (상태) | Meaning (의미) |
|---|---|
| New (생성) | 프로세스 생성 중 |
| Ready (준비) | CPU 할당만 기다리는 상태 |
| Running (실행) | CPU에서 명령 실행 중 |
| Waiting / Blocked (대기/블록) | I/O, 이벤트, 자원 등을 기다리는 상태 |
| Terminated (종료) | 실행 종료 |

### 2.1 State Transition (상태 전이)에서 자주 등장하는 이벤트
- **Dispatch (디스패치)**: Ready (준비) → Running (실행) (스케줄러가 CPU 배정)
- **Preemption (선점)**: Running (실행) → Ready (준비) (타이머/우선순위 등으로 CPU 회수)
- **I/O Request (I/O 요청)**: Running (실행) → Waiting (대기)
- **I/O Completion (I/O 완료)**: Waiting (대기) → Ready (준비)
- **Exit (종료)**: Running (실행) → Terminated (종료)

---

## 3. PCB (Process Control Block) (프로세스 제어 블록)
**Operating System (운영체제)** 는 각 **Process (프로세스)** 를 **PCB (Process Control Block) (프로세스 제어 블록)** 로 관리한다.

### 3.1 PCB (프로세스 제어 블록)에 담기는 대표 정보
- **Process State (프로세스 상태)**: Ready/Running 등
- **Program Counter (프로그램 카운터)**: 다음 실행할 명령 주소
- **CPU Registers (CPU 레지스터)**: 실행 문맥의 핵심
- **CPU Scheduling Information (CPU 스케줄링 정보)**: 우선순위, 큐 포인터 등
- **Memory-Management Information (메모리 관리 정보)**: 페이지/세그먼트 테이블 관련
- **Accounting Information (회계/사용량 정보)**: CPU 사용 시간, UID 등
- **I/O Status Information (I/O 상태 정보)**: 열린 파일, 할당 장치 등

> 요점: OS는 프로세스 실행을 “이어가기” 위해 필요한 최소 상태를 PCB에 보관한다.

---

## 4. Context Switch (문맥 교환)
**Context Switch (문맥 교환)** 은 CPU가 한 프로세스에서 다른 프로세스로 전환되는 과정이다.

### 4.1 왜 발생하는가
- **Interrupt (인터럽트)**: 타이머, I/O 완료 등
- **System Call (시스템 콜)**: I/O 요청, 자원 요청
- **Preemption (선점)**: 더 높은 우선순위 작업 등장 등

### 4.2 비용(오버헤드) 감각
- 문맥 교환은 “일을 하는 시간”이 아니라 “바꾸는 시간”이다.
- 저장/복원해야 하는 상태(레지스터, 캐시/메모리 계층 영향 등)가 많아질수록 비용이 증가한다.
- 따라서 OS 설계는 **Responsiveness (응답성)** 과 **Overhead (오버헤드)** 사이의 균형을 가진다.

---

## 5. Process Scheduling (프로세스 스케줄링) 개요
**Multiprogramming (다중 프로그래밍)** 의 목표는 CPU가 놀지 않게 하는 것이다.  
OS는 여러 프로세스를 **Ready Queue (준비 큐)** 에 두고 CPU를 번갈아 할당한다.

### 5.1 Scheduling Queues (스케줄링 큐)
- **Job Queue (잡 큐)**: 시스템에 존재하는 전체 프로세스 집합(개념적으로)
- **Ready Queue (준비 큐)**: 메모리에 있고 CPU 할당을 기다리는 프로세스
- **Device Queue (장치 큐)**: 특정 I/O 장치 완료를 기다리는 프로세스

### 5.2 Scheduler (스케줄러) 역할 구분(감각)
- **Short-term Scheduler (단기 스케줄러) / CPU Scheduler (CPU 스케줄러)**  
  - Ready Queue에서 다음에 실행할 프로세스를 선택(매우 빈번)
- **Long-term Scheduler (장기 스케줄러) / Job Scheduler (잡 스케줄러)**  
  - 시스템에 “얼마나 많은” 프로세스를 들일지 조절(덜 빈번)
- **Medium-term Scheduler (중기 스케줄러)**  
  - **Swapping (스와핑)** 등으로 메모리 압박을 조절(일부 시스템에서)

### 5.3 Degree of Multiprogramming (다중 프로그래밍 정도)
- 메모리에 동시에 올라와 경쟁하는 프로세스 수(대략적 개념)
- 너무 많으면 문맥 교환/메모리 압박 증가, 너무 적으면 CPU 유휴 증가 가능

---

## 6. Operations on Processes (프로세스에 대한 연산)
OS는 **Process (프로세스)** 에 대해 생성/종료/대기/통지 같은 연산을 제공한다.

### 6.1 Process Creation (프로세스 생성)
- 생성 시 대표적으로 수행되는 일(개념):
  - 새로운 PID 부여 및 PCB 생성
  - 주소 공간 준비(코드/데이터/스택 등)
  - 초기 상태 설정(레지스터, 프로그램 카운터 등)
  - Ready Queue에 등록

#### Parent Process (부모 프로세스)와 Child Process (자식 프로세스)
- 생성 관계가 트리를 이룰 수 있음(**Process Tree (프로세스 트리)**)
- 자식 생성 시 자원의 처리 방식은 OS/정책에 따라 다를 수 있음:
  - 자식이 부모 자원을 일부 상속(예: 열린 파일 등)
  - 부모-자식이 병행 실행 가능

#### Address Space (주소 공간) 관점의 두 가지 패턴
- **Copy of Parent (부모의 복사본)** 형태로 시작 후, 다른 프로그램을 적재
- **New Program (새 프로그램)** 을 바로 적재해 실행

> 핵심: “프로세스 생성”과 “새 프로그램 실행”은 개념적으로 분리될 수 있다.

### 6.2 Process Termination (프로세스 종료)
- 프로세스는 정상 종료 또는 비정상 종료 가능
- 종료 시 OS는:
  - 자원 회수(메모리, 열린 파일, 락 등)
  - 종료 상태를 부모에게 전달할 수 있음(**Exit Status (종료 상태)**)

#### Zombie Process (좀비 프로세스) / Orphan Process (고아 프로세스) 감각
- **Zombie Process (좀비 프로세스)**: 실행은 끝났지만, 부모가 종료 상태를 회수하지 않아 PCB 일부가 남아 있는 상태(개념)
- **Orphan Process (고아 프로세스)**: 부모가 먼저 종료되어 부모가 없는 자식(시스템이 다른 프로세스가 관리/수거하도록 정책 적용)

---

## 7. IPC (Interprocess Communication) (프로세스 간 통신)
프로세스는 단독으로만 동작하지 않고 상호작용한다. 이를 위한 메커니즘이 **IPC (Interprocess Communication) (프로세스 간 통신)** 이다.

### 7.1 Why IPC? (왜 필요한가)
- **Information Sharing (정보 공유)**: 데이터 교환
- **Computation Speedup (계산 가속)**: 병렬 처리
- **Modularity (모듈성)**: 기능 분리(서비스/클라이언트)
- **Convenience (편의성)**: 협업적 프로그램 구성

### 7.2 IPC의 두 큰 모델
- **Shared Memory (공유 메모리)** 모델
- **Message Passing (메시지 패싱)** 모델

---

## 8. Shared Memory (공유 메모리) 모델
### 8.1 핵심 아이디어
- 서로 다른 프로세스가 접근 가능한 메모리 영역을 만들어 **읽기/쓰기**로 통신한다.
- 성능은 좋을 수 있으나, 올바르게 쓰려면 동기화가 중요하다.

### 8.2 Producer–Consumer (생산자-소비자) 패턴(대표 예)
- **Producer (생산자)**: 데이터를 만들어 버퍼에 넣음
- **Consumer (소비자)**: 버퍼에서 데이터를 꺼내 처리
- 버퍼 형태:
  - **Unbounded Buffer (무한 버퍼)**: 현실적 제약은 있으나 개념적으로 생산자가 대기하지 않음
  - **Bounded Buffer (유한 버퍼)**: 버퍼가 차면 생산자 대기, 비면 소비자 대기

#### 동기화 포인트(감각)
- “동시에 접근”하면 데이터가 깨질 수 있다 → **Synchronization (동기화)** 가 필수

---

## 9. Message Passing (메시지 패싱) 모델
### 9.1 핵심 아이디어
- 프로세스가 OS가 제공하는 통신 채널을 통해 **send (전송)** / **receive (수신)** 연산으로 메시지를 주고받는다.
- 공유 메모리보다 구현/격리가 단순한 경우가 많고, 분산 환경에 자연스럽게 확장된다.

### 9.2 Design Dimensions (설계 차원)
- **Direct Communication (직접 통신)** vs **Indirect Communication (간접 통신, Mailbox/Port (메일박스/포트))**
  - Direct: 프로세스가 상대를 명시
  - Indirect: 중간 객체(메일박스)를 통해 연결
- **Blocking (블로킹)** vs **Nonblocking (논블로킹)**
  - Blocking send/receive는 동기화가 단순하지만 대기 비용이 생길 수 있음
- **Buffering (버퍼링)**: 통신 큐가 얼마나 메시지를 저장할지
  - Zero capacity (0 용량): 보내는 쪽과 받는 쪽이 만나야 전달(강한 동기)
  - Bounded capacity (유한 용량): 큐가 가득 차면 send가 대기할 수 있음
  - Unbounded capacity (무한 용량): 개념적으로 send가 대기하지 않음(현실적 제약은 별도)

---

## 10. IPC Examples (IPC 예시)
### 10.1 POSIX Shared Memory (POSIX 공유 메모리) 감각
- POSIX 계열에서 공유 메모리를 만들고 매핑해 프로세스 간 공유하는 형태
- 실제 구현은 API/시스템 콜 세부로 내려가지만, 개념은:
  - 공유 영역 생성 → 프로세스가 매핑 → 읽기/쓰기 → 동기화

### 10.2 Pipes (파이프)
- **Pipe (파이프)**: 한 프로세스의 출력이 다른 프로세스의 입력으로 흐르도록 하는 IPC
- 종류(개념):
  - **Ordinary Pipe (일반 파이프)**: 보통 부모-자식 관계 등 제한된 범위에서 사용되는 단방향 흐름
  - **Named Pipe (이름 있는 파이프, FIFO)**: 이름을 통해 더 일반적인 프로세스 간 연결이 가능
- 특성 감각:
  - 스트림 기반(레코드 경계가 약함), 버퍼 용량/블로킹 특성이 동작에 영향

---

## 11. Communication in Client–Server Systems (클라이언트-서버 통신)
분산/네트워크 환경에서는 IPC가 “프로세스 내부”를 넘어 “네트워크 너머”로 확장된다.

### 11.1 Sockets (소켓)
- **Socket (소켓)** 은 통신의 끝점(endpoint) 추상화
- 일반적으로:
  - 서버는 특정 주소/포트에 바인딩하여 대기
  - 클라이언트가 연결 후 데이터 송수신
- 핵심 감각:
  - “프로세스 간 통신”을 “네트워크 통신”으로 확장한 대표 인터페이스

### 11.2 RPC (Remote Procedure Call) (원격 프로시저 호출)
- 네트워크 너머의 함수를 “로컬 호출처럼” 보이게 하는 추상화
- 구성 감각:
  - Client Stub (클라이언트 스텁) / Server Stub (서버 스텁)이 인자 마샬링/언마샬링 수행
  - 네트워크 전송/응답을 숨기되, 실제로는 지연/실패 가능성이 존재
- 요점: 편의성은 크지만, 분산 특성(지연, 부분 장애, 타임아웃)을 고려해야 한다.

---

## 12. Thread (스레드)와의 연결(챕터 연결고리)
- **Thread (스레드)** 는 프로세스 내부의 실행 단위로, 이후 챕터에서 병행성의 핵심으로 다뤄진다.
- Ch 3에서의 연결 감각:
  - 프로세스는 “자원 컨테이너 + 실행 상태”의 단위
  - 스레드는 그 안에서 CPU 실행 흐름을 여러 개로 확장하는 방향
  - IPC/공유 메모리/동기화 문제는 스레드 모델에서도 더 빈번하게 등장한다.

---

# Ch 4. Threads & Concurrency (스레드와 동시성)

> 큰 흐름: **Thread (스레드)** 는 **Process (프로세스)** 내부의 실행 단위이며, **Concurrency (동시성)** 와 **Parallelism (병렬성)** 을 이해하는 출발점이다. 이 장은 “스레드를 왜 쓰는가(동기) → 어떻게 구현되는가(모델) → 어떤 위험이 생기는가(동시성 이슈)” 순으로 정리한다.

---

## 1. Overview (개요)
- **Thread (스레드)** 는 프로세스 내에서 CPU 실행 흐름을 나타내는 단위다.
- 하나의 **Process (프로세스)** 는 하나 이상의 **Thread (스레드)** 를 가질 수 있다.
- 핵심 효과:
  - 응답성 향상(**Responsiveness (응답성)**)
  - 자원 공유로 인한 효율(**Resource Sharing (자원 공유)**)
  - 멀티코어 활용(**Parallelism (병렬성)**)

---

## 2. Motivation (동기)

### 2.1 Why Threads? (왜 스레드인가)
- **Responsiveness (응답성)**:
  - 한 작업이 I/O로 막혀도 다른 작업을 진행 가능
  - 예: UI가 멈추지 않게 백그라운드 작업 분리
- **Resource Sharing (자원 공유)**:
  - 같은 프로세스 주소 공간을 공유 → 통신 비용이 낮음
- **Economy (경제성)**:
  - 프로세스 생성/문맥 교환보다 스레드가 보통 더 가벼움
- **Scalability (확장성)**:
  - 멀티코어에서 스레드 병렬 실행으로 처리량 증가

### 2.2 Single-Threaded Process (단일 스레드 프로세스) vs Multithreaded Process (다중 스레드 프로세스)
- **Single-Threaded Process (단일 스레드 프로세스)**:
  - 실행 흐름 1개 → 간단하지만 I/O 대기/병렬성 활용에 한계
- **Multithreaded Process (다중 스레드 프로세스)**:
  - 실행 흐름 여러 개 → 복잡하지만 응답성/병렬성/구조적 이점

---

## 3. Thread (스레드)의 기본 모델

### 3.1 What is shared? What is private? (무엇을 공유/분리하는가)
- 같은 프로세스의 스레드들은 보통 다음을 공유한다:
  - **Code Section (코드 영역)**
  - **Data Section (데이터 영역)**
  - **Heap (힙)**
  - **Open Files (열린 파일)** 등 일부 자원
- 스레드마다 개별로 갖는 대표 요소:
  - **Program Counter (프로그램 카운터)**
  - **Registers (레지스터)**
  - **Stack (스택)**

> 직관: “프로세스는 자원 컨테이너”, “스레드는 실행 흐름”.  
> 자원은 공유해서 효율을 얻지만, 실행 문맥은 분리되어야 동시 실행이 가능하다.

---

## 4. Multicore Programming (멀티코어 프로그래밍)

### 4.1 Concurrency (동시성) vs Parallelism (병렬성)
- **Concurrency (동시성)**:
  - 여러 작업이 “겹치는 시간 동안” 진행되는 성질(논리적 개념)
  - 싱글코어에서도 타임 슬라이스로 동시성이 성립할 수 있음
- **Parallelism (병렬성)**:
  - 여러 작업이 “물리적으로 동시에” 실행되는 성질(하드웨어/코어 기반)
  - 멀티코어에서 진짜 동시 실행

### 4.2 Challenges (도전 과제)
- **Identifying Tasks (작업 분해)**:
  - 무엇을 병렬화할지 나누는 것 자체가 어렵다
- **Balance (부하 균형)**:
  - 스레드 간 작업량이 치우치면 성능이 안 나온다
- **Data Splitting (데이터 분할)**:
  - 공유 데이터가 많을수록 동기화 비용이 증가
- **Data Dependency (데이터 의존성)**:
  - 순서가 강제되는 부분은 병렬화가 제한된다
- **Testing & Debugging (테스트/디버깅)**:
  - 타이밍에 따라 버그가 나타났다 사라지는 **Heisenbug (하이젠버그)** 성격

### 4.3 Types of Parallelism (병렬성의 유형)
- **Data Parallelism (데이터 병렬성)**:
  - 같은 연산을 다른 데이터 조각에 적용
- **Task Parallelism (태스크 병렬성)**:
  - 서로 다른 연산/기능을 병렬로 수행

---

## 5. Multithreading Models (멀티스레딩 모델)

> 핵심 질문: **User Thread (사용자 스레드)** 와 **Kernel Thread (커널 스레드)** 가 어떻게 매핑되는가?

### 5.1 User Threads (사용자 스레드) vs Kernel Threads (커널 스레드)
- **User Thread (사용자 스레드)**:
  - 사용자 공간 라이브러리에서 관리
  - 커널은 스레드의 존재를 직접 모를 수 있음(모델에 따라)
  - 장점: 생성/전환이 빠를 수 있음
  - 단점: 커널 수준 블로킹(I/O 등)에서 제약 가능
- **Kernel Thread (커널 스레드)**:
  - OS가 직접 스케줄링 대상으로 관리
  - 장점: 커널이 병렬 실행/블로킹 처리를 더 잘 지원
  - 단점: 오버헤드가 상대적으로 클 수 있음

### 5.2 Many-to-One Model (다대일 모델)
- 여러 **User Thread (사용자 스레드)** → 하나의 **Kernel Thread (커널 스레드)**에 매핑
- 장점: 사용자 수준에서 빠른 스레드 관리 가능
- 단점:
  - 한 사용자 스레드가 블로킹되면 전체가 막힐 수 있음
  - 멀티코어에서 병렬 실행이 제한됨(커널 스케줄링 단위가 1개)

### 5.3 One-to-One Model (일대일 모델)
- 각 **User Thread (사용자 스레드)** ↔ 하나의 **Kernel Thread (커널 스레드)**
- 장점:
  - 블로킹/병렬 실행에 유리
  - 멀티코어 활용이 자연스럽다
- 단점:
  - 스레드 수가 많아지면 커널 자원/오버헤드 부담

### 5.4 Many-to-Many Model (다대다 모델)
- 여러 사용자 스레드가 여러 커널 스레드에 매핑
- 목표: 병렬성 확보 + 과도한 커널 스레드 생성 억제의 균형
- 현실 감각:
  - 구현 복잡도가 올라가며, 시스템/런타임 설계에 따라 지원 여부가 달라진다

---

## 6. Thread Libraries (스레드 라이브러리)

### 6.1 Thread Library (스레드 라이브러리)의 역할
- 스레드 생성/종료
- 스레드 동기화(락 등) 지원
- 스레드 스케줄링/정책은 구현에 따라 다르며, OS 커널과 결합 수준이 다를 수 있음

### 6.2 Common APIs (대표 API) 감각
- **POSIX Threads (POSIX 스레드, Pthreads)**:
  - C/C++ 계열에서 널리 쓰이는 표준적 인터페이스
- **Windows Threads (윈도우 스레드)**:
  - Windows OS의 스레드 API
- **Java Threads (자바 스레드)**:
  - 언어 런타임 수준에서 스레드/동시성 구성 제공

> 포인트: “표준 API”가 같아도 내부 매핑(커널 스레드 여부 등)은 구현에 따라 다를 수 있다.

---

## 7. Implicit Threading (암묵적 스레딩)

> 개발자가 “스레드 하나씩 직접 만들기”가 어려워지며 등장한 접근.  
> 목표: **Thread Management (스레드 관리)** 를 프레임워크/런타임에게 위임.

### 7.1 Thread Pools (스레드 풀)
- 미리 일정 수의 스레드를 만들어 두고 작업을 큐잉해 처리
- 장점:
  - 생성/파괴 비용 감소
  - 동시 실행 개수 제어로 과도한 경쟁/스래싱 완화
- 단점:
  - 풀 크기 튜닝 필요
  - 작업 특성(I/O bound vs CPU bound)에 따른 최적점이 다름

### 7.2 Fork-Join Model (포크-조인 모델)
- 작업을 분할(**Fork (포크)**)하고, 결과를 합침(**Join (조인)**)
- 재귀적 분할/병렬 처리 패턴에 적합
- 실제 구현은 프레임워크/런타임(예: 특정 언어의 병렬 라이브러리)에 의해 제공되곤 한다

---

## 8. Threading Issues (스레딩 이슈)

### 8.1 Semantics of fork() and exec() (fork/exec 의미)
- 다중 스레드 프로세스에서 **fork (포크)** 시 의미가 모호해진다:
  - “현재 스레드만 복제?” vs “모든 스레드 복제?”
- **exec (실행 이미지 교체)** 는 프로세스 주소 공간 자체를 바꾸므로,
  - 호출 이후 기존 스레드/상태가 어떻게 되는지 정책이 중요해진다
- 결론: 멀티스레드 환경에서 프로세스 생성/실행 모델은 신중히 정의되어야 한다.

### 8.2 Signal Handling (시그널 처리)
- **Signal (시그널)** 은 프로세스에 이벤트를 전달하는 메커니즘(개념)
- 멀티스레드에서는 “어느 스레드가 시그널을 받는가?”가 핵심 이슈가 된다.
  - 특정 스레드로 전달
  - 모든 스레드로 브로드캐스트
  - 전용 시그널 처리 스레드를 두는 전략 등

### 8.3 Thread Cancellation (스레드 취소)
- 실행 중인 스레드를 종료시키는 문제
- 방식 감각:
  - **Asynchronous Cancellation (비동기 취소)**: 즉시 종료(위험—자원 정리 누락 가능)
  - **Deferred Cancellation (지연 취소)**: 안전 지점에서 종료(상대적으로 안전)
- 핵심: 자원(락/메모리/파일)을 어떻게 정리할지가 항상 따라온다.

### 8.4 Thread-Local Storage (스레드 로컬 저장소, TLS)
- 전역 변수처럼 보이지만 스레드마다 별도 값을 갖는 저장소
- 목적:
  - 스레드 간 간섭 없이 상태를 유지
  - 라이브러리/런타임 구현에서 자주 활용

### 8.5 Scheduler Activations (스케줄러 활성화) (개념)
- 사용자 스레드와 커널 스레드 사이의 협업을 통해
  - 블로킹/실행 가능 상태를 효율적으로 조정하려는 메커니즘(개념적 이해)
- 포인트: 스레딩 모델이 복잡해질수록 “누가 스케줄링을 책임지는가”가 중요해진다.

---

## 9. Concurrency Hazards (동시성 위험) — Ch 5+ 연결고리
- 스레드는 공유 자원 접근이 쉬워져 성능/구조는 좋아지지만,
  - **Race Condition (경쟁 상태)**, **Deadlock (교착상태)** 같은 문제가 현실적으로 발생한다.
- 따라서 스레드를 제대로 쓰려면 다음이 필요:
  - **Critical Section (임계 구역)** 개념
  - **Mutual Exclusion (상호 배제)** 메커니즘(락, 세마포어 등)
  - 올바른 설계/테스트 전략

> Ch 4는 “스레드가 왜 유용한지”와 “왜 위험한지”를 동시에 납득시키는 장이다.  
> 구체적인 동기화 기법은 이후 장에서 본격적으로 다룬다.

---

# Ch 5. CPU Scheduling (CPU 스케줄링)

> 큰 흐름: **CPU Scheduler (CPU 스케줄러)** 는 **Ready Queue (준비 큐)** 에 있는 **Process (프로세스)** / **Thread (스레드)** 중 “누가 다음에 CPU를 쓸지”를 결정한다. 목표는 **Efficiency (효율)**과 **Responsiveness (응답성)** 등 서로 충돌하는 지표를 균형 있게 만족시키는 것이다.

---

## 1. Basic Concepts (기본 개념)

### 1.1 Why CPU Scheduling? (왜 CPU 스케줄링이 필요한가)
- 시스템에는 일반적으로 여러 작업이 동시에 존재한다.
- CPU는 한 순간에 하나(코어 기준)의 실행 흐름만 수행하므로, OS는 실행 순서를 결정해야 한다.
- 목표:
  - CPU가 놀지 않게(**CPU Utilization (CPU 활용률)**)
  - 사용자 체감 응답을 좋게(**Response Time (응답 시간)**)
  - 전체 처리량을 올리고(**Throughput (처리량)**)
  - 공정성(**Fairness (공정성)**)을 유지

### 1.2 CPU-I/O Burst Cycle (CPU–I/O 버스트 사이클)
- 많은 프로세스는 다음 패턴을 반복한다:
  - **CPU Burst (CPU 버스트)**: 계산 수행
  - **I/O Burst (I/O 버스트)**: I/O 대기
- 관찰:
  - **I/O-bound (I/O 바운드)** 작업은 CPU 버스트가 짧고 I/O 대기가 많다.
  - **CPU-bound (CPU 바운드)** 작업은 CPU 버스트가 길다.
- 스케줄러는 이 특성을 고려해 시스템 전체 효율을 높일 수 있다.

### 1.3 When Scheduling Occurs? (스케줄링이 발생하는 시점)
CPU 스케줄링 의사결정은 주로 아래 전환에서 발생한다.
1) Running (실행) → Waiting (대기) (예: I/O 요청)
2) Running (실행) → Ready (준비) (예: 타이머 인터럽트로 **Preemption (선점)**)
3) Waiting (대기) → Ready (준비) (예: I/O 완료)
4) Running (실행) → Terminated (종료)

- 1), 4)는 보통 **Nonpreemptive (비선점)** 스케줄링에서도 발생
- 2), 3)은 **Preemptive (선점)** 스케줄링에서 핵심

### 1.4 Preemptive (선점) vs Nonpreemptive (비선점)
- **Nonpreemptive Scheduling (비선점 스케줄링)**:
  - CPU를 얻은 프로세스가 자발적으로 반납(대기/종료)할 때까지 실행
  - 구현이 단순하지만 응답성이 떨어질 수 있음
- **Preemptive Scheduling (선점 스케줄링)**:
  - OS가 타이머/우선순위 등으로 CPU를 회수 가능
  - 응답성이 좋아지지만 동기화/오버헤드가 증가할 수 있음

---

## 2. Scheduling Criteria (평가 기준)

스케줄링 알고리즘은 목적 함수가 하나가 아니라 “여러 지표의 균형” 문제다.

- **CPU Utilization (CPU 활용률)**: CPU가 바쁘게 일하는 비율(높을수록 좋음)
- **Throughput (처리량)**: 단위 시간당 완료된 프로세스 수(높을수록 좋음)
- **Turnaround Time (반환 시간)**: 제출부터 완료까지 걸린 전체 시간(낮을수록 좋음)
- **Waiting Time (대기 시간)**: Ready Queue에서 기다린 시간 총합(낮을수록 좋음)
- **Response Time (응답 시간)**: 첫 반응까지 걸린 시간(대화형 시스템에서 중요, 낮을수록 좋음)

> 주의: Turnaround Time (반환 시간)은 “전체 완료” 기준이고, Response Time (응답 시간)은 “첫 반응” 기준이다.

---

## 3. Scheduling Algorithms (스케줄링 알고리즘)

### 3.1 First-Come, First-Served (선입선출) (FCFS)
- Ready Queue에 들어온 순서대로 처리
- 장점: 단순, 공정해 보임
- 단점:
  - 긴 작업이 앞에 오면 뒤 작업이 줄줄이 대기(**Convoy Effect (콘보이 효과)**)
  - 대화형 응답성에 불리

### 3.2 Shortest-Job-First (최단 작업 우선) (SJF)
- CPU 버스트가 가장 짧은 작업을 먼저 실행
- 특성:
  - 평균 대기 시간을 최소화하는 성질이 있음(이론적 강점)
- 현실적 문제:
  - “다음 CPU 버스트 길이”를 정확히 알기 어렵다 → **Prediction (예측)**이 필요

#### Predicting CPU Burst (CPU 버스트 예측) 감각
- 과거 버스트를 기반으로 다음을 추정하는 방식이 자주 등장
- 요점: SJF는 “이상적”이지만, 실제 구현은 추정 품질에 좌우된다.

### 3.3 Shortest-Remaining-Time-First (최단 잔여 시간 우선) (SRTF)
- SJF의 선점형 버전
- 새로 도착한 프로세스의 “예측 버스트”가 현재 잔여 시간보다 짧으면 선점
- 장점: 응답성과 평균 대기 시간 측면에서 유리할 수 있음
- 단점: 선점/문맥 교환이 많아질 수 있음 + 예측 오류 영향

### 3.4 Priority Scheduling (우선순위 스케줄링)
- 가장 높은 **Priority (우선순위)** 를 가진 프로세스를 먼저 실행
- **Preemptive (선점)** / **Nonpreemptive (비선점)** 모두 가능
- 대표 문제: **Starvation (기아)**  
  - 낮은 우선순위 작업이 영원히 실행되지 못할 수 있음

#### Aging (에이징)
- 오래 기다린 작업의 우선순위를 점진적으로 올려 **Starvation (기아)** 를 완화

### 3.5 Round Robin (라운드 로빈) (RR)
- 각 프로세스에 고정된 **Time Quantum (시간 할당량)** 을 부여하고 순환 실행
- 특징:
  - 대화형 시스템에서 **Response Time (응답 시간)** 을 개선
  - Time Quantum에 따라 성능 성질이 크게 달라짐

#### Time Quantum (시간 할당량) 트레이드오프
- 너무 크면: FCFS처럼 동작(응답성 저하)
- 너무 작으면: **Context Switch (문맥 교환)** 오버헤드 증가
- 요점: RR은 “시간 할당량 튜닝”이 성능의 핵심 레버다.

### 3.6 Multilevel Queue (다단계 큐) Scheduling
- Ready Queue를 여러 큐로 분리(예: 대화형 vs 배치 작업)
- 각 큐는 서로 다른 스케줄링 정책을 가질 수 있음(예: 대화형은 RR, 배치는 FCFS)
- 큐 간에도 우선순위가 존재할 수 있음(상위 큐가 항상 우선이면 하위 큐 Starvation 가능)

### 3.7 Multilevel Feedback Queue (다단계 피드백 큐) (MLFQ)
- 작업이 큐 사이를 이동할 수 있는 다단계 큐 스케줄링
- 핵심 아이디어(감각):
  - “CPU를 오래 쓰는 작업”은 점점 낮은 우선순위 큐로 내려감
  - “짧게 쓰는 작업”은 높은 우선순위 큐에서 빠르게 처리
- 목표:
  - SJF의 이점을 “근사”하면서도, 대화형 응답성을 챙기기
- 현실: 파라미터(큐 개수, 시간 할당량, 승/강등 규칙)가 많아 설계/튜닝이 중요

---

## 4. Thread Scheduling (스레드 스케줄링)과의 연결
- 현대 OS는 **Kernel Thread (커널 스레드)** 단위로 CPU에 올린다.
- 프로세스 스케줄링처럼 설명하지만, 실제 실행 단위는 스레드인 경우가 일반적이다.
- 멀티코어에서는 각 코어에 어떤 스레드를 배치할지까지 포함해 고려해야 한다.

---

## 5. Multiple-Processor Scheduling (다중 프로세서 스케줄링) 감각

### 5.1 Load Balancing (부하 분산)
- 코어마다 Ready Queue를 두거나, 전역 큐를 두는 방식 등 구현이 갈린다.
- 목표: 코어가 한쪽만 바쁘고 다른 쪽은 노는 상황을 줄이기

### 5.2 Processor Affinity (프로세서 친화도)
- 특정 스레드를 특정 코어에 계속 두면 캐시 적중률이 좋아질 수 있다.
- **Cache (캐시)** 관점에서 이득이 있지만, 부하 분산과 트레이드오프가 생긴다.

### 5.3 NUMA (Non-Uniform Memory Access) (비균일 메모리 접근) 감각
- 메모리 접근 비용이 “어느 CPU/노드에 붙었는지”에 따라 달라지는 구조
- 스케줄링은 CPU만이 아니라 “메모리 locality (지역성)”까지 고려하게 된다.

---

## 6. Operating-System Examples (운영체제 사례) (감각)
- 실제 OS는 단일 알고리즘 하나로 끝나지 않고,
  - 우선순위, 타임 슬라이스, 피드백, 인터랙티브 부스트 등 “혼합 정책”을 쓴다.
- “어떤 지표를 우선하는가”가 곧 설계 철학(서버 vs 데스크톱 vs 모바일)이다.

---

## 7. Algorithm Evaluation (알고리즘 평가)
스케줄링 알고리즘은 “이론적으로 좋아 보임”과 “현실에서 좋음”이 다를 수 있다.

### 7.1 Deterministic Modeling (결정적 모델링)
- 특정 프로세스 집합/버스트 시간을 가정하고 성능을 계산
- 단순하지만 가정에 민감

### 7.2 Queueing Models (대기행렬 모델)
- 확률 모델로 평균 성능을 분석(이론적 도구)
- 현실 시스템을 완벽히 반영하진 못하지만 통찰을 준다

### 7.3 Simulation (시뮬레이션)
- 워크로드를 생성하거나 트레이스를 사용해 알고리즘을 실험
- 구현/비교에 실용적

### 7.4 Implementation (구현/측정)
- 실제 OS에 적용해 측정(가장 현실적이지만 비용이 큼)
- 관측 도구/벤치마크/워크로드 정의가 중요

---

## 8. Summary (요약)
- CPU 스케줄링은 “다목적 최적화”에 가깝다: 응답성, 처리량, 공정성, 오버헤드의 균형.
- FCFS/SJF/RR/Priority/MLFQ는 각각 강점과 약점이 명확하며,
  - 실제 OS는 워크로드(대화형 vs 배치 vs 서버)에 맞춰 혼합 정책을 사용한다.
- 멀티코어/NUMA 환경에서는 단순 “다음 누구”를 넘어 “어느 코어/어느 메모리 지역성”까지 고려하게 된다.

---

# Ch 6. Synchronization Tools (동기화 도구)

> 큰 흐름: **Concurrency (동시성)** 환경에서 공유 데이터에 대한 접근은 **Race Condition (경쟁 상태)** 를 만들 수 있다. 이를 해결하기 위해 OS/하드웨어/런타임은 **Critical-Section Problem (임계구역 문제)** 을 만족하는 동기화 도구를 제공한다. Ch 6은 그 도구(하드웨어 지원, **Mutex Lock (뮤텍스 락)**, **Semaphore (세마포어)**, **Monitor (모니터)** 등)를 정리한다.

---

## 1. Background (배경)

### 1.1 Race Condition (경쟁 상태)
- **Race Condition (경쟁 상태)**: 여러 실행 흐름이 **Shared Data (공유 데이터)** 를 동시에 접근할 때, 실행 순서에 따라 결과가 달라지는 현상
- 원인:
  - **Non-atomic Operation (비원자 연산)** 이 중간에 끼어들 수 있음
  - 읽기-수정-쓰기(read-modify-write) 형태가 특히 취약

### 1.2 Critical Section (임계 구역)
- **Critical Section (임계 구역)**: 공유 데이터를 읽거나 쓰는 코드 구간
- 목표: 동시에 둘 이상이 임계 구역을 실행하지 못하도록 보장(**Mutual Exclusion (상호 배제)**)

---

## 2. The Critical-Section Problem (임계구역 문제)

프로세스/스레드가 다음 구조를 가진다고 본다.
- **Entry Section (진입 구역)**: 임계 구역 진입 제어
- **Critical Section (임계 구역)**: 공유 데이터 접근
- **Exit Section (탈출 구역)**: 임계 구역 종료 처리
- **Remainder Section (나머지 구역)**: 나머지 코드

### 2.1 Requirements (요구 조건)
- **Mutual Exclusion (상호 배제)**: 한 실행 흐름이 임계 구역에 있으면 다른 실행 흐름은 प्रवेश 불가
- **Progress (진행)**: 임계 구역이 비어 있고 진입 요청이 있으면, 다음 진입자 결정이 무한히 지연되지 않음
- **Bounded Waiting (유한 대기)**: 진입 요청 후 무한히 기다리는 일이 없도록 제한됨

---

## 3. Peterson’s Solution (피터슨 해법)
- **Peterson’s Solution (피터슨 해법)** 은 2개의 실행 흐름에 대해 상호 배제/진행/유한 대기를 만족시키는 소프트웨어 해법으로 소개된다.
- 목적:
  - 실무 적용보다는 “임계구역 조건이 무엇인지”와 “제어 변수로 어떤 논리를 구성하는지”를 학습하는 데 있다.
- 현대 시스템에서는 컴파일러/CPU의 재정렬 및 **Memory Model (메모리 모델)** 특성 때문에, 하드웨어 지원 없는 순수 소프트웨어 해법을 그대로 신뢰하기 어렵다. 

---

## 4. Hardware Support for Synchronization (동기화를 위한 하드웨어 지원) 

### 4.1 Memory Model (메모리 모델)과 Memory Barrier (메모리 배리어)
- 멀티코어에서 각 코어의 메모리 관측 시점이 달라질 수 있다(약한 순서 보장).
- **Memory Barrier (메모리 배리어)** 는 특정 시점까지의 메모리 변경이 다른 프로세서에 “보이도록” 강제하는 명령이다. 

### 4.2 Hardware Instructions (하드웨어 원자 명령)
- 대표적인 원자 명령:
  - **Test-and-Set (테스트-앤-셋)**: 값을 읽고 동시에 세팅하는 동작을 원자적으로 수행
  - **Compare-and-Swap (비교-교환) (CAS)**: 기대값일 때만 새 값으로 교체를 원자적으로 수행 
- 이 명령들은 락, 세마포어 등 상위 동기화 도구의 기반이 된다.

### 4.3 Atomic Variables (원자 변수)
- 정수/불리언 등의 업데이트를 원자적으로 수행하는 변수/연산을 제공한다.
- 원자 변수는 단순 카운터/플래그에서 락보다 가벼운 선택지가 될 수 있다.

---

## 5. Mutex Locks (뮤텍스 락) 
- **Mutex Lock (뮤텍스 락)** 은 임계 구역을 보호하는 가장 기본적인 상호 배제 도구다.
- 기본 사용 형태:
  - 임계 구역 진입 전에 락 획득
  - 임계 구역 종료 후 락 해제

### 5.1 acquire() / release()
- `acquire()`와 `release()`는 원자적으로 동작해야 하며, 내부 구현은 CAS/Test-and-Set 같은 원자 명령을 기반으로 할 수 있다. 

### 5.2 Spinlock (스핀락)과 Busy Waiting (바쁜 대기)
- 어떤 뮤텍스 구현은 락이 풀릴 때까지 반복 확인(스핀)할 수 있다.
- 장단점:
  - 장점: 매우 짧은 임계 구역에서는 컨텍스트 스위칭 비용을 줄일 수 있음
  - 단점: 대기 시간이 길면 CPU 시간을 소모함 

---

## 6. Semaphores (세마포어) 

### 6.1 Semaphore (세마포어) 정의
- **Semaphore (세마포어)**n는 정수 카운터 기반 동기화 도구다.
- 표준 연산:
  - **wait (대기)**: 자원이 없으면 대기, 있으면 감소 후 진행
  - **signal (신호)**: 자원 반환(증가) 및 대기자 깨움 

### 6.2 Counting Semaphore (카운팅 세마포어) vs Binary Semaphore (이진 세마포어)
- **Counting Semaphore (카운팅 세마포어)**: N개의 동일 자원 풀을 제어
- **Binary Semaphore (이진 세마포어)**: 0/1만 사용, 뮤텍스처럼 상호 배제에 활용 가능

### 6.3 Semaphore 구현과 대기 방식
- 바쁜 대기 방식(스핀) 또는 블로킹 방식(대기 큐 사용)으로 구현될 수 있다.
- 블로킹 방식은 CPU 낭비를 줄이지만, 커널 개입/스케줄링이 필요하다.

---

## 7. Monitors (모니터) 

### 7.1 Monitor (모니터) 개념
- **Monitor (모니터)**는 공유 데이터와 그 데이터를 조작하는 연산을 “하나의 추상화”로 묶고,
- 모니터 내부에서는 기본적으로 상호 배제가 보장되도록 구성된다.

### 7.2 Condition Variables (조건 변수)
- 모니터는 조건 기반 동기화를 위해 **Condition Variable (조건 변수)** 를 제공한다.
- 대표 연산:
  - `wait()` : 조건이 만족될 때까지 대기
  - `signal()` / `broadcast()` : 대기 중인 실행 흐름을 깨움 

### 7.3 Signal-and-Wait vs Signal-and-Continue (개념)
- 조건 변수에서 `signal` 이후 락 소유권/실행 순서를 어떻게 둘지에 따라 의미가 달라질 수 있으며,
- 모니터 의미론은 구현/런타임에 의해 구체화된다.

---

## 8. Liveness (라이브니스) 
- 동기화는 “안전성(safety)”뿐 아니라 “진행성(liveness)”도 영향을 받는다.
- 대표 라이브니스 문제:
  - **Deadlock (교착상태)**: 서로가 서로를 기다려 진행 불가
  - **Starvation (기아)**: 특정 실행 흐름이 계속 자원을 얻지 못함

---

## 9. Priority Inversion (우선순위 역전) 
- **Priority Inversion (우선순위 역전)**: 낮은 우선순위가 락을 잡고 있어 높은 우선순위가 대기하는 동안,
  중간 우선순위가 CPU를 점유해 높은 우선순위가 더 오래 기다리는 현상
- 완화 개념:
  - **Priority Inheritance (우선순위 상속)** 등 정책을 사용해 락 보유자의 우선순위를 임시로 올리는 방식

---

## 10. Summary (요약)
- Ch 6은 임계구역 문제를 해결하기 위한 “도구”를 정리한다:  
  **Hardware Support (하드웨어 지원)**(메모리 배리어, CAS/Test-and-Set, 원자 변수) → **Mutex Lock (뮤텍스 락)** → **Semaphore (세마포어)** → **Monitor (모니터)** + **Condition Variable (조건 변수)**. 
- 동기화 도구는 **Deadlock (교착상태)**, **Starvation (기아)**, **Priority Inversion (우선순위 역전)** 같은 라이브니스 이슈도 함께 고려해야 한다. 

---

# Ch 7. Synchronization Examples (동기화 예제)

> 큰 흐름: **Process Synchronization (프로세스 동기화)** 에서 배운 도구(**Mutex Lock (뮤텍스 락)**, **Semaphore (세마포어)**, **Monitor (모니터)**, **Condition Variable (조건 변수)** 등)를 대표 문제에 적용한다. 또한 **Linux (리눅스)**, **Windows (윈도우)**, **POSIX (포직스)**, **Java (자바)** 에서 제공하는 동기화 수단을 정리한다. 

---

## 1. Classic Problems of Synchronization (고전 동기화 문제) :contentReference

### 1.1 The Bounded-Buffer Problem (유한 버퍼 문제) / Producer–Consumer (생산자–소비자)
- 상황:
  - **Producer (생산자)** 가 데이터를 생성해 **Buffer (버퍼)** 에 넣고
  - **Consumer (소비자)** 가 버퍼에서 데이터를 꺼내 처리한다.
- 핵심 요구사항:
  - 버퍼 접근은 **Mutual Exclusion (상호 배제)** 가 필요하다.
  - 버퍼가 가득 차면 생산자는 대기해야 한다.
  - 버퍼가 비어 있으면 소비자는 대기해야 한다.
- 전형적 구성(도구 관점):
  - **Mutex (뮤텍스)**: 버퍼(공유 자료구조) 보호
  - **Counting Semaphore (카운팅 세마포어)**: `empty (빈 칸 수)`, `full (채워진 칸 수)` 관리
- 대표 오류:
  - mutex 없이 접근 → **Race Condition (경쟁 상태)**
  - `signal`/`wait` 순서 불일치 → 교착 또는 데이터 손실

### 1.2 The Readers–Writers Problem (독자–저자 문제)
- 상황:
  - **Reader (독자)** 는 데이터를 읽기만 한다.
  - **Writer (저자)** 는 데이터를 수정한다.
- 핵심 요구사항:
  - Writer는 단독 접근이 필요하다(쓰기 중에는 읽기/쓰기 모두 금지).
  - Reader는 “읽기끼리”는 동시에 가능하게 만들고 싶다.
- 정책 이슈:
  - Reader 우선 정책이면 Writer가 오래 대기할 수 있다(**Starvation (기아)** 가능).
  - Writer 우선 정책이면 Reader의 지연이 커질 수 있다.
- 전형적 구성:
  - Reader 수를 추적하는 공유 변수 + 그 보호용 락/세마포어
  - Writer 진입을 제어하는 락/세마포어

### 1.3 The Dining Philosophers Problem (식사하는 철학자 문제)
- 상황:
  - 철학자들이 생각/식사를 반복하며, 식사하려면 양쪽 자원(젓가락/포크)을 모두 확보해야 한다.
- 목표:
  - **Deadlock (교착상태)** 가 발생하지 않게
  - **Starvation (기아)** 가 발생하지 않게
  - 가능한 한 동시 식사를 허용
- 전형적 접근:
  - 단순히 “왼쪽→오른쪽” 순서로 잡게 하면 교착 가능
  - 자원 획득 순서 제한(전역 순서), 동시 진입 제한, 상태 기반 제어(세마포어 배열 + 상태 변수) 등으로 해결 

---

## 2. Synchronization Tools in Operating Systems (운영체제의 동기화 도구)

### 2.1 Synchronization in Linux (리눅스 동기화)
- 커널은 멀티코어/선점 환경에서 공유 자료구조를 보호해야 한다.
- 대표 수단:
  - **Atomic Operations (원자 연산)** / **Atomic Integers (원자 정수)**
  - **Spinlock (스핀락)**
  - **Semaphore (세마포어)**
  - **Reader–Writer Lock (읽기-쓰기 락)** 계열(읽기 공유/쓰기 배타)
- 커널 환경에서는 “블로킹 가능 여부”와 “임계 구역 길이”에 따라 스핀락/세마포어 선택이 달라진다. 

### 2.2 Synchronization in Windows (윈도우 동기화)
- Windows는 커널/유저 영역에서 다양한 동기화 객체를 제공한다.
- 대표 개념:
  - 짧은 임계 구역을 위한 스핀 기반 기법
  - 사용자 영역에서 사용할 수 있는 동기화 객체(뮤텍스, 세마포어, 이벤트, 타이머 등)
- **Event (이벤트)** 는 조건 기반 신호 전달에서 **Condition Variable (조건 변수)** 와 유사한 역할로 이해할 수 있다. 

---

## 3. POSIX Synchronization (POSIX 동기화)

### 3.1 POSIX Mutex Locks (POSIX 뮤텍스 락)
- 스레드 간 상호 배제를 위한 기본 도구
- `lock/unlock` 패턴으로 임계 구역 보호

### 3.2 POSIX Semaphores (POSIX 세마포어)
- 두 종류:
  - **Named Semaphore (이름 있는 세마포어)**: 이름으로 참조되며, 서로 무관한 프로세스 간에도 사용 가능
  - **Unnamed Semaphore (이름 없는 세마포어)**: 보통 같은 프로세스 내부(또는 제한된 공유 범위)에서 사용

### 3.3 POSIX Condition Variables (POSIX 조건 변수)
- POSIX는 언어 차원의 모니터가 없으므로,
  - **Condition Variable (조건 변수)** 는 보통 **Mutex (뮤텍스)** 와 함께 사용해 상호 배제를 보장한다.
- 패턴:
  - 조건이 만족되지 않으면 `wait`로 잠들고
  - 다른 스레드가 상태를 바꾼 뒤 `signal/broadcast`로 깨운다.

---

## 4. Java Synchronization (자바 동기화) 

### 4.1 Java Monitors (자바 모니터)
- 모든 객체는 내부적으로 락을 가질 수 있고,
- `synchronized`는 해당 락을 기반으로 상호 배제를 제공한다.
- `wait/notify/notifyAll`은 조건 대기/신호의 기본 도구다. 

### 4.2 Reentrant Locks (재진입 락)
- `synchronized`와 유사한 목적(상호 배제)을 더 유연한 API로 제공
- 예외 상황에서도 락이 해제되도록 `try/finally` 패턴을 함께 쓰는 것이 일반적이다. 

### 4.3 Java Semaphores (자바 세마포어) / Java Condition Variables (자바 조건 변수)
- 세마포어: 특정 개수의 자원 접근 제어에 사용
- 조건 변수: 재진입 락과 결합해 조건 기반 대기/신호를 구조화

---

## 5. Alternative Approaches (대안적 접근) 
- **Transactional Memory (트랜잭셔널 메모리)**: 공유 메모리 갱신을 트랜잭션으로 처리하고 충돌 시 롤백하는 접근
- **OpenMP (오픈엠피)**: 컴파일러 지시문 기반 병렬화/동기화 지원(주로 공유 메모리 병렬 프로그래밍)
- **Functional Programming Languages (함수형 프로그래밍 언어)**: 불변성/순수 함수 기반으로 공유 상태를 줄여 동시성 문제를 완화하는 방향

---

## 6. Summary (요약)
- Ch 7은 동기화 도구를 대표 문제에 적용하며 패턴을 학습한다:  
  **Bounded-Buffer (유한 버퍼)**, **Readers–Writers (독자–저자)**, **Dining Philosophers (식사하는 철학자)**. 
- 또한 OS/플랫폼이 제공하는 동기화 수단을 비교한다:  
  **Linux (리눅스)**, **Windows (윈도우)**, **POSIX (포직스)**, **Java (자바)**. 

---

# Ch 8. Deadlocks (교착상태)

> 큰 흐름: **Deadlock (교착상태)** 는 여러 **Process (프로세스)** / **Thread (스레드)** 가 **Resource (자원)** 를 서로 점유한 채 상대가 가진 자원을 기다리면서 영원히 진행하지 못하는 상태다. Ch 8은 교착상태의 성립 조건을 정리하고, 이를 다루는 네 가지 접근(**Prevention (예방)**, **Avoidance (회피)**, **Detection & Recovery (탐지 및 복구)**, **Ignoring (무시)**)을 설명한다. 

---

## 1. System Model (시스템 모델)

### 1.1 Resource (자원)와 Instance (인스턴스)
- OS는 다양한 자원을 관리한다.
  - 예: **CPU (CPU)**, **Memory (메모리)**, **I/O Device (입출력 장치)**, **File (파일)**, **Mutex Lock (뮤텍스 락)** 등
- 각 **Resource Type (자원 유형)** 은 하나 또는 여러 개의 **Instance (인스턴스)** 를 가질 수 있다. 

### 1.2 Resource-Usage Pattern (자원 사용 패턴)
프로세스/스레드는 일반적으로 다음의 순서를 반복한다.
1) **Request (요청)**
2) **Use (사용)**
3) **Release (반납)** 

---

## 2. Deadlock Characterization (교착상태 특성)

### 2.1 Deadlock (교착상태) 정의
- **Deadlock (교착상태)**: 서로 자원을 점유한 채 상대가 가진 자원을 기다려 “영구적으로 블로킹(permanent blocking)”되는 상태 

### 2.2 Four Necessary Conditions (4가지 필요 조건)
교착상태는 아래 4조건이 동시에 성립할 때 발생 가능하다. 

1. **Mutual Exclusion (상호 배제)**  
   - 어떤 자원은 한 번에 하나만 사용할 수 있다.

2. **Hold and Wait (점유 및 대기)**  
   - 최소 하나의 자원을 점유한 상태에서, 다른 자원을 추가로 요청하며 대기한다.

3. **No Preemption (비선점)**  
   - 자원을 강제로 빼앗을 수 없고, 자원은 점유자가 자발적으로 반납해야 한다.

4. **Circular Wait (순환 대기)**  
   - 프로세스/스레드들이 자원 대기 관계로 원형 고리를 이룬다.

---

## 3. Resource-Allocation Graph (자원 할당 그래프)

### 3.1 Graph Elements (그래프 요소)
- **Process Node (프로세스 노드)**: Pi
- **Resource Node (자원 노드)**: Rj
- 간선:
  - **Request Edge (요청 간선)**: Pi → Rj
  - **Assignment Edge (할당 간선)**: Rj → Pi 

### 3.2 Cycle (사이클)과 교착상태 관계
- 자원 유형마다 인스턴스가 1개인 경우:
  - 그래프에 **Cycle (사이클)** 이 존재하면 교착상태가 성립한다. 
- 인스턴스가 여러 개인 경우:
  - Cycle이 있어도 교착상태가 반드시 발생한다고 단정할 수는 없다. 

---

## 4. Methods for Handling Deadlocks (교착상태 처리 방법)

교착상태 대응은 크게 네 가지 접근으로 정리된다.
1) **Deadlock Prevention (교착상태 예방)**
2) **Deadlock Avoidance (교착상태 회피)**
3) **Deadlock Detection and Recovery (교착상태 탐지 및 복구)**
4) **Ignoring Deadlocks (교착상태 무시)**

---

## 5. Deadlock Prevention (교착상태 예방)

> 목표: 4가지 필요 조건 중 최소 하나가 항상 성립하지 않도록 시스템을 제한한다. 

### 5.1 Eliminate Mutual Exclusion (상호 배제 제거)
- 가능한 자원은 공유 가능하게 설계한다.
- 단, 프린터/락 같은 자원은 본질적으로 공유가 어렵다.

### 5.2 Eliminate Hold and Wait (점유 및 대기 제거)
- 방식 예:
  - 시작 시 필요한 자원을 한 번에 모두 요청하게 하거나
  - 새 자원을 요청하기 전에 보유 자원을 모두 반납하게 한다.
- 부작용:
  - 자원 활용률 저하, 기아 가능성 증가

### 5.3 Eliminate No Preemption (비선점 제거)
- 특정 상황에서 자원을 선점(회수)할 수 있게 한다.
- 적용 가능한 자원과 불가능한 자원이 존재한다(락/일부 장치는 선점이 어렵다).

### 5.4 Eliminate Circular Wait (순환 대기 제거)
- 모든 자원에 **Total Ordering (전역 순서)** 를 부여하고, 오름차순으로만 요청하도록 강제한다.
- 시스템 전체에서 일관된 자원 획득 순서를 유지해야 한다.

---

## 6. Deadlock Avoidance (교착상태 회피)

> 목표: 자원 요청이 들어올 때마다 “지금 할당해도 안전한가”를 판단하고, 안전하지 않으면 할당을 지연/거부한다. 

### 6.1 Safe State (안전 상태)와 Unsafe State (비안전 상태)
- **Safe State (안전 상태)**: 어떤 프로세스 실행 순서(안전 순서)가 존재하여 모든 프로세스를 종료시킬 수 있는 상태
- **Unsafe State (비안전 상태)**: 교착상태가 “당장”은 아니더라도, 특정 진행에서 교착상태가 발생할 수 있는 상태 

### 6.2 Resource-Allocation Graph Algorithm (자원 할당 그래프 알고리즘)
- (주로) 자원 인스턴스가 1개인 상황에서,
  - 미래 요청 가능성까지 표현해 “사이클이 생기는 요청”을 제한하는 방식으로 설명된다. 

### 6.3 Banker’s Algorithm (은행가 알고리즘)
- 각 프로세스의 최대 요구량을 알고 있다고 가정하고, 할당 후에도 안전 상태가 유지될 때만 자원을 할당한다. 
- 핵심 데이터(전형 표기):
  - **Available (가용 자원)**
  - **Max (최대 요구)**
  - **Allocation (현재 할당)**
  - **Need (필요 = Max - Allocation)**

---

## 7. Deadlock Detection (교착상태 탐지)

> 목표: 교착상태 발생을 허용하되, 주기적으로 상태를 검사해 교착상태를 찾아낸다. 

### 7.1 Single Instance per Resource Type (자원 유형당 1 인스턴스)
- **Wait-for Graph (대기 그래프)**로 변환해 사이클을 탐지한다.
  - 노드: 프로세스
  - 간선: Pi가 Pj가 가진 자원을 기다림(Pi → Pj)
- 사이클이 있으면 교착상태로 판단한다. 

### 7.2 Multiple Instances per Resource Type (자원 유형당 다중 인스턴스)
- Available/Allocation/Request(또는 Need) 정보를 기반으로 “종료 가능한 프로세스가 존재하는지”를 반복적으로 검사하는 탐지 알고리즘을 사용한다. 

---

## 8. Recovery from Deadlock (교착상태 복구)

> 목표: 탐지된 교착상태를 “깨뜨려” 시스템을 다시 진행 가능하게 만든다. :contentReference

### 8.1 Process Termination (프로세스 종료)
- 방법:
  - 교착상태 관련 프로세스를 모두 종료
  - 또는 한 번에 하나씩 종료하며 교착상태가 해소될 때까지 반복
- 고려 기준:
  - 우선순위, 점유 자원량, 실행 시간, 롤백/재시작 비용, 사용자 영향 등

### 8.2 Resource Preemption (자원 선점)
- 특정 프로세스에서 자원을 회수하여 다른 프로세스에 재할당한다.
- 주요 이슈:
  - **Victim Selection (희생자 선택)**
  - **Rollback (롤백)**: 선점된 프로세스를 안전한 지점으로 되돌릴 수 있는지
  - **Starvation (기아)** 방지: 특정 프로세스만 반복 희생되지 않게 정책 필요 

---

## 9. Ignoring Deadlocks (교착상태 무시)
- 일부 시스템은 교착상태를 드물다고 보고 적극적 처리(예방/회피/탐지)를 하지 않는다.
- 대신 타임아웃, 재시도, 운영자(프로세스 재시작) 등으로 현실적 대응을 한다. 

---

## 10. Summary (요약)
- **Deadlock (교착상태)** 는 4가지 필요 조건이 동시에 성립할 때 발생 가능하다. :contentReference
- 처리 방법은 네 가지 축으로 정리된다:  
  **Prevention (예방)**, **Avoidance (회피: Safe State, Banker’s Algorithm (은행가 알고리즘))**, **Detection & Recovery (탐지 및 복구)**, **Ignoring (무시)**. 

---

# Ch 9. Main Memory (메인 메모리)

> 큰 흐름: **Main Memory (메인 메모리)** 는 실행 중인 **Process (프로세스)** 가 적재되는 공간이며, OS는 (1) 주소 변환과 보호(**Address Binding (주소 바인딩)**, **Logical/Physical Address (논리/물리 주소)**, **MMU (Memory-Management Unit) (메모리 관리 장치)**), (2) 연속 할당의 한계(**Contiguous Memory Allocation (연속 메모리 할당)**, **Fragmentation (단편화)**), (3) **Paging (페이징)** 과 페이지 테이블 구조, (4) **Swapping (스와핑)** 을 통해 메모리를 효율적이고 안전하게 관리한다.

---

## 1. Background (배경)

### 1.1 Main Memory (메인 메모리)와 실행
- **Program (프로그램)** 은 저장장치에 있는 정적인 실행 파일이고, 메모리에 적재되어 실행되면 **Process (프로세스)** 가 된다.
- CPU는 **Program Counter (프로그램 카운터)** 가 가리키는 주소에서 명령을 가져오고(fetch), 실행 중 **Load/Store (로드/스토어)** 로 메모리에 접근한다.
- 메모리는 “주소가 붙은 바이트 배열”로 볼 수 있으며, OS는 여러 프로세스가 이 공간을 안전하게 공유하도록 관리해야 한다.

### 1.2 Address Binding (주소 바인딩)
- 프로그램의 주소(심볼/참조)가 실제 메모리 위치와 연결되는 시점:
  - **Compile-Time Binding (컴파일 시 바인딩)**: 고정 위치 가정, 위치 변경 시 재컴파일 필요
  - **Load-Time Binding (적재 시 바인딩)**: 로딩 시 실제 위치 결정, 적재 후 이동 제한
  - **Execution-Time Binding (실행 시 바인딩)**: 실행 중에도 위치 변경 가능, 하드웨어 지원 필요

### 1.3 Logical Address (논리 주소) vs Physical Address (물리 주소)
- **Logical Address (논리 주소)**(또는 **Virtual Address (가상 주소)**): CPU가 생성하는 주소(프로세스 관점)
- **Physical Address (물리 주소)**: 실제 RAM이 접근하는 주소(하드웨어 관점)
- 현대 시스템은 보통 논리/물리 주소를 분리하고, 변환은 **MMU (메모리 관리 장치)**가 수행한다.

### 1.4 Memory Protection (메모리 보호)
- 한 프로세스가 자신의 주소 공간 밖을 접근하지 못하도록 해야 한다.
- 단순한 보호/재배치 모델:
  - **Base Register (베이스 레지스터)**: 프로세스 시작 물리 주소
  - **Limit Register (리밋 레지스터)**: 접근 가능한 범위(크기)
- 논리 주소가 limit 내인지 검사한 뒤, 물리 주소를 base+offset 형태로 계산한다.

### 1.5 Dynamic Loading (동적 로딩) / Dynamic Linking (동적 링킹)
- **Dynamic Loading (동적 로딩)**: 실제로 호출될 때까지 루틴을 메모리에 올리지 않는 방식(메모리 절약)
- **Dynamic Linking (동적 링킹)**: 공용 라이브러리를 실행 시점에 연결하는 방식
- **Shared Library (공유 라이브러리)** 는 여러 프로세스가 같은 코드 페이지를 공유하도록 해 메모리를 절약할 수 있다.

---

## 2. Contiguous Memory Allocation (연속 메모리 할당)

> 프로세스가 물리 메모리에서 “연속된 한 덩어리”를 할당받는 방식.

### 2.1 Memory Partitioning (메모리 분할)
- **Fixed Partitioning (고정 분할)**:
  - 미리 정한 크기의 파티션들로 나눔
  - 단순하지만 내부 단편화가 발생하기 쉽다.
- **Variable Partitioning (가변 분할)**:
  - 프로세스 크기에 맞춰 가변 크기의 hole(빈 공간)에 배치
  - 외부 단편화가 핵심 문제가 된다.

### 2.2 Allocation Strategies (할당 전략)
- **First Fit (최초 적합)**: 처음 만나는 충분히 큰 hole에 배치
- **Best Fit (최적 적합)**: 가장 작은 충분한 hole에 배치
- **Worst Fit (최악 적합)**: 가장 큰 hole에 배치

### 2.3 Fragmentation (단편화)
- **Internal Fragmentation (내부 단편화)**:
  - 할당 단위(파티션/블록) 때문에 실제 필요보다 더 크게 배정되어 남는 공간
- **External Fragmentation (외부 단편화)**:
  - 총 빈 공간은 충분하지만 “연속된 큰 공간”이 없어 할당 실패

### 2.4 Compaction (압축)
- 프로세스들을 재배치하여 흩어진 빈 공간을 하나로 모으는 방법
- 전제: 프로세스의 실행 중 이동이 가능해야 하므로 **Execution-Time Binding (실행 시 바인딩)** 이 필요하다.
- 비용이 크기 때문에 실행 타이밍/빈도는 정책 문제다.

---

## 3. Paging (페이징)

> 물리 메모리를 고정 크기 블록으로 나누고(프레임), 논리 주소 공간도 같은 크기로 나누어(페이지) 매핑하는 방식.

### 3.1 Basic Method (기본 방법)
- 물리 메모리: **Frame (프레임)** 단위로 분할
- 논리 주소 공간: **Page (페이지)** 단위로 분할
- 프로세스는 연속된 논리 주소 공간을 갖지만, 물리 메모리에서는 프레임들에 분산 배치될 수 있다.
- 핵심 효과: 외부 단편화가 발생하지 않는다(고정 크기 매핑).

### 3.2 Address Translation (주소 변환)
- 논리 주소는 보통 다음으로 구성된다:
  - **Page Number (페이지 번호)** + **Page Offset (페이지 오프셋)**
- **Page Table (페이지 테이블)** 이 page number를 frame number로 변환한다.
- 물리 주소는:
  - **Frame Number (프레임 번호)** + offset

### 3.3 Page Table (페이지 테이블)과 PTE (Page-Table Entry) (페이지 테이블 엔트리)
- PTE에 들어갈 수 있는 대표 정보:
  - **Frame Number (프레임 번호)**
  - **Valid Bit (유효 비트)**: 해당 페이지가 주소 공간에 속하는지/현재 매핑이 유효한지
  - **Protection Bits (보호 비트)**: R/W/X 권한
  - **Dirty Bit (더티 비트)**: 수정 여부
  - **Reference Bit (참조 비트)**: 최근 참조 여부(교체 알고리즘에 활용)

### 3.4 TLB (Translation Lookaside Buffer) (변환 색인 버퍼)
- 페이지 테이블 조회는 메모리 접근을 추가로 유발할 수 있다.
- **TLB (변환 색인 버퍼)** 는 최근 변환을 캐시해 주소 변환 비용을 줄인다.
- **TLB Hit (히트)** 면 빠르게 변환하고, **TLB Miss (미스)** 면 페이지 테이블을 참조한다.

### 3.5 Shared Pages (공유 페이지)
- 여러 프로세스가 같은 코드(예: 공유 라이브러리)를 사용할 때 동일한 물리 프레임을 공유할 수 있다.
- 공유는 메모리 효율을 높이지만, 보호/권한 설정이 정확해야 한다.

---

## 4. Structure of the Page Table (페이지 테이블의 구조)

### 4.1 Motivation (동기)
- 주소 공간이 커지면 단일 레벨 페이지 테이블이 매우 커질 수 있다.
- 이를 줄이거나 관리하기 위해 다양한 구조가 사용된다.

### 4.2 Hierarchical Paging (계층적 페이징)
- 페이지 테이블을 여러 단계로 나누어, 실제로 사용되는 범위에 대해서만 하위 테이블을 할당한다.
- 대표 형태: 2단계/3단계 이상의 다단계 페이지 테이블

### 4.3 Hashed Page Tables (해시 페이지 테이블)
- 큰 주소 공간에서 해시를 이용해 (가상 페이지 → 프레임) 매핑을 찾는 방식
- 충돌 처리(체이닝 등)가 필요하다.

### 4.4 Inverted Page Table (역 페이지 테이블)
- “가상 페이지마다 엔트리” 대신 “물리 프레임마다 엔트리”를 둔다.
- 물리 메모리 크기에 비례해 테이블 크기를 제한할 수 있다.
- 변환 시 탐색 비용을 줄이기 위해 해시/보조 구조가 함께 쓰인다.

---

## 5. Swapping (스와핑)

### 5.1 Swapping (스와핑) 개념
- **Swapping (스와핑)**: 프로세스(또는 메모리 이미지)를 메모리에서 **Backing Store (백킹 스토어)**(보통 디스크)로 내렸다가 다시 올리는 것
- 목적:
  - 메모리가 부족할 때 더 많은 프로세스를 수용
  - 다중 프로그래밍 정도를 유지

### 5.2 Swapping 비용
- 디스크 I/O가 포함되므로 비용이 매우 크다.
- 스와핑이 잦아지면 전체 성능과 응답성이 급격히 저하될 수 있다.

### 5.3 Swapping 제약
- I/O 중인 페이지(또는 버퍼)는 임의로 이동/스왑아웃하기 어렵다.
- 따라서 실제 구현에서는 “프로세스 전체 스와핑”보다 “페이지 단위 이동”으로 발전하는 경우가 많고, 이는 다음 장의 **Virtual Memory (가상 메모리)** 와 직접 연결된다.

---

## 6. Summary (요약)
- 메인 메모리는 실행 중인 프로세스가 적재되는 핵심 자원이며, OS는 주소 변환/보호로 안전한 실행 환경을 만든다.
- 연속 메모리 할당은 단순하지만 단편화 문제가 있으며, 압축은 비용이 큰 해결책이다.
- 페이징은 외부 단편화를 제거하고, 페이지 테이블과 TLB로 주소 변환을 효율화한다.
- 페이지 테이블은 계층/해시/역 페이지 테이블 등 다양한 구조로 확장된다.
- 스와핑은 메모리 부족을 완화하지만 디스크 I/O 비용이 크며, 페이지 단위 관리로 자연스럽게 확장된다.

---

# Ch 10. Virtual Memory (가상 메모리)

> 큰 흐름: **Virtual Memory (가상 메모리)** 는 프로세스가 물리 메모리(**Physical Memory (물리 메모리)**) 에 전부 올라와 있지 않아도 실행되도록 하며, 각 프로세스에 큰 **Virtual Address Space (가상 주소 공간)** 을 제공한다. 핵심은 **Demand Paging (요구 페이징)**, **Page Replacement (페이지 교체)**, **Frame Allocation (프레임 할당)**, **Thrashing (스래싱)** 제어, 그리고 **Memory-Mapped Files (메모리 매핑 파일)** 이다.

---

## 1. Background (배경)

### 1.1 Virtual Memory (가상 메모리)의 목적
- 물리 메모리보다 큰 주소 공간 제공
- 필요한 페이지만 적재하여 메모리 사용 효율 향상
- 더 많은 프로세스를 동시에 실행 가능(**Degree of Multiprogramming (다중 프로그래밍 정도)** 증가)
- 프로세스 간 격리(**Protection (보호)**) 및 선택적 공유(**Sharing (공유)**) 지원

### 1.2 Locality (지역성)
- 프로그램은 짧은 시간 동안 제한된 주소 범위를 집중적으로 참조하는 경향이 있다.
  - **Temporal Locality (시간 지역성)**: 최근 참조한 데이터/코드를 곧 다시 참조
  - **Spatial Locality (공간 지역성)**: 참조한 주소 근처를 곧 참조
- 요구 페이징과 교체 정책은 지역성을 전제로 성능을 확보한다.

---

## 2. Demand Paging (요구 페이징)

### 2.1 기본 아이디어
- 페이지를 실제로 필요할 때만 메모리에 적재한다.
- 초기 로딩 비용을 줄이고, 사용하지 않는 페이지를 올리지 않아 메모리를 절약한다.

### 2.2 Valid–Invalid Bit (유효–무효 비트)
- 페이지 테이블 엔트리는 해당 페이지가 유효한 매핑인지 표시한다.
- Invalid는 보통:
  - 아직 메모리에 적재되지 않았거나
  - 주소 공간에 속하지 않는 접근을 의미한다.

### 2.3 Page Fault (페이지 폴트) 처리 흐름
1) CPU가 페이지 접근
2) 해당 페이지가 메모리에 없으면 **Page Fault (페이지 폴트)** 발생
3) OS가 접근이 합법적인지 확인
   - 불법 접근이면 프로세스 종료
4) 합법이면 빈 프레임 확보 또는 교체 수행
5) 디스크에서 페이지를 읽어와 프레임에 적재
6) 페이지 테이블 갱신(프레임 번호, 유효 비트 등)
7) 중단된 명령 재시작

### 2.4 Pure Demand Paging (순수 요구 페이징)
- 실제 접근 전에는 페이지를 전혀 올리지 않는 형태
- 시스템은 초기 실행 최적화를 위해 일부 선적재를 섞을 수 있다.

---

## 3. Performance of Demand Paging (요구 페이징 성능)

### 3.1 Effective Access Time (유효 접근 시간)
- 평균 메모리 접근 시간은 다음 요소에 의해 결정된다.
  - **Memory Access Time (메모리 접근 시간)**
  - **Page-Fault Rate (페이지 폴트율)**
  - 페이지 폴트 처리 비용(트랩/디스크 I/O/재시작)
- 폴트가 발생하면 디스크 I/O 때문에 지연이 크게 증가한다.

### 3.2 Demand Paging 성능에 영향을 주는 요소
- 폴트율(지역성 및 작업 집합 크기와 관련)
- 교체 알고리즘과 프레임 수
- 디스크/스왑 구성 및 I/O 스케줄링
- TLB와 페이지 테이블 접근 비용

---

## 4. Copy-on-Write (복사-쓰기)

### 4.1 Copy-on-Write (COW) 개념
- 프로세스 생성 시 주소 공간을 즉시 복사하지 않고, 페이지를 공유한다.
- 쓰기가 발생할 때만 해당 페이지를 복사하여 분리한다.

### 4.2 장점
- `fork` 기반 생성이 빠르다.
- 실제로 수정되는 페이지만 복사되므로 메모리 사용량이 줄어든다.

---

## 5. Page Replacement (페이지 교체)

### 5.1 필요성
- 페이지 폴트가 발생했는데 빈 프레임이 없으면 희생 페이지를 선택해 교체해야 한다.

### 5.2 기본 절차
1) 희생 페이지 선택(**Victim Page (희생 페이지)**)
2) 수정된 페이지면 디스크에 기록(**Dirty Bit (더티 비트)**)
3) 희생 페이지의 페이지 테이블 엔트리 갱신(무효화)
4) 요구 페이지를 프레임에 적재
5) 페이지 테이블 갱신 후 명령 재시작

### 5.3 Page-Replacement Algorithms (페이지 교체 알고리즘)
- **FIFO (First-In, First-Out) (선입선출)**
- **Optimal (최적) 알고리즘**: 비교 기준(현실 구현 불가)
- **LRU (Least Recently Used) (최소 최근 사용)**
- **LRU Approximation (LRU 근사)**: 참조 비트 기반 등
- **Second-Chance (세컨드 찬스) / Clock (클록)**

### 5.4 Belady’s Anomaly (벨라디 이상)
- FIFO에서 프레임 수 증가에도 페이지 폴트가 증가할 수 있다.

---

## 6. Allocation of Frames (프레임 할당)

### 6.1 Minimum Number of Frames (최소 프레임 수)
- 명령 실행을 위해 동시에 필요한 페이지 수가 존재할 수 있다.
- 최소 프레임이 부족하면 과도한 폴트로 실행이 비정상적으로 느려진다.

### 6.2 Allocation Schemes (할당 방식)
- **Equal Allocation (균등 할당)**
- **Proportional Allocation (비례 할당)**

### 6.3 Global vs Local Replacement (전역 vs 지역 교체)
- **Global Replacement (전역 교체)**: 전체 프레임 집합에서 희생 페이지 선택
- **Local Replacement (지역 교체)**: 프로세스에 할당된 프레임 내에서만 선택

---

## 7. Thrashing (스래싱)

### 7.1 Thrashing (스래싱) 정의
- 페이지 폴트가 과도하게 발생해, CPU가 유용한 작업보다 페이징 처리에 대부분의 시간을 쓰는 상태

### 7.2 증상
- CPU 활용률 감소
- 디스크 I/O 폭증
- 응답 시간 악화
- 처리량 감소

### 7.3 원인
- 프로세스가 필요로 하는 **Working Set (워킹 셋)** 보다 프레임이 부족
- 다중 프로그래밍 정도가 너무 높아 프레임이 분산됨

---

## 8. Working-Set Model (워킹 셋 모델)

### 8.1 Working Set (워킹 셋)
- 시간 창 $Δ$ 동안 참조된 페이지들의 집합
- 워킹 셋 크기는 프로세스가 원활히 실행되기 위한 프레임 수의 추정치가 된다.

### 8.2 Working-Set 기반 제어
- 각 프로세스에 워킹 셋을 수용할 프레임을 제공하려고 한다.
- 전체 워킹 셋 요구가 물리 프레임을 초과하면 일부 프로세스를 줄이거나 스왑아웃이 필요하다.

---

## 9. Page-Fault Frequency (페이지 폴트 빈도) Control

### 9.1 PFF 정책
- 프로세스별 페이지 폴트율을 관찰하여 프레임을 동적으로 조정한다.
- 폴트율이 높으면 프레임을 늘리거나 프로세스 수를 줄인다.
- 폴트율이 낮으면 프레임을 회수해 재분배할 수 있다.

---

## 10. Memory-Mapped Files (메모리 매핑 파일)

### 10.1 Memory-Mapped File (메모리 매핑 파일) 개념
- 파일을 프로세스의 주소 공간에 매핑하여 메모리 접근으로 파일 I/O를 수행한다.
- OS는 페이지 단위로 파일 내용을 적재하고 변경 내용을 반영한다.

### 10.2 장점
- 시스템 콜 기반 I/O보다 프로그래밍 모델이 단순해질 수 있다.
- 공유 파일/공유 라이브러리 구현에 유리하다.
- 여러 프로세스가 동일 파일을 매핑하면 물리 프레임 공유가 가능해질 수 있다.

---

## 11. Summary (요약)
- 가상 메모리는 필요한 페이지만 적재하는 요구 페이징으로 메모리 효율과 다중 프로그래밍 정도를 높인다.
- 페이지 폴트는 디스크 I/O를 수반하므로 폴트율과 교체 정책이 성능을 좌우한다.
- 페이지 교체 알고리즘과 프레임 할당(전역/지역)은 폴트율, 공정성, 성능 변동성에 큰 영향을 준다.
- 스래싱은 워킹 셋 대비 프레임 부족으로 발생하며, 워킹 셋 모델과 PFF 정책으로 제어한다.
- 메모리 매핑 파일은 파일을 주소 공간에 매핑하여 I/O를 메모리 접근처럼 다룬다.
