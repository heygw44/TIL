> HTTP 완벽 가이드 책을 읽고 정리한 내용입니다.

# 목차
- [목차](#목차)
- [HTTP 개관](#http-개관)
  - [HTTP: 인터넷의 멀티미디어 배달부](#http-인터넷의-멀티미디어-배달부)
    - [리소스와 MIME 타입](#리소스와-mime-타입)
    - [URI (Uniform Resource Identifier)](#uri-uniform-resource-identifier)
  - [HTTP 트랜잭션](#http-트랜잭션)
    - [메서드: 서버에게 무엇을 시키는가](#메서드-서버에게-무엇을-시키는가)
    - [상태코드: 결과가 어떠한가](#상태코드-결과가-어떠한가)
  - [메시지 구조](#메시지-구조)
    - [요청 메시지 (Request)](#요청-메시지-request)
    - [응답 메시지 (Response)](#응답-메시지-response)
  - [TCP 커넥션](#tcp-커넥션)
    - [계층 구조](#계층-구조)
    - [접속 과정 (브라우저가 URL을 쳤을 때)](#접속-과정-브라우저가-url을-쳤을-때)
  - [웹의 구성 요소](#웹의-구성-요소)
  - [오늘의 회고](#오늘의-회고)
- [URL과 리소스](#url과-리소스)
  - [URL: 인터넷의 탐색 도구](#url-인터넷의-탐색-도구)
  - [URL 문법](#url-문법)
    - [각 구성요소의 역할](#각-구성요소의-역할)
  - [URL 단축과 상대 URL](#url-단축과-상대-url)
    - [기저(Base) URL](#기저base-url)
    - [상대 경로 해석법](#상대-경로-해석법)
  - [URL 인코딩](#url-인코딩)
    - [안전하지 않은 문자](#안전하지-않은-문자)
    - [이스케이프 문자열](#이스케이프-문자열)
  - [여러가지 스킴](#여러가지-스킴)
  - [오늘의 회고](#오늘의-회고-1)
- [HTTP 메시지](#http-메시지)
  - [메시지의 흐름](#메시지의-흐름)
  - [메시지의 해부](#메시지의-해부)
    - [구성 요소](#구성-요소)
  - [메서드 심화](#메서드-심화)
    - [주요 메서드](#주요-메서드)
    - [안전성과 멱등성](#안전성과-멱등성)
  - [상태 코드 상세](#상태-코드-상세)
  - [헤더 분류](#헤더-분류)
  - [오늘의 회고](#오늘의-회고-2)
- [커넥션 관리](#커넥션-관리)
  - [TCP 커넥션의 이해](#tcp-커넥션의-이해)
    - [TCP 커넥션의 지연 요소](#tcp-커넥션의-지연-요소)
  - [HTTP 커넥션 관리 모델](#http-커넥션-관리-모델)
    - [병렬 커넥션](#병렬-커넥션)
    - [지속 커넥션](#지속-커넥션)
  - [Keep-Alive와 멍청한(Dumb)프락시 문제](#keep-alive와-멍청한dumb프락시-문제)
    - [멍청한 프락시](#멍청한-프락시)
    - [해결책: Proxy-Connection 헤더](#해결책-proxy-connection-헤더)
  - [파이프라인 커넥션](#파이프라인-커넥션)
  - [커넥션 끊기](#커넥션-끊기)
  - [오늘의 회고](#오늘의-회고-3)
- [프록시](#프록시)
  - [프록시란?](#프록시란)
  - [프록시의 두 얼굴: Foward vs Reverse](#프록시의-두-얼굴-foward-vs-reverse)
    - [포워드 프록시 - 클라이언트 대리인](#포워드-프록시---클라이언트-대리인)
    - [리버스 프록시 - 서버 대리인](#리버스-프록시---서버-대리인)
  - [프록시와 헤더](#프록시와-헤더)
  - [X-Forwarded-For (XFF)와 표준화](#x-forwarded-for-xff와-표준화)
    - [Via 헤더](#via-헤더)
  - [HTTPS와 프록시의 딜레마](#https와-프록시의-딜레마)
    - [HTTP CONNECT 메서드 (터널링)](#http-connect-메서드-터널링)
    - [MITM (Man-In-The-Middle) 프록시](#mitm-man-in-the-middle-프록시)
  - [마이크로서비스 시대의 프록시: Service Mesh](#마이크로서비스-시대의-프록시-service-mesh)
  - [오늘의 회고](#오늘의-회고-4)
- [웹 캐시](#웹-캐시)
  - [웹 캐시란?](#웹-캐시란)
  - [캐시 적중/부적중과 성능 지표](#캐시-적중부적중과-성능-지표)
  - [신선도 관리](#신선도-관리)
    - [만료 관련 헤더](#만료-관련-헤더)
    - [기타 Cache-Control 디렉티브](#기타-cache-control-디렉티브)
  - [재검사 기반 캐싱: 조건부 요청과 304](#재검사-기반-캐싱-조건부-요청과-304)
    - [Last-Modified / If-Modified-Since](#last-modified--if-modified-since)
    - [ETag / If-None-Match](#etag--if-none-match)
  - [캐시 전략과 캐시 무력화(Cache busting)](#캐시-전략과-캐시-무력화cache-busting)
    - [캐시 제어 전략](#캐시-제어-전략)
    - [캐시 무력화 방법](#캐시-무력화-방법)
  - [캐시 처리 단계](#캐시-처리-단계)
  - [오늘의 회고](#오늘의-회고-5)
- [HTTP/2.0](#http20)
  - [HTTP/2.0의 등장배경](#http20의-등장배경)
  - [HTTP/2.0 개요: 무엇이 달라졌나](#http20-개요-무엇이-달라졌나)
  - [HTTP/1.1과의 핵심 차이점](#http11과의-핵심-차이점)
    - [프레임 구조](#프레임-구조)
    - [스트림과 멀티 플렉싱](#스트림과-멀티-플렉싱)
    - [헤더 압축](#헤더-압축)
  - [서버 푸시](#서버-푸시)
  - [보안 이슈](#보안-이슈)
  - [오늘의 회고](#오늘의-회고-6)
- [쿠키](#쿠키)
  - [쿠키는 왜 생겼나: 상태 없는 HTTP를 "상태 있게"](#쿠키는-왜-생겼나-상태-없는-http를-상태-있게)
  - [쿠키의 기본 개념과 동작 흐름](#쿠키의-기본-개념과-동작-흐름)
    - [서버가 쿠키를 심는 과정](#서버가-쿠키를-심는-과정)
    - [브라우저가 쿠키를 보내는 과정](#브라우저가-쿠키를-보내는-과정)
  - [쿠키의 구조: 이름 = 값 + 속성들](#쿠키의-구조-이름--값--속성들)
    - [기본 형태](#기본-형태)
    - [주요 속성들](#주요-속성들)
  - [쿠키와 세션 관리](#쿠키와-세션-관리)
    - [세션 ID 기반 패턴](#세션-id-기반-패턴)
    - [쿠키에 직접 상태를 담는 방식](#쿠키에-직접-상태를-담는-방식)
  - [1st-party 쿠키 vs 3rd-party 쿠키 (프라이버시 이슈의 핵심)](#1st-party-쿠키-vs-3rd-party-쿠키-프라이버시-이슈의-핵심)
    - [1st-party 쿠키](#1st-party-쿠키)
    - [3rd-party 쿠키](#3rd-party-쿠키)
  - [쿠키 관련 보안/프라이버시 고려 사항](#쿠키-관련-보안프라이버시-고려-사항)
  - [오늘의 회고](#오늘의-회고-7)
- [보안 HTTP](#보안-http)
  - [왜 보안 HTTP가 필요한가](#왜-보안-http가-필요한가)
  - [보안 HTTP가 제공하는 세 가지 큰 기능](#보안-http가-제공하는-세-가지-큰-기능)
  - [암호학 기초](#암호학-기초)
  - [SSL/TLS와 HTTPS의 관계](#ssltls와-https의-관계)
  - [HTTPS 동작 흐름](#https-동작-흐름)
  - [서버 인증서와 CA(PKI)](#서버-인증서와-capki)
  - [TLS와 HTTP의 경계: 애플리케이션은 그대로](#tls와-http의-경계-애플리케이션은-그대로)
  - [성능 이슈와 최적화 포인트](#성능-이슈와-최적화-포인트)
  - [보안 HTTP가 막아주는 공격 vs 못 막는 공격](#보안-http가-막아주는-공격-vs-못-막는-공격)
    - [막아 주는 것](#막아-주는-것)
    - [못 막는것(또는 부분적)](#못-막는것또는-부분적)
  - [오늘의 회고](#오늘의-회고-8)
- [엔터티와 인코딩](#엔터티와-인코딩)
  - [메시지 vs 엔터티 : 컨테이너 vs 화물](#메시지-vs-엔터티--컨테이너-vs-화물)
  - [Content-Length: 엔터티의 길이](#content-length-엔터티의-길이)
  - [엔터티 요약](#엔터티-요약)
  - [미디어 타입과 charset](#미디어-타입과-charset)
  - [콘텐츠 인코딩: 콘텐츠 자체를 변형](#콘텐츠-인코딩-콘텐츠-자체를-변형)
  - [전송 인코딩과 청크 인코딩](#전송-인코딩과-청크-인코딩)
  - [시간에 따라 바뀌는 인스턴스, 검사기와 신선도](#시간에-따라-바뀌는-인스턴스-검사기와-신선도)
  - [범위 요청과 부분 콘텐츠](#범위-요청과-부분-콘텐츠)
  - [델타 인코딩](#델타-인코딩)
  - [오늘의 회고](#오늘의-회고-9)
- [국제화](#국제화)
  - [언어 태그와 HTTP](#언어-태그와-http)
    - [언어 태그란?](#언어-태그란)
    - [HTTP에서 언어 태그가 쓰이는곳](#http에서-언어-태그가-쓰이는곳)
    - [언어 태그 + 캐시/콘텐츠 네고시에이션](#언어-태그--캐시콘텐츠-네고시에이션)
  - [국제화된 URI](#국제화된-uri)
    - [기본 문제의식: URI는 원래 ASCII만](#기본-문제의식-uri는-원래-ascii만)
    - [HTTP에서 실제로 쓰이는 방식](#http에서-실제로-쓰이는-방식)
    - [국제화 도메인 이름(IDN) 관련](#국제화-도메인-이름idn-관련)
  - [기타 고려사항](#기타-고려사항)
    - [언어 vs 로케일 vs 스크립트](#언어-vs-로케일-vs-스크립트)
    - [정렬, 검색, 비교](#정렬-검색-비교)
    - [글꼴, 표기 방향(Bidi), UI 렌더링](#글꼴-표기-방향bidi-ui-렌더링)
    - [캐시·프록시·네고시에이션과의 상호작용](#캐시프록시네고시에이션과의-상호작용)
  - [오늘의 회고](#오늘의-회고-10)
- [내용 협상과 트랜스코딩](#내용-협상과-트랜스코딩)
  - [내용 협상이란? 한 URL, 여러 "표현" 중에서 고르기](#내용-협상이란-한-url-여러-표현-중에서-고르기)
  - [내용 협상 기법: 세가지 방식](#내용-협상-기법-세가지-방식)
  - [클라이언트 주도 협상](#클라이언트-주도-협상)
    - [동작 흐름](#동작-흐름)
    - [장점](#장점)
    - [단점](#단점)
  - [서버 주도 협상](#서버-주도-협상)
    - [기본 아이디어](#기본-아이디어)
  - [내용 협상 헤더](#내용-협상-헤더)
  - [품질값(q-value): 선호도 스코어](#품질값q-value-선호도-스코어)
    - [의미](#의미)
    - [왜 필요한가?](#왜-필요한가)
  - [그 외의 헤더들 및 정보](#그-외의-헤더들-및-정보)
---

# HTTP 개관

## HTTP: 인터넷의 멀티미디어 배달부
HTTP는 단순한 텍스트 전송규약이 아닌, 전 세계 웹 서버와 클라이언트 간의 신뢰성있는 데이터 전송을 보장하는 애플리케이션 계층 프로토콜이다.

### 리소스와 MIME 타입
- 리소스: 웹에 존재하는 모든 컨텐츠(파일, 게이트웨이 프로그램, 검색 결과 등)을 총칭
- MIME 타입:
  - 원래 이메일 전송을 위해 설계되었으나 HTTP에서도 사용된다.
  - 서버는 데이터 전송시 `Content-Type` 헤더를 통해 데이터의 형식을 알려준다.

### URI (Uniform Resource Identifier)
리소스의 고유 식별자. URI는 URL과 URN으로 나뉜다.
- URL(Locator): 리소스의 위치를 지정. 가장 일반적인 형태.
  - 구조: `<스킴>://<서버주소>:<포트>/<경로>`
  - 예: `http://www.naver.com:80/index.html`
- URN(Name): 리소스의 이름을 지정. 위치가 변해도 이름은 유지.
  - 예: `urn:isbn:978-0-123-45678-9`(아직 널리 쓰이지는 않는다.)

---

## HTTP 트랜잭션
HTTP 트랜잭션은 요청(Request)와 응답(Response) 결과로 구성된다.

### 메서드: 서버에게 무엇을 시키는가
모든 서버가 모든 메서드를 지원하는것은 아님.
- GET: 리소스를 서버에서 클라이언트로 가져온다. (가장 많이 사용)
- POST: 클라이언트가 서버로 데이터를 보낸다. (입력 폼 전송 등)
- PUT: 서버에 문서를 저장하거나 덮어쓴다.
- DELETE: 서버에서 리소스를 삭제한다.
- HEAD: GET과 같지만, 본문(Body) 없이 헤더만 가져온다. (리소스 존재 여부 확인, 변경 여부 검사 시 유용)

### 상태코드: 결과가 어떠한가
세 자리 숫자로 구성되며, 함께 오는 사유 구문은 사람이 이해하기 위한 것.
- 100-199: 정보 (Information)
- 200-299: 성공 (Success) -> 200 OK
- 300-399: 리다이렉션 (Redirection) -> 302 Found (다른 위치로 가라)
- 400-499: 클라이언트 에러 (Client Error) -> 404 Not Found (네가 요청한 게 없다)
- 500-599: 서버 에러 (Server Error) -> 500 Internal Server Error (서버 내부 문제)

---

## 메시지 구조
HTTP 메시지는 인간이 읽을 수 있는 텍스트로 되어있다.

### 요청 메시지 (Request)
1. 시작줄: `<메서드> <URL> <버전>`
   - 예: `GET /index.html HTTP/1.1`
2. 헤더: 키: 값 형태의 메타 정보.(빈 줄로 헤더의 끝을 알린다.)
3. 본문: POST 요청시 보낼 데이터

### 응답 메시지 (Response)
1. 시작줄: `<버전> <상태코드> <사유구문>`
   - 예: `HTTP/1.1 200 OK`
2. 헤더: 컨텐츠 타입, 길이, 서버 정보 등.
3. 본문: 실제 데이터

---

## TCP 커넥션
HTTP는 네트워크 통신의 핵심인 데이터 전송을 TCP/IP에 맡긴다.

### 계층 구조
1. HTTP (애플리케이션 계층): 무엇을 보낼지 결정.
2. TCP (전송 계층): 데이터를 패킷 단위로 쪼개고, 순서대로, 에러 없이 도착하도록 보장.
3. IP (네트워크 계층): 목적지 컴퓨터(IP 주소)까지 패킷을 배달.
4. 네트워크 인터페이스: 실제 물리적인 선.

### 접속 과정 (브라우저가 URL을 쳤을 때)
1. 브라우저가 URL에서 호스트명(www.google.com)을 추출한다.
2. 브라우저가 DNS 서버에 호스트명의 IP 주소를 물어본다
3. IP 주소를 얻으면, 포트 번호(HTTP는 기본 80)를 확인한다.
4. 브라우저가 해당 IP:Port로 TCP 커넥션을 맺는다.
5. 브라우저가 HTTP 요청 메시지를 보낸다.
6. 서버가 HTTP 응답 메시지를 보낸다.
7. 커넥션을 끊는다 (HTTP/1.1의 Keep-Alive 설정에 따라 유지될 수도 있음).

---

## 웹의 구성 요소
인터넷은 단순한 1:1 연결이 아니라 중간에 수많은 중개자가 존재한다.
1. 프락시(Proxy): 클라이언트와 서버 사이에서 HTTP 메시지를 정리하거나, 보안 검사를 수행하는 중개 서버.
2. 캐시(Cache): 자주 요청받는 리소스의 사본을 저장해두는 특별한 종류의 프락시. 서버 부하를 줄이고 응답 속도를 높인다.
3. 게이트웨이(Gateway): 다른 프로토콜을 HTTP로 변환해준다.
   - 예: HTTP 트래픽을 받아서 SQL 쿼리로 변환해 DB에 접속하는 서버.
4. 터널(Tunnel): HTTP 메시지를 엿보지 않고 그대로 전달만 해주는 파이프.
   - 예: SSL/TLS(HTTPS) 통신 시 암호화된 데이터를 통과시킬 때 사용.
5. 에이전트(Agent): HTTP 요청을 발생시키는 주체.
    - 대표적인 예: 웹 브라우저, 웹 크롤러(스파이더).

---

## 오늘의 회고
1. 단순함의 미학: HTTP 메시지는 바이너리(0과 1)가 아니라 텍스트로 되어 있다. 이는 디버깅을 쉽게 하고 프로토콜의 확장을 용이하게 했다는 점이 인상 깊다. (Telnet으로 직접 요청을 날려볼 수 있는 이유)
2. 상태 코드의 분류: 단순히 에러가 났다가 아니라, 4xx는 내(클라이언트) 잘못, 5xx는 서버 잘못이라는 책임 소재를 명확히 숫자로 구분한 설계가 효율적이다.
3. 계층의 분리: HTTP는 '어떻게 보낼지(Routing)'를 고민하지 않는다. 그건 TCP/IP가 한다. HTTP는 오직 '무엇을 보낼지'에만 집중한다. 이 추상화가 웹의 폭발적 성장을 가능하게 했다.

---
# URL과 리소스

## URL: 인터넷의 탐색 도구
URL은 브라우저가 리소스를 찾고, 사용하고, 가져오기 위해 필요한 모든 정보를 담고 있는 표준화된 이름이다.
- 역할: 리소스가 어디에 있고, 어떻게 접근해야하는지 알려준다.
- 구성: `스킴(Scheme)` + `호스트(Host)` + `경로(Path)`

---

## URL 문법
URL은 생각보다 복잡한 구조를 가질 수 있다. 일반적인 포맷은 다음과 같다.
`py <스킴>://<사용자이름>:<비밀번호>@<호스트>:<포트>/<경로>;<파라미터>?<질의>#<프래그먼트>`

### 각 구성요소의 역할
- 스킴(Scheme): 사용할 프로토콜을 정의.(대소문자 구별x, 보통 소문자 사용)
   - 예: `http, htpps, mailto, ftp` 등
   - 구분자: 뒤에 `://`가 붙는다.
- 사용자 이름 & 비밀번호: 데이터 접근시 인증이 필요한 경우 사용.
  - 예: `ftp://anonymous:my_passwd@ftp.prep.ai.mit.edu`
  - 당연하게도 비밀번호를 URL에 평문으로 넣는것은 보안에 취약하기 때문에 거의 사용x
- 호스트 & 포트: 리소스를 가진 서버의 위치.
  - 호스트: 도메인명`www.google.com`또는 IP 주소.
  - 포트: 서버가 열고 있는 문. 80, 443 등
- 경로(Path): 서버내 리소스의 계층적 위치 `/`문자로 구분한다.
- 파라미터(Parameters): 애플리케이션에 필요한 추가 정보 전달. `;`문자로 구분한다.
  - 예: `/hammers;sale=false/index.html;graphics=true`
  - 참고: 경로의 각 세그먼트마다 파라미터가 붙을 수 있다.
- 질의 문자열(쿼리문): 데이터베이스나 게이트웨이에 파라미터 전달.
  - 예: `?item=12731&color=blue`
  - 구분자 `?`로 시작하며, `&`로 키-값 쌍을 나눈다.
- 프래그먼트(Fragment): 리소스 내부의 특정 조각(섹션)을 가리킨다.
  - 예: `#section-2`
  - 핵심: 프래그먼트는 서버로 전송되지 않는다. 브라우저(클라이언트)가 전체 문서를 받은 뒤 해당 위치로 이동하는 용도로만 사용.

---

## URL 단축과 상대 URL
항상 전체 URL(절대)을 다 쓰는 것은 비효율적이다. HTML 내에서는 상대 URL을 많이 사용한다.

### 기저(Base) URL
상대 URL을 해석하려면 기준이 되는 기저 URL이 필요하다.
1. 리소스 자체의 URL: 현재 보고 있는 페이지의 URL이 기저.
2. 명시적 설정: HTML의 `<base href="...">` 태그로 기저 URL을 고정할 수 있다.

### 상대 경로 해석법
유닉스/리눅스의 파일 시스템 경로와 유사.
- `./`:현재 디렉터리
- `../`: 상위 디렉터리
- `/`로 시작: 도메인 루트(Root)에서 시작
- 예) 기저가 `http://www.a.com/b/c/d.html` 일 때,
  - `e.html` -> `http://www.a.com/b/c/e.html`
  - `/f.html` -> `http://www.a.com/f.html`
---

## URL 인코딩
컴퓨터는 이진 데이터를 다루지만, URL은 안전한 정송을 위해 ASCII 문자 집합만을 사용해야함. 따라서 안전하지 않는 문자는 인코딩해서 사용해야 한다.

### 안전하지 않은 문자
- 출력 불가능한 문자: 제어 문자 등.
- 예약된 문자: URL에서 특별한 의미로 이미 사용중인 문자들 `(/, :, ?, @, & 등)`. 이들을 문자 그대로 데이터로 쓰고 싶다면 인코딩해야 한다.
- 비 ASCII 문자: 한글, 일본어 등 영어 이외의 문자.

### 이스케이프 문자열
안전하지 않은 문자를 `%` + `16진수 두 자리(Hex)`로 바꾼다.
- **스페이스(공백):** ASCII 32 -> %20
- **~ (물결표):** ASCII 126 -> %7E
- **한글:** UTF-8 바이트 값을 각각 %로 변환.

---

## 여러가지 스킴
- http: 일반적인 웹 통신.
- https: SSL/TLS로 암호화된 안전한 http.
- mailto: 이메일 보내기. (예: `mailto:jo@jo.com`)
- ftp: 파일 전송 프로토콜.
- rtsp: 실시간 스트리밍 프로토콜.
- file: 로컬 컴퓨터의 파일에 접근.

---

## 오늘의 회고
1. 프래그먼트(#)의 비밀: # 뒤의 내용은 서버 요청 로그에 남지 않는다는 점이 중요하다. 요즘 SPA(Single Page Application)에서 라우팅을 할 때 HashRouter를 쓰면 서버 설정 없이도 페이지 이동처럼 보이는 이유가 바로 이것이다.
2. 인코딩의 중요성: 개발하다 보면 검색어 파라미터에 특수문자(& 등)가 들어가서 쿼리 스트링이 깨지는 경우가 있다. 이때 반드시 encodeURIComponent 같은 함수로 인코딩을 해줘야 함을 이론적으로 재확인했다.
3. URL의 미래와 한계: URL은 리소스가 옮겨지면 링크가 깨지는(Link Rot) 문제가 있다. 이를 해결하기 위해 URN(이름)이 나왔지만, 인프라 비용과 표준화 문제로 여전히 URL이 지배적이라는 현실.

---

# HTTP 메시지

## 메시지의 흐름
HTTP 메시지는 강물 처럼 흐름이 존재한다.

- 인바운드 vs 아웃바운드
  - 트랜잭션 방향을 기준으로 한다.
  - 메시지가 원 서버로 향하면 인바운드.
  - 메시지가 사용자 에이전트로 돌아오면 아웃바운드.
- 다운 스트림
  - 모든 메시지(요청이든 응답이든)는 다운스트림으로 흐른다.
  - 발송자 -> 수신자 방향이 물이 흐르는 방향이다.(거꾸로 거슬러 올라가는 메시지는 존재하지않는다.)

---

## 메시지의 해부
HTTP 메시지는 세 부분으로 나뉜다. 엄격한 규칙은 **CRLF(캐리지 리턴 + 개행)**으로 구분된다는 점이다.

`py <시작줄> (CRLF) <헤더> (CRLF) <빈 줄> (CRLF) --> 헤더의 끝을 알리는 매우 중요한 경계선 <본문>`

### 구성 요소
- 시작줄: 이것이 어떤 메시지인지 정의.
  - 요청: `<메서드> <URL> <버전> (예: GET /home HTTP/1.1)`
  - 응답: `<버전> <상태코드> <사유구문> (예: HTTP/1.1 200 OK)`
- 헤더: 속성 정보. `(예: Content-Type: text/html)`
- 본문: 페이로드. 이미지, 비디오, HTML 문서, 텍스트 등. 본문이 없을수도 있다.

---

## 메서드 심화
단순히 동작을 지시하는 것을 넘어, 안전성과 멱등성이란 속성을 이해하는것이 핵심.

### 주요 메서드
- GET: 리소스 요청.
- HEAD: 리소스의 헤더만 요청. (본문은 안 옴).
  - 용도: 리소스가 살아있는지, 변경되었는지(Last-Modified), 타입이 무엇인지 미리 확인할 때 효율적.
- POST: 서버에 입력 데이터 전송. (보통 처리 주체는 서버의 게이트웨이 프로그램).
- PUT: 리소스를 생성하거나, 있으면 덮어씌움(Update).
- DELETE: 리소스 삭제.
- TRACE: 루프백(Loopback) 테스트.
  - 클라이언트가 보낸 요청이 프락시들을 거치며 어떻게 변조되는지 서버가 그대로 반송해서 보여줌. (디버깅용)
- OPTIONS: 서버가 특정 리소스에 대해 어떤 메서드를 지원하는지 물어봄.

### 안전성과 멱등성
1. 안전한 메서드: `GET, HEAD`
   - 서버의 상태를 바꾸지 않는다(Read Only).
   - 크롤러가 막 호출해도 서버에 영향을 주지 않아야한다.
2. 멱등성:
   - 연산을 한 번 하든, 백 번 하든 결과가 똑같은 성질.
   - 멱등함: `GET, PUT, DELETE`
     - `PUT`: 같은 내용으로 100번 덮어써도, 결과물은 그 내용 하나이다.
     - `DELETE`: 한 번 삭제하나, 삭제된걸 또 삭제 요청하나 삭제된 상태는 같다.
  - 멱등하지 않음: `POST`
    - 게시글 작성 버튼을 100번 누르면 게시글이 100개 생긴다. (따라서 결제 페이지 등에서 중복 전송 방지가 중요.)
---

## 상태 코드 상세
상태 코드는 클라이언트 소프트웨어(브라우저)가 처리하는 기준이고, 사유 구문(Reason Phrase)은 오직 사람을 위한 설명이다.

- 100 Continue: (1xx) 클라이언트가 본문을 보내기 전, 헤더만 먼저 보내서 "이거 보내도 돼?" 물어볼 때 사용.
- 200 OK: (2xx) 성공. 가장 일반적.
- 301 Moved Permanently: (3xx) 리소스가 영원히 이사 감. 브라우저는 북마크를 갱신해야 함.
- 302 Found: (3xx) 리소스가 잠깐 이사 감. (대부분의 리다이렉트).
- 304 Not Modified: (3xx) 조건부 요청 시, "네가 가진 캐시랑 똑같으니 그거 써라"는 뜻. (본문 없음, 대역폭 절약).
- 401 Unauthorized: (4xx) 인증 필요 (로그인 해라).
- 403 Forbidden: (4xx) 서버가 요청을 거부함 (권한 없음, 파일 숨김 등).
- 405 Method Not Allowed: (4xx) 해당 URL에 그 메서드(예: DELETE)는 못 쓴다.
- 502 Bad Gateway: (5xx) 프락시나 게이트웨이가 업스트림 서버로부터 이상한 응답을 받음.

---

## 헤더 분류
헤더는 어디에 쓰이느냐에 따라 5가지로 나뉜다.
1. 일반 헤더 (General): 요청/응답 양쪽에 모두 쓰임. (예: Date, Connection)
2. 요청 헤더 (Request): 클라이언트 정보나 선호도. (예: User-Agent, Accept-Language)
3. 응답 헤더 (Response): 서버 정보. (예: Server, Retry-After)
4. 엔터티 헤더 (Entity): 본문(Payload)에 대한 설명. 본문이 없어도 있을 수 있음. (예: Content-Type, Content-Length)
5. 확장 헤더 (Extension): 표준에 없지만 개발자가 임의로 만든 헤더. (과거엔 X-를 붙였으나 요즘은 안 붙이는 추세)

---

## 오늘의 회고
1. 빈 줄(CRLF)의 역할: 헤더와 본문을 구분하는 것이 고작 '빈 줄' 하나라는 점이 HTTP의 단순함을 보여준다. 하지만 코딩할 때 이 빈 줄을 빠뜨리면 서버는 헤더가 계속되는 줄 알고 무한 대기할 수 있다.
2. 멱등성의 실무적 중요성: 네트워크 오류로 패킷이 유실됐을 때, 클라이언트가 자동으로 재시도(Retry) 해도 되는지 판단하는 기준이 바로 멱등성이다. POST 요청이 실패했을 때 함부로 재전송하면 중복 결제가 될 수 있으니 조심해야 한다는 원리를 깨달았다.
3. 304 Not Modified의 경제학: 이 코드는 본문 데이터를 보내지 않음으로써 인터넷 트래픽을 어마어마하게 절약해주는 일등 공신이다. 캐시 최적화의 핵심이다.

---                 

# 커넥션 관리

## TCP 커넥션의 이해
HTTP 메시지는 반드시 TCP 커넥션을 맺은 이후에 데이터를 보낼 수 있다. 따라서 HTTP 성능은 TCP 성능에 크게 좌우된다.

### TCP 커넥션의 지연 요소
웹 브라우저가 느리게 느껴지는 경우 대부분 지연 때문인 경우가 많다.
- TCP 핸드셰이크 지연:
  - 새로운 연결을 맺을 때 마다 `SYN` -> `SYN+ACK` -> `ACK`의 3-way handshake가 필요하다. 작은 데이터를 보낼 때도 이 과정이 필수라 오버헤드가 크다.
- TCP 느린 시작:
  - TCP는 처음에는 패킷을 천천히 보내다가 성공하면 속도를 높인다. (혼잡 제어)
  - 새로 맺은 커넥션은 튜닝되지 않아 속도가 느리다. 이미 튜닝된 커넥션을 사용하는게 중요하다.
- 네이글 알고리즘:
  - 작은 패킷 여러개을 모아서 한번에 보낸다. 효율적이지만, HTTP 처럼 요청-응답이 즉시 필요한 경우 지연을 유발한다.(HTTP는 `TCP_NODELAY`로 끈다.)
- TIME_WAIT 누적
  - 커넥션을 끊은 쪽에서 일정 시간 동안 포트를 점유하고 있는다. 커넥션을 너무 자주 맺고 끊으면 가용 포트가 고갈될 수 있다.

---

## HTTP 커넥션 관리 모델
초기 HTTP부터 현재까지 커넥션을 효율적으로 사용하기 위해 모델이 진화.

### 병렬 커넥션
- 방식: 브라우저가 여러 개의 TCP 커넥션(보통 6개)을 동시에 맺어 여러 이미지나 파일을 한꺼번에 내려받는다.
- 장점: 사용자가 보기에 페이지가 빨리 뜨는 것처럼 느껴진다.
- 단점: 서버 메모리를 많이 잡아먹고, 각 커넥션마다 핸드셰이크/느린 시작 비용이 발생한다.

### 지속 커넥션
- 방식: 처리가 완료된 커넥션을 끊지 않고, 계속 연결해 둔 상태로 다음 요청을 보낸다.
- 장점:
  - 핸드셰이크 시간 절약.
  - TCP "느린 시작" 단계를 건너뛰고 튜닝된 속도로 전송 가능.
- 종류:
  - HTTP/1.0+ Keep-Alive: 실험적인 모델. 헤더에 Connection: Keep-Alive를 명시해야 함.
  - HTTP/1.1 Persistent: 기본적으로 지속 커넥션. 끊으려면 Connection: close를 명시해야 함.

---

## Keep-Alive와 멍청한(Dumb)프락시 문제
HTTP/1.0의 `Keep-Alive` 설계에는 치명적인 결함이 있었다.

### 멍청한 프락시
1. 클라이언트가 `Connection: Keep-Alive` 헤더를 보내며 연결 유지를 요청함.
2. 중간에 있는 오래된 프락시는 이 헤더의 의미를 모른다.
3. 프락시는 이 헤더를 그대로 서버에 전달(Relay) 해버린다. (Hop-by-Hop 헤더는 전달하면 안 되는데 규칙을 모름).
4. 서버는 프락시가 연결 유지를 원하는 줄 알고 동의함.
5. 결과: 프락시는 통신이 끝난 줄 알고 기다리고(Hung), 서버는 프락시의 다음 요청을 기다리고, 클라이언트는 응답을 기다리는 무한 대기(Hang) 상태에 빠진다.

### 해결책: Proxy-Connection 헤더
이 문제를 피하기 위해 브라우저는 비표준인 `Proxy-Connection` 헤더를 사용하기도 한다. 멍청한 프락시는 이걸 그대로 넘기지만, 영리한 프락시는 이걸 보고 `Connection: Keep-Alive`로 바꿔서 서버에 보낸다.

---

## 파이프라인 커넥션
HTTP/1.1에서 지속 커넥션을 더 효율적으로 쓰기 위해 제안된 기술.

- 방식: 요청을 보내고 응답을 기다리지 않고, 연속해서 요청을 쏜다. (요청1 -> 요청2 -> 요청3 ... 응답1 -> 응답2 -> 응답3)
- 제약:
  - 응답은 반드시 요청 순서대로 와야 한다.
  - 중간에 하나가 막히면 뒤에 것도 다 막힌다 (HOL Blocking 문제).
  - 실무: 구현이 복잡하고 버그가 많아 실제로는 잘 안 쓰임 (HTTP/2에서 멀티플렉싱으로 해결됨).

---

## 커넥션 끊기
영원한 커넥션은 없다. 언제 어떻게 끊느냐가 중요하다.

- 우아한 종료 (Graceful Close):
  - TCP는 양방향 통신이다. 입력 채널과 출력 채널이 따로 있다.
  - 갑자기 close()를 부르면 전송 중이던 데이터가 유실될 수 있다.
  - 자신의 출력 채널만 먼저 닫고(shutdown), 상대방의 데이터가 다 올 때까지 기다리는 것이 안전하다.
- Content-Length의 중요성: 지속 커넥션에서는 메시지의 끝을 알아야 한다. Content-Length 값이 틀리면 커넥션은 다음 데이터를 하염없이 기다리거나, 다음 요청을 데이터로 착각하게 된다.

---

## 오늘의 회고
1. "이미 맺어진 커넥션이 가장 빠르다": 웹 최적화의 제1원칙은 불필요한 바이트를 줄이는 것이지만, 제2원칙은 기존 커넥션을 재활용하는 것이다. TCP 3-way handshake 비용이 생각보다 비싸다는 것을 깨달았다.
2. Hop-by-Hop 헤더의 위험성: Connection 헤더는 딱 나와 내 옆의 녀석(프락시) 사이에서만 유효하고 삭제되어야 한다. 이를 어기면 전체 통신이 마비될 수 있다는 '멍청한 프락시' 시나리오가 매우 흥미롭다.
3. HTTP/1.1의 위대함: HTTP/1.1이 단순히 기능 추가가 아니라, 1.0의 커넥션 관리 문제(성능 저하)를 해결하기 위해 '지속 커넥션'을 기본(Default)으로 채택했다는 점이 프로토콜 설계의 진화를 보여준다.

---

# 프록시

## 프록시란?

프록시는 클라이언트와 서버 사이의 중개자이다. HTTP 요청을 받아서 다른 서버로 전달하고, 응답을 받아 다시 클라이언트에게 돌려준다.

- 과거의 프록시: 주로 인터넷 속도를 높이기 위한 캐시 공유나, 사내망 접속 통제용으로 사용.
- 현대의 프록시: 보안, 부하 분산, 익명화, 트래픽 분산의 핵심 인프라.

---

## 프록시의 두 얼굴: Foward vs Reverse

책에서는 두 개념을 설명하지만, 현대 아키텍쳐에서는 리버스 프록시의 비중이 압도적으로 커졌다.

### 포워드 프록시 - 클라이언트 대리인
- 위치: 클라이언트 앞단에 위치.
- 역할: 클라이언트를 감춰준다.(서버는 요청이 프록시에서 온 줄 안다.)
- 용도:
  - 검열 우회 및 익명성
  - 사내 보안
  - 캐싱: (ISP 차원에서 대역폭 절약 - 현재는 CDN으로 대체)

### 리버스 프록시 - 서버 대리인
- 위치: 웹 서버 앞단에 위치.
- 역할: 진짜 서버를 감춘다.(클라이언트는 프록시가 서버인줄 알고 요청.)
- 대표적 소프트웨어: Nginx, HAProxy, AWS ALB, Traefik.
- 현대적 용도:
  - 로드 밸런싱: 들어오는 요청을 여러대의 뒷단 서버로 분산시킨다.
  - 보안(WAF): 디도스 공격을 막거나 SQL 인젝션을 필터링한다.
  - TLS 종단: 암호화/복호화 부하를 프록시가 담당하고, 뒷단 서버와는 가벼운 HTTP로 통신한다.

---

## 프록시와 헤더
프록시를 거치면 클라이언트 정보가 세탁될 수 있다. 이를 방지하기 위한 헤더 규약이 존재.

## X-Forwarded-For (XFF)와 표준화
프록시르 통과할 때마다 원본 IP가 사라진다. 이를 보오나하기 위해 헤더를 추가한다.
- 과거/관습: `X-Forwarded-For: <Client-IP>, <Proxy1-IP>, ...`
  - 이 헤더를 확인하지 않으면 서버는 모든 요청이 로드 밸런서 IP에서 온 것으로 착각한다.
- 최신 표준(RFC 7239): `Forwarded` 헤더
  - `Forwarded: for=192.0.2.60;proto=http;by=203.0.113.43` 형식으로 더 상세한 정보를 담는다. (하지만 여전히 실무에선 XFF가 더 많이 쓰임)

### Via 헤더
- 메시지가 거쳐간 프록시들의 경로를 기록한다. 무한 루프 방지용으로 사용.

---

## HTTPS와 프록시의 딜레마

책에서는 간단히 다루지만, 현재 웹의 90% 이상은 HTTPS다. 프락시는 암호화된 데이터를 어떻게 처리할까?

### HTTP CONNECT 메서드 (터널링)
- 클라이언트가 프락시에게 "나 저 서버랑 비밀 얘기(HTTPS) 할 거니까, 내용 보지 말고 파이프만 연결해줘"라고 요청한다.
- 프록시는 단순히 바이트를 퍼 나르기만 한다(Blind Relay). 내용을 볼 수 없다.

### MITM (Man-In-The-Middle) 프록시
- 회사 보안 장비나 개발용 프록시(Charles, Fiddler)는 HTTPS 내용을 뜯어봐야 한다.
- 원리: 프록시가 가짜 인증서를 만들어서 클라이언트에게 주고, 자기가 서버인 척한다. 클라이언트가 이를 신뢰(인증서 설치)해야만 가능하다.

---

## 마이크로서비스 시대의 프록시: Service Mesh

책에는 없지만 6장의 개념이 현대적으로 확장된 개념이다.

- 사이드카 패턴: 모든 애플리케이션 컨테이너 옆에 작은 프록시(Envoy 등)를 하나씩 붙인다.
- 역할:
  - 서비스 간 통신(Service-to-Service)을 프록시가 가로채서 처리한다.
  - 트래픽 제어: A버전 90%, B버전 10% 전송 (카나리 배포).
  - 서킷 브레이커: 뒷단 서비스가 죽으면 프록시 선에서 차단하여 장애 확산 방지.
  - 관측 가능성(Observability): 누가 누구를 호출했는지 자동으로 추적.

---

## 오늘의 회고
1. "진짜 IP"를 찾는 법: 백엔드 개발 시 `request.getRemoteAddr()`를 쓰면 사용자가 아닌 로드 밸런서의 IP가 찍힌다는 것을 명심해야 한다. 반드시 `X-Forwarded-For`의 첫 번째 값을 파싱하거나, 프레임워크의 신뢰할 수 있는 프록시 설정을 켜야 한다.
2. 프록시는 아키텍처의 유연함이다: 서버 구성을 바꿀 때 클라이언트를 수정할 필요 없이, 앞단의 리버스 프록시(Nginx 등) 설정만 바꾸면 된다는 점이 유지보수의 핵심이다.
3. TLS Offloading의 중요성: 암호화는 CPU를 많이 쓴다. 비싼 웹 서버 대신 앞단의 프록시 장비가 이를 전담하게 하여 웹 서버의 부하를 줄이는 전략이 대규모 서비스의 기본임을 알게 되었다.

---

# 웹 캐시

## 웹 캐시란?
- 정의: 자주 요청되는 리소스의 사본을 저장해 두었다가, 다음 요청부터는 원 서버가 아니라 캐시에서 바로 응답해 주는 HTTP 장치(브라우저 캐시, 프록시 캐시, CDN 등 포함).
- 효과
  - 불필요한 데이터 전송 감소 → 네트워크 비용 절감
  - 네트워크 병목 완화 → 체감 속도 개선
  - 원 서버 부하 감소 → 더 많은 요청을 처리 가능
  - 거리·지연 감소 → 지리적으로 먼 서버라도 빠르게 응답 가능

---

## 캐시 적중/부적중과 성능 지표
- 캐시 적중: 요청한 리소스가 캐시에 존재하여, 원 서버에 가지 않고 캐시에서 바로 응답.
- 캐기 부적중: 캐시에 리소스가 없거나, 쓸 수 없는 상태라서 원 서버에 요청.
- 중요 지표:
  - hit ratio: 전체 요청 중 캐시 적중 비율
  - byte hit ratio: 전체 전송 바이트 중 캐시가 대신 처리한 비율
  → 단순 응답 속도뿐만 아니라 바이트 기준으로도 캐시 효과를 보는것이 중요하다.

---

## 신선도 관리
서버가 언제까지 이 리소스를 믿어도 되는지를 클라이언트/캐시에게 알려주는 방식이다.

### 만료 관련 헤더
- Cache-Control: `max-age=초`
  - 문서가 생성된 시점부터 “최대 나이”를 정의
  - 예: `Cache-Control: max-age=31536000` → 1년 동안 신선한 리소스
- Expires: 날짜
  - 이 날짜/시간까지 유효함을 명시(HTTP/1.0 방식)
  - 예: `Expires: Wed, 21 Oct 2025 07:28:00 GMT`
- Age 헤더
  - 캐시가 응답할 때, 이 사본이 얼마나 오래되었는지(초 단위)를 알려줌

### 기타 Cache-Control 디렉티브
- `no-store`: 민감한 정보. 아예 디스크/메모리에 저장 금지.
- `no-cache` : 캐시에 저장은 할 수 있지만, 쓰기 전에 반드시 원 서버 재검사 필요.
- `must-revalidate` : 만료된 후에는 반드시 원 서버와 재검사해야 함.
- `public / private`
  - `public`: 중간 캐시(프록시)에도 저장해도 됨.
  - `private`: 브라우저 같은 개인 캐시에만 저장.

프론트/백엔드 개발시 기본적으로 `Cache-Control` 조합을 의식적으로 설계해야 한다.

---

## 재검사 기반 캐싱: 조건부 요청과 304
만료 시간만으로는 부족할 때, 바뀌었는지 확인만 하는 방식.

### Last-Modified / If-Modified-Since
- 서버 응답 예:
  - `Last-Modified: Wed, 21 Oct 2025 07:28:00 GMT`
- 다음 요청 시 브라우저가:
  - `If-Modified-Since: Wed, 21 Oct 2025 07:28:00 GMT`
- 서버 동작:
  - 변경 없음 → `304 Not Modified` + 헤더만 전송 (본문 없음)
  - 변경됨 → `200 OK` + 새로운 본문 전송

본문을 다시 받지 않고도 최신 여부만 확인 하는것이 포인트이다.

### ETag / If-None-Match
- ETag: 리소스 버전에 대한 고유 식별자(해시처럼 생각)
  - 응답: `ETag: "v1.2.3-abcd"`
- 다음 요청 시:
  - `If-None-Match: "v1.2.3-abcd"`
- 서버:
  - 동일 버전이면 `304 Not Modified`
  - 다르면 새 리소스 + 새 ETag

시간기반보다 더 정밀하게 변경 여부를 판단 가능하다.
실제 서비스에서 가장 많이 사용하는 패턴이다. `ETag + Cache-Control.`

---

## 캐시 전략과 캐시 무력화(Cache busting)

### 캐시 제어 전략
- 정적 자원(CSS, JS, 이미지)
  - 파일명에 해시 붙이고, `Cache-Control: max-age=1년, public, immutable` 같이 강하게 캐시
  - 변경 시 파일명(해시)이 바뀌므로, 자연스럽게 캐시 무효화
- HTML 문서
  - 상대적으로 짧은 `max-age` 또는 `no-cache + 조건부 요청`으로 신선도 유지
- API 응답
  - 변경 빈도, 데이터 민감도에 따라 `no-store, no-cache, max-age` 등 선택

### 캐시 무력화 방법
- 쿼리 스트링 버전: `/app.js?v=123`
- 파일명에 해시: `/app.1a2b3c.js`
- 응답 헤더로 아예 캐시를 막기: `Cache-Control: no-store`

---

## 캐시 처리 단계
캐시가 요청을 받았을 때 대략 이런 흐름으로 동작한다.:

1. 요청 도착 → 캐시 키 계산(URL, Host, Vary 헤더 등)
2. 로컬 캐시에서 엔트리 검색
3. 만료 여부/정책 확인
   - 신선하면 → 바로 응답(cache hit)
   - 신선하지 않으면 → 원 서버에 조건부 요청(If-Modified-Since / If-None-Match)
4. 원 서버 응답
   - 304면 → 캐시 헤더만 갱신 후 캐시에 있는 본문으로 응답
   - 200이면 → 새 리소스를 저장하고 응답
5. 로깅, 통계( hit ratio, latency 등)

단순히 저장해놨다가 요청이 오면 주는것이아니라 프로토콜단에서 꽤 복잡한 정책/과정을 통해 진행된다.

---

## 오늘의 회고
- 캐싱은 **속도 최적화뿐 아니라 비용/부하/지연까지 동시에 줄여주는 기본기**다.
- Cache-Control, Expires, Age로 **신선도(언제까지 믿을 수 있는지)** 를 표현한다.
- Last-Modified / If-Modified-Since, ETag / If-None-Match로 변경 여부를 재검사해 낭비를 줄인다.
- 정적 파일은 **파일명 버전 + 강한 max-age 조합**이 사실상 표준 패턴이다.
- 캐시 정책은 “어디에 캐시가 있는지(브라우저/프록시/CDN/리버스 프록시)”까지 포함해서 설계해야 한다.

---

# HTTP/2.0

## HTTP/2.0의 등장배경
HTTP/1.0의 구조적 한계때문에 등장하였다.
- HTTP/1.1의 한계
  - 텍스트 기반 + 요청/응답 순차 처리 구조 → 지연(latency) 큼
  - 하나의 TCP 커넥션에서 사실상 “요청 하나씩 처리” → HOL(Head-of-line) blocking
  - 이를 피하려고 브라우저가 병렬 커넥션 여러 개를 열지만 개수 제한이 있음
  - 요청마다 중복되는 헤더(쿠키, User-Agent 등) 계속 전송 → 낭비
- SPDY → HTTP/2로의 진화
  - 구글 SPDY가 헤더 압축, 하나의 TCP 연결에서 동시 요청 등으로 성능 개선 시도
  - 이 아이디어들을 기반으로 HTTP/2 초안이 작성되고, 2015년 HTTP/2 표준 공개
---

## HTTP/2.0 개요: 무엇이 달라졌나
문법은 거의 유지하였고, 전송 방식만 대폭 변경했다고 이해하면 편하다.
- 텍스트 → 바이너리 프로토콜
  - HTTP/1.1:
    - `GET /index.html HTTP/1.1` 같은 텍스트 줄을 파싱해야 했음
  - HTTP/2:
    - 모든 메시지를 바이너리 프레임(frame) 단위로 쪼개서 보냄
    - 사람이 읽기 어렵지만, 기계가 파싱하기 훨씬 빠르고 안전
- 프레임(Frame) 단위 전송
  - HTTP/2 메시지는 모두 프레임에 담겨 전송
  - 프레임 = 헤더(8바이트) + 페이로드(최대 16383바이트) 구조
  - 다양한 프레임 타입: `DATA, HEADERS, SETTINGS, PUSH_PROMISE, PING` 등
- 스트림(Stream)과 하나의 TCP 커넥션
  - 하나의 TCP 연결 위에서 여러 스트림을 동시에 운반
  - 각 스트림은 고유 ID + 독립된 양방향 시퀀스
  - 프레임에는 “이 프레임이 어느 스트림에 속하는지”를 나타내는 스트림 식별자(31비트) 가 포함

---

## HTTP/1.1과의 핵심 차이점

### 프레임 구조
프레임 헤더 필드:
- 길이(Length, 14비트): 페이로드 길이
- 종류(Type, 8비트): DATA, HEADERS, … 어떤 프레임인지
- 플래그(Flags, 8비트): END_STREAM, END_HEADERS 등 속성
- R(Reserved): 예약 비트(항상 0)
- 스트림 식별자(Stream Identifier, 31비트)

→ 이 구조 덕분에 프레임을 조합하여 메시지를 만들고, 다양한 제어 기능(우선순위, 흐름 제어 등)을 구현 가능.

### 스트림과 멀티 플렉싱
- 멀티플렉싱: 하나의 TCP 커넥션에서 여러 요청/응답이 동시에 오가게 하는 핵심 기능이다.
- 장점
  - HOL blocking 완화 (어느 정도)
  - 커넥션 수를 무리하게 늘릴 필요 줄어듦
  - RTT(왕복 지연) 영향 완화 → 체감 성능 개선
- 우선순위, 흐름 제어(Flow Control)도 지원한다.
  - 각 스트림에 우선순위를 부여해 중요한 리소스를 먼저 보내도록 힌트 제공 가능.
  - 단, 우선순위는 권고 사항이기 때문에 실제 서버 구현에 따라 효과는 다를 수 있다.

### 헤더 압축
HTTP/1.1은 매 요청마다 비슷한 헤더(쿠키, User-Agent 등)를 계속 보내서 비효율적.

HTTP/2는 HPACK이라는 전용 헤더 압축 알고리즘을 도입:
- 정적 테이블: 자주 쓰이는 표준 헤더를 미리 정의해두고 인덱스로 전송
- 동적 테이블: 세션 중에 자주 사용하는 헤더를 테이블에 쌓아두고 재사용
- 요청/응답 양쪽이 압축 컨텍스트(context) 를 공유 → 헤더를 조각 내어 압축/복원

장점:
  - 헤더크기 대폭 감소 → 대역폭 절감, 지연 감소
  - 잘못된 압축 상태 등 문제 발생시 `COMPRESSION_ERROR`로 명확히 실패 처리

---

## 서버 푸시
- HTTP/1.1: 클라이언트가 요청해야만 서버가 응답 가능
- HTTP/2: 서버가 “이 HTML이면 CSS/JS도 필요하겠네?” 하고 먼저 보내줄 수 있음
  - `PUSH_PROMISE` 프레임으로 “이 리소스를 곧 보낼게”라고 선 선언
  - 그 후 해당 리소스를 실제 DATA 프레임으로 푸시
- 장점:
  - RTT를 줄여 초기 로딩 속도 개선 가능(잘 설계했을 경우)
- 단점/주의:
  - 남용 시 불필요한 리소스 전송 → 오히려 느려질 수 있음
  - 현대 브라우저/플랫폼에서는 서버 푸시 활용이 제한적이거나 비권장인 경우도 많음(실무에서는 CDN/플랫폼 가이드 체크 필요)

--- 

## 보안 이슈
책에서 언급하는 대표적인 HTTP/2 관련 보안 이슈들:

1. 중계자 캡슐화 공격 (Intermediary Encapsulation Attack)
   - HTTP/2 메시지가 중간 프록시/게이트웨이에서 HTTP/1.1로 변환될 때
의미가 변질될 수 있는 문제
   - HTTP/2는 헤더를 바이너리로 인코딩하고, 중간 장비는 HTTP/1.1 텍스트 헤더로 번역
   - 이 과정에서 잘못된 해석 →
정상 요청이 위조/변조된 것처럼 보이거나, 반대로 악성 요청이 정상으로 보일 위험

2. 장기 커넥션에 따른 개인정보 노출 가능성
   - 지연 감소를 위해 클라이언트–서버 사이 커넥션을 오래 유지하는 특성이 있음
   - 이 장기 커넥션이 사용자 추적/식별에 악용될 여지가 있음
(이전 방문 기록, 세션 정보 등의 노출 가능성 증가)

→ 성능을 위해 연결을 오래 유지하고, 더 많은 정보를 한 연결에서 주고받는 만큼,
프록시/게이트웨이 설계와 개인정보 보호 관점에서 더 신경 써야 한다는 메시지.

---

## 오늘의 회고
- HTTP/2는 HTTP의 의미(메서드, 상태 코드)를 유지한 채, 전송 방식을 바이너리 프레임/스트림 기반으로 바꿔 성능과 효율을 올린 버전이다.
- 하나의 TCP 커넥션에서 여러 스트림을 멀티플렉싱하여 HOL blocking을 완화한다.
- HPACK 헤더 압축으로 중복 헤더를 크게 줄여 대역폭과 지연을 줄인다.
- 서버 푸시(Server Push) 로 서버가 필요한 리소스를 먼저 보낼 수 있지만, 남용하면 역효과가 날 수 있다.
- HTTP/2는 중계자 캡슐화 공격, 장기 커넥션에 따른 개인정보 노출 같은 새로운 보안 이슈도 가지고 있어 인프라 설계 시 주의가 필요하다.

---

# 쿠키

## 쿠키는 왜 생겼나: 상태 없는 HTTP를 "상태 있게"
HTTP는 원래 완전한 무상태(stateless) 프로토콜이다.
- 각 요청은 다른 요청과 독립
- 서버는 기본적으로 "이 요청이 이전에 왔던 그 사용자와 같은 사용자인지" 알 수 없다.

웹 서비스에서 필요한 것들:
- 로그인 상태 유지
- 장바구니
- 사용자 설정(언어, 테마 등)
- 최근 본 상품, 개인화 추천 등
→ 이 모든 것은 “이전 요청과 지금 요청이 같은 사용자다”라는 연결된 상태가 있어야 함.
→ 이를 HTTP 위에서 구현하기 위한 핵심 메커니즘이 쿠키.

쿠키는 클라이언트(주로 브라우저)에 저장되는 작은 상태 정보 조각이다.
→ 이후 요청마다 자동으로 서버에 같이 보내서 “나 누구인지 기억해줘” 역할을 수행한다.

---

## 쿠키의 기본 개념과 동작 흐름
쿠키는 두 가지 헤더로 동작한다.
1. 서버 → 브라우저: Set-Cookie 헤더
2. 브라우저 → 서버: Cookie 헤더

### 서버가 쿠키를 심는 과정
```http
HTTP/1.1 200 OK
Set-Cookie: sessionId=abc123; Path=/; Domain=example.com
Content-Type: text/html
...
```
- 브라우저는 `Set-Cookie` 헤더를 보고, 해당 도메인/경로/만료 조건에 맞게
로컬의 “쿠키 저장소”에 `sessionId=abc123`를 저장.

### 브라우저가 쿠키를 보내는 과정
이후 사용자가 같은 사이트(해당 도메인/경로에 매칭되는 URL)를 요청하면:
```http
GET /mypage HTTP/1.1
Host: example.com
Cookie: sessionId=abc123
```
- 브라우저는 자동으로 `Cookie`헤더를 붙여서 서버에 전송한다.
- 서버는 `sessionId=abc123`를 보고, 해당 세션에 매핑된 사용자 정보, 장바구니, 로그인 상태 등을 복원

→ 이렇게 해서 원래 무상태인 HTTP 위에, “세션(상태)”을 올릴 수 있게 되는 것.

---

## 쿠키의 구조: 이름 = 값 + 속성들
쿠키는 크게 다음처럼 조합된다.
- 필수: 이름(name)과 값(value)
- 옵션 속성들: 도메인, 경로, 만료(Expires/Max-Age), Secure 등

### 기본 형태
```http
Set-Cookie: name=value
```
여기에 뒤에 `;`로 이어서 각종 속성을 추가한다.

### 주요 속성들
1. Domain
   - 쿠키를 어느 도메인에 대해 보낼지
   - 예: `Domain=.example.com`
     - `www.example.com`, `api.example.com`등 서브 도메인에도 전송
   - 도메인을 넓게 잡을수록 공유 범위가 넓어지고, 그만큼 보안/프라이버시 리스크도 커진다.
2. Path
   - 쿠키가 유효한 URL 경로를 제한
   - 예: `Path=/shop`
     - `/shop`이하 요청에만 이 쿠키 포함
     - `/account` 요청에는 포함되지 않는다.
   - 서비스 내 기능별로 쿠키 범위를 잘게 나눌 수 있다.
3. Expires / Max-Age
   - 세션 쿠키
     - 만료 속성이 없다.
     - 브라우저를 종료하면 사라진다(전통적 정의 기준)
   - 영속 쿠키
     - `Expires`(만료시각) 또는 `Max-Age`(초 단위 수명) 지정
     - 브라우저 종료 후에도, 기간이 남아있으면 계속 살아있다.
4. Secure
   - `secure`플래그가 있으면 HTTPS(암호화된 연결)에서만 쿠키 전송.
   - 평문 HTTP로는 쿠키를 보내지 않으므로, 공격자의 공격을 어느정도 방어할 수 있다. 

---

## 쿠키와 세션 관리

### 세션 ID 기반 패턴
1. 서버가 세션 ID 생성 (예: `sessionId=abc123`)
2. `Set-Cookie: sessionId=abc123; Path=/;` 로 브라우저에 전송
3. 브라우저는 다음 요청부터 `Cookie: sessionId=abc123` 자동 전송
4. 서버는 세션 저장소(메모리, Redis, DB 등)에 `abc123 → 사용자 X, 장바구니 Y`로 매핑

장점
- 브라우저는 민감한 데이터 자체를 저장하지 않고, 단지 키(세션 ID)만 저장한다.
- 서버 쪽에서 세션 스토리지에 접근하여 상세 상태 관리가 가능하다.
- 세션이 필요 없어지면 서버에서 세션을 삭제해도 된다.

### 쿠키에 직접 상태를 담는 방식
- 쿠키 값에 인코딩된 사용 정보(예: `userId=123&theme=dark` 등)를 직접 넣는 방식도 가능하다 그러나,
  - 노출/변조 위험
  - 용량 제한(쿠키는 크기 제한이 큼)
  - 서버에서 서명/암호화를 하지 않으면 신뢰성 하락

---

## 1st-party 쿠키 vs 3rd-party 쿠키 (프라이버시 이슈의 핵심)

쿠키가 주는 기능성은 엄청난데, 동시에 프라이버시 이슈의 근원도 된다.

### 1st-party 쿠키
- 사용자가 방문한 사이트의 같은 도메인에서 설정한 쿠키
  - 예: `example.com`을 방문했을 때, `example.com`이 심은 쿠키
- 로그인, 장바구니, 환경 설정 등 정상적인 기능 구현의 핵심 도구

### 3rd-party 쿠키
- 현재 방문 중인 사이트와 다른 도메인이 심은 쿠키
  - 예: `news-site.com`에서 페이지를 보는데,
  거기에 `<img src="https://ad-network.com/banner.jpg">`가 포함
  - 이 때 `ad-network.com`이 쿠키를 심고,
  사용자가 다른 사이트에서도 같은 광고 네트워크를 통해 광고를 볼 때 동일한 쿠키로 사용자를 추적할 수 있음

이렇게 해서
- 사용자가 어떤 사이트들을 돌아다니는지,
- 어떤 페이지에 관심을 가졌는지

등을 광고 네트워크, 분석 업체 등이 장기간 추적할 수 있게 된다.

---

## 쿠키 관련 보안/프라이버시 고려 사항
쿠키는 본질적으로 “브라우저가 자동으로 붙여서 보내는 정보”라서, 잘못 설계하면 공격자에게 좋은 타깃이 된다.

대표적인 고려사항:

1. 쿠키 값 탈취
   - 평문 HTTP로 전송 시, 네트워크 상에서 훔쳐볼 수 있음
   - 특히 세션 ID가 유출되면 세션 하이재킹(남의 로그인 상태 가로채기) 가능
   - → HTTPS와 `Secure` 플래그 중요
2. 도메인/경로 설정 부주의
   - Domain을 너무 넓게 잡으면, 의도치 않은 서브 도메인에서도 쿠키 접근 가능
   - Path를 잘못 잡으면, 특정 기능에만 쓰여야 할 쿠키가 다른 경로에서도 전송
   - → 최소 권한 원칙: 필요한 범위에만 쿠키를 유효하게
3. 쿠키의 수명 관리
   - 너무 긴 만료 시간 → 사용자 추적 및 세션 남용 위험 증가
   - 민감한 정보가 아닌 설정/편의성 수준은 길게,
  로그인/권한과 연관된 쿠키는 짧게 또는 세션 쿠키로 관리
4. 프라이버시 정책
   - 3rd-party 쿠키를 통한 추적이 사회적 이슈가 되면서,
  브라우저/정책 레벨에서 제약이 계속 늘어나는 추세

---

## 오늘의 회고
- HTTP는 원래 무상태지만, 쿠키를 통해 “이전과 같은 사용자”를 식별하여 상태를 유지한다.
- 쿠키는 `Set-Cookie`로 심고, 이후 해당 도메인/경로에 대한 요청마다 Cookie 헤더로 자동 전송된다.
- 쿠키는 `name=value`에 Domain, Path, Expires/Max-Age, Secure 등의 속성을 붙여 범위·수명·보안을 제어한다.
- 실무에서는 쿠키에 모든 정보를 넣기보다, 세션 ID만 저장하고 서버 측 세션 저장소에서 실제 상태를 관리하는 패턴이 일반적이다.
- 3rd-party 쿠키는 사용자 추적·광고 타겟팅의 핵심 수단이지만, 동시에 대표적인 프라이버시 리스크이기도 하다.
- 쿠키 설계 시, 도메인/경로 최소화 + HTTPS + 적절한 만료 시간을 기본 원칙으로 가져가야 한다.

---

# 보안 HTTP

## 왜 보안 HTTP가 필요한가
기본 HTTP(평문)은 다음 문제를 그대로 노출한다.
- 도청 가능
  - HTTP 응답/요청은 그냥 텍스트이다.
  - 같은 네트워크에 있는 공격자는 패킷 스니핑으로 로그인 정보, 쿠키, 검색어, 개인정보 등을 그대로 볼 수 있다.
- 변조 가능
  - 중간자가 패킷을 가로채 수정할 수 있다.
  - 예: 다운로드 파일에 악성 코드 삽입, 웹 페이지에 스크립트 추가.
- 서버 신원 확인 불가
  - `http://mybank.com`에 접속했다고 해서 정말 은행 서버인지, 중간에서 위장한 서버인지 HTTP 자체만으로 확인이 불가능하다.
  
그래서 등장한것이 HTTPS = HTTP + SSL/TLS 
→ “HTTP 메시지를 암호화된 안전한 터널 안에 태워 보내는 것”이 핵심.

---

## 보안 HTTP가 제공하는 세 가지 큰 기능
HTTPS는 크게 세 가지 보안 특성을 제공한다.
- 기밀성
  - 대칭키 암호로 트래픽을 암호화 → 도청해도 내용을 읽을 수 없음
- 무결성
  - MAC(메시지 인증코드) 또는 AEAD 방식으로 데이터가 전송 중 변조되었는지 검사한다.
- 서버인증
  - 서버가 제시하는 디지털 인증서를 검증해 "내가 진짜 example.com 서버다"임을 증명한다.
  - 옵션으로 클라이언트 인증도 가능하지만, 웹에서는 보통 서버 인증만 사용한다.

---

## 암호학 기초

- 대칭키 암호(Symmetric-key)
  - 같은 키로 암호화/복호화
  - 빠르고 효율적 → 실제 데이터 전송에는 대칭키 사용
  - 문제: 키를 어떻게 안전하게 서로 나누느냐(키 교환 문제)
- 공개키 암호(Public-key)
  - 공개키로 암호화 → 개인키로만 복호화 가능
  - 또는 개인키로 서명 → 공개키로 검증 가능
  - 느리지만, “키 교환”과 “서명/인증”에 적합
- 해시 함수(Hash)
  - 임의 길이 → 고정 길이 요약값
  - 한 비트만 바뀌어도 결과가 크게 달라짐
  - 원래 입력을 해시값으로부터 복원할 수 없음(단방향)
- MAC / 디지털 서명
  - MAC: 공유 비밀키 기반으로 무결성 + 인증
  - 디지털 서명: 공개키 암호 기반으로 메시지의 무결성과 서명자의 신원 확인

→ TLS는 이 조합(대칭 + 공개키 + 해시)를 적절히 섞어서
“키를 안전하게 합의하고, 이후 빠르게 암호화 통신”을 수행.

---

## SSL/TLS와 HTTPS의 관계
- SSL/TLS: 전송 계층 보안 프로토콜
  - TCP 위에서 동작한다.
  - HTTP뿐만 아니라 다른 프로토콜(FTP, SMTP등)에도 사용이 가능하다.
- HTTPS:
  - 브라우저/서버가 TCP → TLS → 그 안에 HTTP를 실어서 전송하는 구조
  - 보통 포트 443 사용 (HTTP는 80)

> HTTP는 그대로 두고 '운반 방식'을 TLS로 바꾸어 암호화/인증을 추가한것이 HTTPS이다.

---

## HTTPS 동작 흐름
브라우저에서 `https://example.com` 입력했을 때의 대략적인 순서:

1. TCP 연결
   - 클라이언트 → 서버: `example.com:443`로 TCP 연결
2. TLS 핸드셰이크(Handshake)
여기에서 주로 하는 일:
   - 사용할 프로토콜/암호 스위트 협상(버전, 암호 알고리즘 등)
   - 서버 인증서 전송 및 검증
   - (필요 시) 클라이언트 인증
   - 세션 키(대칭키) 교환/생성
4. 세션 키 확정 후
   - 이후 HTTP 요청/응답은 이 세션 키로 암호화된 채 TLS 레코드를 통해 전송
   - 애플리케이션 관점에서는 평소와 동일하게 HTTP 메시지를 주고받는 것처럼 보임
5. 세션 종료
   - 연결 종료 시 세션 파괴
   - 재연결 시 세션 재개(resume) 기능을 활용할 수도 있음(핸드셰이크 비용 감소)

핵심: 핸드셰이크에서 인증과 키 합의, 그 뒤로는 대칭키 기반 암호화 통신.

---

## 서버 인증서와 CA(PKI)
보안 HTTP의 신뢰 기반은 디지털 인증서 + CA 체계(PKI)이다.
1. 서버 인증서
   - 이 공개키는 `example.com`의 것이다 라는 서명이 담긴 문서
   - 내용
     - 서버의 공개키
     - 서버 도메인 이름
     - 발급자(CA) 정보
     - 유효 기간
     - 서명 알고리즘 등
2. CA(인증 기관)
   - 공인된 제 3자
   - 서버의 신원을 검증한 후 인증서에 서명
   - 브라우저/OS는 여러 신뢰 가능한 CA의 루트 인증서를 미리 내장.
3. 검증 과정
   - 클라이언트(브라우저)는 서버가 보내준 인증서의
     - 유효기간
     - 도메인 이름 일치 여부
     - 서명 검증(CA의 공개키로 검증)
   - 인증 경로를 따라가며 신뢰가능한 루트 CA까지 이어지는지 확인한다.
4. 자체 서명 인증서
   - 서버가 스스로 발급/서명한 인증서
   - 브라우저 입장에서는 누가 이 서버를 검증했는지 알 수 없다. → 경고 표시
   - 내부망/테스트용으로는 사용 가능하지만, 공용 서비스에는 부적합하다.

"이 서버가 진짜 `example.com` 이 맞다"라는 것을 제 3자(CA)의 서명을 통해 전세계적으로 공유하는 시스템이 PKI이다.

---

## TLS와 HTTP의 경계: 애플리케이션은 그대로
HTTPS를 사용해도
- HTTP 메서드
- 상태 코드
- 헤더 구조
- URI 형식 같은 것들은 변화하지 않는다.

달라지는 것은
- URL 스킴: `http://` → `https://`
- 포트: 80 → 443(일반적)
- 전송 경로: 평문 TCP → TLS 레코드 위에서 암호화된 바이트 스트림

즉, 애플리케이션 레벨 HTTP 프로그래밍 모델은 거의 동일하고, 인프라/전송 레벨에서 TLS가 추가될 뿐이라는 점이 포인트이다.

---

## 성능 이슈와 최적화 포인트
당연하게도 보안 HTTP는 "추가 비용"이 존재한다.
1. 핸드 셰이크 비용
   - 공개키 연산때문에 초기 연결이 HTTP보다 비싸다.
   - RTT도 더 든다.
2. 암호화/복호화 비용
   - 모든 트래픽을 암호화/복호화해야 하므로 CPU 사용량이 증가한다.

전통적인 최적화 방향은 다음과 같다.
- Keep-Alive / Persistent Connection
→ 한 번 TLS 핸드셰이크한 연결을 최대한 재사용
- 세션 재개(Session Resumption)
→ 이전 세션 정보를 이용해 암호 협상을 단축
- 하드웨어 가속(SSL Accelerator, 전용 장비)
→ 대형 서비스에서 TLS 연산을 오프로딩

> TLS는 비용이 존재하지만 충분히 감당 가능한 수준이며 보안적으로의 이득이 훨씬 크기때문에 사용하는것이 당연하다.

---

## 보안 HTTP가 막아주는 공격 vs 못 막는 공격

### 막아 주는 것
- 평문 도청(sniffing)
- 중간 변조(단 올바른 인증서 검증이 전제)
- 세션 ID 탈취 등 네트워크 수준 공격 상당수가 방어 가능하다.

### 못 막는것(또는 부분적)
- 피싱
  - `https://fake-bank.com`이 있어도, 사용자가 진짜 은행 사이트인줄 착각하면 문제가 된다. (중고나라 가짜 사이트 같은거)
  - 도메인을 사용자가 헷갈리면 TLS도 막지 못한다.
- 브라우저/클라이언트 측 악성 코드
  - 사용자의 PC/브라우저가 이미 뚫려있다면, HTTPS로 암호화 하기 전에/후에 데이터가 유출 가능.
- 사용자 실수
  - "인증서 경고 무시하고 계속 진행"
  - 비밀번호 재사용, 의심스러운 첨부파일 실행 등

> HTTPS는 네트워크 구간을 상당히 안전하게 만들어주지만, 전체 보안 체인중 하나의 구성일뿐 사용자/애플리케이션/운영 보안이 함께 설계되어야 한다.

---

## 오늘의 회고
- HTTP는 기본적으로 평문/무상태이기 때문에, 도청·변조·위장 서버 문제에 그대로 노출된다.
- HTTPS는 HTTP를 TLS 위에 올려서 암호화·무결성·서버 인증을 제공한다.
- TLS는 공개키 암호로 키를 합의하고, 이후 대칭키 암호로 빠르게 데이터를 암호화하는 구조다.
- 서버 인증서는 CA가 서명한 문서로, 브라우저는 이를 검증해 “이 서버가 진짜 그 도메인인지”를 확인한다.
- HTTPS를 써도 HTTP의 메서드/상태코드/헤더 구조는 변하지 않고, 전송 레이어만 바뀐다.
- TLS는 비용이 들지만, 핸드셰이크 재사용, 세션 재개, 인프라 튜닝으로 충분히 최적화 가능하며, 현대 웹에서 사실상 기본값이다.

---

# 엔터티와 인코딩

## 메시지 vs 엔터티 : 컨테이너 vs 화물
- 메시지: 택배 상자(컨테이너)
- 엔터티: 상자 안에 든 실제 물건(화물)

정리
- HTTP 메시지
  - 시작줄 + 헤더 + 빈 줄 + (선택적)본문(body)
- 엔터티
  - 엔터티 헤더 + 엔터티 본문을 통틀어 부르는 논리적 개념
  - 실제 컨텐츠(HTML, JSON, 이미지 등)에 대한 메타데이터와 데이터 자체이다.

실무적으로 중요한 포인트
- 프록시/게이트웨이/캐시는 메시지 레벨에서 많이 움직이고,
- 애플리케이션은 엔터티 레벨(컨텐츠 타입, 길이, 인코딩 등)을 신경 쓴다.
  → “HTTP 메시지 설계”와 “콘텐츠 설계”를 분리해서 생각할 수 있게 해주는 개념.

---

## Content-Length: 엔터티의 길이
Content-Length 헤더는 엔터티 본문의 바이트 길이를 나타낸다.

왜 중요한가

1. 연결 재사용(keep-alive)을 위해
   - 수신측은 Content-Length를 보고 "여기까지가 이 응답 본문이구나"를 알고
   - 그 다음 바이트부터는 다음 메시지로 인식한다 → 하나의 TCP 연결에서 여러 요청/응답 처리 가능
2. 버퍼링/진행률 표시
   - 다운로드 진행률 계산, 업로드 제한 등에서 사용한다.
3. 보안적 의미
   - 잘못된 Content-Length 또는 Transfer-Encoding과의 모순은 요청 스머글링 같은 취약점으로 이어질 수 있다.

기본 규칙
- 본문이 있는 메시지는 보통 아래 둘 중 하나를 사용한다.
  - `Content-Length`
  - `Transfer-Encoding: chunked` (길이 모를 때)
- `Transfer-Encoding`이 있다면, `Content-Length`는 무시하도록 정의된다.

---

## 엔터티 요약
엔터티 요약은 "이 본문이 제대로 전달되었는가"를 확인하기 위한 해시/체크섬 개념이다.
- 서버
  - 엔터티 본문에 대해 해시를 계산한다.
  - 요약값을 헤더로 전송한다.
- 클라이언트
  - 받은 본문에 대해 동일 방식으로 해시를 계산한다.
  - 헤더의 값과 비교하여 전송 중 **손상 여부**를 확인한다.

현대 HTTP에서는 RFC3230/9110을 기반으로 한 `Digest`, `Want-Digest`등의 헤더가 더 일반적으로 다루어진다.

실무 포인트
- 대형 파일 다운로드, API 응답 무결성 검증에 적용이 가능하다.
- 다만, HTTPS가 기본이 되면서 "전송 경로에서의 비트 플립 방지"는 대부분 TLS선에서 해결된다. → 엔터티 요약은 **추가적인 무결성 검증 수단** 정도로 보는 흐름이다.

---

## 미디어 타입과 charset
Content-Type 헤더가 엔터티의 타입을 결정한다.
- 형식: `type/subtype`
  - 예: `text/html, application/json, image/png`
- 선택적 파라미터:
  - `charset=UTF-8` 등 문자 인코딩 정보
  - 예: `Content-Type: text/html; charset=UTF-8`

역할
- 브라우저/클라이언트가 어떻게 해석/렌더링할지 결정한다.
- 국제화와 연결된다.

실무 포인트
- 텍스트 계열 응답은 항상 `charset`까지 명확히 지정해야한다.
- 파일다운로드 시에도 MIME 타입을 정확히 지정하면, 브라우저/OS에서 기본 프로그램과 연동이 잘된다.

---

## 콘텐츠 인코딩: 콘텐츠 자체를 변형
Content-Encoding은 엔터티 본문을 압축/변형한 "코딩 방식"을 나타낸다.

- 원본 콘텐츠를 gzip/deflate 등으로 압축하는 경우
- 인코딩 전후로 콘텐츠 타입은 동일하다.
  - 인코딩 전후 모두 `text/html`, 단 크기만 달라진다.
- 수신 측은 `Content-Encoding`을 보고 디코딩 한 후 `Content-Type` 기준으로 처리한다.

흐름
1. 서버에서 원본 응답(HTML/JSON 등) 생성
2. 클라이언트의 `Accept-Encoding`을 보고, 서버가 gzip 등으로 압축
3. `Content-Encoding: gzip`을 붙여 전송
4. 클라이언트는 이를 해제(decode)한 후 렌더링/파싱

실무 포인트
- 텍스트 기반 리소스(HTML/CSS/js/JSON)는 gzip/br 압축 기본 활성화 하는것이 일반적이다.
- 이미지/동영상등 이미 압축된 포맷은 재 압축 이득이 거의 없기 때문에 선택적으로 적용하도록 하자.

---

## 전송 인코딩과 청크 인코딩
Transfer-Encoding은 “네트워크를 통해 메시지 바디를 어떻게 나눠 보낼지”에 대한 인코딩이다. 콘텐츠 포맷과는 독립적인, 전송용 인코딩이다.

대표적인것이 chunked인코딩이다.
- `Transfer-Encoding: chunked`
- 본문이 아래 형식으로 전송된다.
  - 각 청크의 길이를 16진수로 표시하는 줄
  - 해당 길이만큼의 데이터
  - 마지막에 길이 0인 청크 + optional trailer 헤더들
- 장점
  - 응답 길이를 미리 몰라도, 스트리밍으로 바로 보내기가 가능해진다.
  - 동적 페이지, 대용량 스트리밍에서 유용하다.

HTTP/1.1 관점
- `Transfer-Encoding: chunked`가 있으면, `Content-Length`는 사용하지 않거나 무시해야 함
- 클라이언트/프록시는 chunk를 하나씩 읽으면서 전체 엔터티를 조립

Content-Encoding는 콘텐츠 자체 Transfer-Encoding은 전송 방식. 역할이 다르다는것을 명심하자.

---

## 시간에 따라 바뀌는 인스턴스, 검사기와 신선도
한 리소스(URL)은 시간에 따라 여러 버전(인스턴스)를 가질 수 있다.
- 오늘 `/index.html`과 내일의 `/index.html`은 같은 리소스지만 내용(엔터티)는 다른 내용일 수 있다.

이를 다루기 위한 핵심 도구가 바로 **검사기**이다.
- `Etag`: 인스턴스 버전을 구분하는 식별자(보통 해시)
- `Last-Modified`: 마지막 수정 시각

그리고 신선도
- `Cache-Control: max-age=..., Expires` 등으로
캐시가 “언제까지 이 인스턴스가 최신이라고 믿을 수 있는지”를 지정한다.

---

## 범위 요청과 부분 콘텐츠
범위 요청(byte serving)은 큰 리소스의 일부만 전송하는 기능이다.
1. 서버가 지원 의사를 표기:
   - `Accept-Ranges: bytes`
2. 클라이언트가 특정 범위를 요청:
   - `Range: bytes=0-999` → 처음 1000바이트
   - `Range: bytes=500-` → 500바이트부터 끝까지
3. 서버 응답:
   - 상태 코드: `206 Partial Content`
   - `Content-Range` 헤더로 실제 범위 명시

사용 사례
- 동영상/오디오 스트리밍에서 특정 지점으로 이동
- 대용량 다운로드 중단 후 재개
- 대체 프록시/캐시가 부분만 가지고 있을 때 효율적 재요청

실무 포인트
- 정적 파일 서버(Nginx, S3 등)는 보통 자동 지원한다.
- 애플리케이션 서버에서 직접 파일 스트리밍 할 때는 Range 헤더 처리를 구현하면 UX가 크게 좋아진다.

---

## 델타 인코딩
델타 인코딩은 "캐시된 이전 버젅과 현재 버전 사이의 차이"만 전송하자는 아이디어이다.

컨셉
- 클라이언트는 이미 이전 인스턴스를 캐싱 중
- 서버는 전체 새 엔터티 대신 "이전 버전에서 무엇이 바뀌었는지"만 전송한다.
- 클라이언트는 캐시 + 델타를 합쳐서 최신 버전을 재구성 한다.

장점
- 자주 조금씩만 바뀌는 리소스(뉴스, 문서, API 응답)에 대해 전송량을 줄일 수 있다.

하지만
- 구현이 복잡하고, 클라이언트와 서버 모두 지원해야 한다.
- 브라우저/일반 웹 환경에서는 실제 사용이 드문편이다.

현대 일반 웹 서비스에서는 캐싱 + 압축으로 충분한 경우가 많고, 델타 인코딩은 특수한 시스템(버전 관리, 전용 클라이언트 등)에 더 적합한 경우가 많다.

---

## 오늘의 회고
- HTTP 메시지는 상자, 엔터티는 그 안의 실제 콘텐츠와 메타데이터다.
- Content-Length 는 엔터티 크기를 알려줘서 연결 재사용, 파싱, 보안에서 매우 중요하다.
- 엔터티 요약(digest)은 해시/체크섬으로 무결성 검증을 돕는다.
- Content-Type + charset 은 “이걸 무슨 형식/문자셋으로 해석할지”를 결정한다.
- Content-Encoding 은 콘텐츠 자체를 압축/변형하고, Transfer-Encoding 은 전송 방식(chunked 등) 을 정의한다.
- 리소스는 시간에 따라 여러 인스턴스를 가지며, ETag, Last-Modified, Cache-Control로 인스턴스 버전과 신선도를 관리한다.
- Range 요청과 206 Partial Content 로 대용량 리소스의 일부만 효율적으로 전송할 수 있다.
- 델타 인코딩은 “변경분만 전송”하는 강력한 개념이지만, 일반 웹 브라우저 환경에서는 아직 널리 쓰이지는 않는다.

---

# 국제화

## 언어 태그와 HTTP

### 언어 태그란?
- 사람의 언어를 식별하기 위한 표준 코드 문자열이다.
- IETF BCP 47 표준을 따른다.
  - 기본 언어코드: `en`, `fr`, `ko`등
  - 지역/변종: `en-US`, `en-GB`, `pt-BR`등 하이픈으로 이어붙인다.

실무 포인트
- 언어 태그는 문자열을 "언어+지역/스크립트" 조합으로 지정하는 표기 규칙이다.

### HTTP에서 언어 태그가 쓰이는곳
대표적으로 두 HTTP 헤더에서 사용된다.

1. Content-Language(서버 → 클라이언트)
   - 이 응답 엔터티가 어떤 언어로 쓰였는지를 알려준다.
   - 예
    ```http
    Content-Language: ko
    Content-Language: en-US
    Content-Language: en, fr
    ```
  - 하나의 문서에 여러 언어가 섞여있을 수 있으므로, 복수 언어 태그도 허용한다.

2. Accept-Language(클라이언트 → 서버)
   - 나는 이런 언어를 이런 우선순위로 선호한다를 브라우저가 서버에 알린다.
   - 예
   ```http 
   Accept-Language: ko-KR, ko;q=0.9, en-US;q=0.8, en;q=0.7
   ```
   - `q`(품질 값, 0 ~ 1): 선호도. 값이 클수록 선호도가 높다.
   - 서버는 이 헤더를 보고, 가지고 있는 여러 번역본 중에서 가장 적합한 언어 리소스를 선택한다.

### 언어 태그 + 캐시/콘텐츠 네고시에이션
- 언어가 바뀌면 사실상 다른 리소스로 취급해야한다.
- 캐시 키에 언어 관련 헤더(`Accept-Language`, `Content-Language`)가 영향을 줄 수 있음.
- Vary 헤더와 함께 사용한다. → “이 리소스는 언어에 따라 응답이 달라진다”는 뜻
(캐시가 헤더 조합별로 별도의 엔트리를 유지해야 함)

실무 포인트
- 다국어 페이지를 설계할 떄
  - URL Path, 도메인, 쿠키 등과 Accept-Language 기반 자동 선택을 적절히 조합해야한다.
  - 캐시/CDN을 쓸 경우 `Vary: Accept-Language` 설정 여부를 신중하게 결정해야 한다.

---

## 국제화된 URI

### 기본 문제의식: URI는 원래 ASCII만
- 원래 URI 스펙은 7비트 US-ASCII만 허용한다.
  - 한글, 일본어, 특수문자, 공백 등은 직접 사용 불가.
  - 대신 퍼센트 인코딩으로 이진 데이터를 표현한다.(16진수 2자리로 표현)
- 국제화가 필요해지면서 비 ASCII 문자들을 어떻게 URI에 표현할것인가가 문제점.

### HTTP에서 실제로 쓰이는 방식
1. 브라우저 내부에서 문자열(예: 한글경로)을 어떤 문자 인코딩으로 바이트 변환.
2. 그 바이트들을 URI 허용 문자 외의 바이트는 `%XX` 퍼센트 인코딩으로 바꿈.
3. 서버는 이 퍼센트 인코딩을 원래 바이트로 되돌린 후, 같은 문자 인코딩 규약을 적용하여 문자열로 복원.

문제는,
- 브라우저가 어떤 인코딩으로 URI를 인코딩했는지와 서버가 어떤 인코딩으로 URI를 해석하는지가 서로 맞지 않으면 깨짐/오해석이 발생.
- 역사적으로는 각국 인코딩이 혼재해서 서버 측에서 처리 로직이 복잡해졌다.

현대 실무에서는
- UTF-8을 사실상 표준으로 사용하는 추세이다.
- 웹 서버/프레임워크도 대부분 URI 디코딩에 UTF-8을 기본값으로 가정한다.

### 국제화 도메인 이름(IDN) 관련
- 도메인 이름은 여전히 DNS 차원에서는 ASCII만 허용된다.
- 그래서 `한국어도메인.com`같은것을 표현하려면 PunyCode를 이용한 IDN으로 변환한다.
- 브라우저는 주소창에 사용자가 입력한 유니코드 도메인을 내부적으로 IDN 포맷으로 변환한 뒤 DNS를 조회한다.

국제화 URI = “문자열 → 어떤 문자 인코딩(보통 UTF-8) → 바이트 → 퍼센트 인코딩 → HTTP로 전송” 흐름 전체를, 브라우저와 서버 양쪽에서 동일한 규칙으로 처리해야 한다.

---

## 기타 고려사항

### 언어 vs 로케일 vs 스크립트
- 언어: 한국어/영어 같은 언어 종류
- 로케일: 언어 + 지역 + 문화권(날짜, 통화, 숫자 포맷 등)
- 스크립트: 한글, 라틴, 한자, 키릴 문자 등 글자 체계

HTTP의 언어 태그는 주로 언어까지만 표현한다. 그러나 실제 앱 로직에서는 같은 언어라도 지역별 로케일 차이가 중요하다. 그렇기 때문에 HTTP 언어 태그만으로는 완전한 로케일 처리가 안되며, 서버 애플리케이션 내에서 추가적인 로케일/문화권 정보가 필요하다.

### 정렬, 검색, 비교
- 문자열 비교/정렬은 단순한 바이트 비교가 아닌 언어별 규칙에 의존한다.
- 예를 들어, 독일어, 프랑스어, 한글 등은 각자 고유의 정렬 규칙이 존재한다.
- HTTP 수준에서는 구체 정렬 규칙을 정의하지 않지만. 국제화된 검색/정렬 API 설계시에는 
- 언어 태그 + 로케일 정보를 함께 고려해야한다.

### 글꼴, 표기 방향(Bidi), UI 렌더링
- HTTP는 그저 텍스트 스트림을 전달할 뿐이다.
- 실제 렌더링/UI는 브라우저/클라이언트의 책임.
- 국제화 애플리케이션에서는
  - RTL, 언어에 대한 Bidi 처리
  - 다양한 글꼴/폰트 지원
  - 줄바꿈 규칙, 조합 문자 등의 문제가 모두 실제 UX에 영향을 미친다.

따라서 HTTP만 국제화를 지원한다고 끝날게 아니라, 클라이언트, UI, 백엔드 로직 전체가 국제화 관점에서 설계되어야 한다.

### 캐시·프록시·네고시에이션과의 상호작용
- 국제화된 리소스(언어/문자셋별 변형)를 제공하는 경우
  - 캐시/프록시가 `Accept-Language`, `Accept-Charset`등을 보고 서로 다른 변형을 인식해야한다.
  - `Vary` 헤더로 어떤 헤더에 따라 응답이 달라지는지 명시하는것이 중요하다.
- 네고시에이션과 결합되면
  - 언어/문자셋/인코딩 등 다양한 기준으로 "가장 적절한 표현"을 고르는 로직이 필요하다.

---

## 오늘의 회고
- BCP 47 언어 태그(ko-KR, en-US 등)로 문서 언어와 사용자 선호 언어를 표현한다.
- Content-Language는 문서의 실제 언어, Accept-Language는 사용자의 언어 선호도이며,
둘 사이에서 언어 기반 콘텐츠 네고시에이션이 이루어진다.
- 언어에 따라 응답이 달라질 경우 Vary: Accept-Language 등으로 캐시를 조정해야 한다.
- URI는 기본적으로 ASCII만 허용하므로, 비 ASCII 문자는 문자 인코딩 → 바이트 → 퍼센트 인코딩 흐름으로 표현한다.
- 브라우저와 서버가 같은 문자 인코딩(현대에는 사실상 UTF-8) 을 가정해야 깨지지 않는다.
- 도메인 이름의 국제화는 IDN/Punycode를 통해 “겉은 유니코드, 내부는 ASCII”로 처리된다.
- 언어 태그만으로는 부족하고, 실제 앱 설계에서는 로케일/스크립트/문화권까지 함께 고려해야 한다.
- 문자열 정렬/검색/비교, Bidi, 글꼴 등은 HTTP 밖에서 처리되지만, 국제화 웹 서비스 품질에 직접적인 영향을 준다.
- 국제화된 리소스를 제공할 때는 캐시·프록시·네고시에이션과의 상호작용까지 설계해야 한다.

---

# 내용 협상과 트랜스코딩

## 내용 협상이란? 한 URL, 여러 "표현" 중에서 고르기
내용 협상은 같은 URL에 대해 여러 버전(표현, variant)이 있을 때, 그 중에서 클라이언트에게 가장 적합한 것을 고르는 메커니즘이다.

예를들어,
- `/docs/guide`라는 하나의 URL인데
  - `uide.ko.html, guide.en.html` (언어)
  - `guide.html, guide.pdf` (포맷)
  - `guide.html (압축 X), guide.html.gz (gzip 압축)` 등

이런 서로 다른 버전중에서, 클라이언트의 선호에 따라 가장 알맞은 하나를 선택하는 것이다.

---

## 내용 협상 기법: 세가지 방식
서버가 어떤 variant를 줄지 판단하는 방식은 크게 세가지 이다.
1. 클라이언트 주도 협상
   - 서버가 선택지를 보내고
   - 클라이언트(또는 사용자)가 그 중 하나를 고르는 방식이다.
2. 서버 주도 협상
   - 클라이언트가 HTTP 헤더(`Accept-*`, `Accept-Languae`등)에 내가 선호/수용 가능한 표현을 알려주고 서버가 이 정보를 보고 자동으로 최종표현을 선택하는 방식이다.
3. 투명 협상
   - 중간 프락시/캐시 같은 투명한 중개자가 서버를 대신해 협상/선택을 수행하는 방식이다.

---

## 클라이언트 주도 협상

### 동작 흐름
전형적인 플로우는 다음과 같다.
1. 클라이언트가 URL에 일반 요청을 보낸다.
2. 서버는 이 URL은 선택 가능한 여러 버전이 있다고 판단한다.
3. 서버는
   - HTTP 300(Multiple Choices)응답, 혹은 언어 선택/포맷 선택 같은 선택 페이지 HTML을 반환한다.
4. 클라이언트(사용자)는 목록 중 원하는 버전을 클릭/선택한다.
5. 선택된 variant의 구체적인 URL로 다시 요청을 보낸다.
6. 서버는 해당 버전을 그대로 반환한다.

선택 로직은 사용자/클라이언트에게 있고, 서버는 단지 옵션 리스트를 제공하는 구조이다.

### 장점
- 구현이 단순하다.
  - 서버는 어떤 버전이 있는지 목록만 주면 되기 때문.
  - 복잡한 헤더 파싱, 우선순위(q-vaule)계산 등이 필요없다.
- 사용자 선택이 명시적이다
  - 사용자가 직접 한국어/영어를 누르기 때문에
  - 잘못된 언어로 자동 선택될 일이 적다.
  - UX측면에서도 용이하다.
- 캐싱 관점에서도 단순하다.
  - 실제 리소스마다 URL이 분리되기 때문에 CDN/브라우저 캐시 입장에서 구분이 쉽다.

### 단점
- 왕복(RTT)이 최소 2번 이상
  - 최초 요청 → 선택 페이지
  - 선택 → 실제 리소스
  - (사용자가 언어를 바꾸거나 하면 더 많아질 수 있음)
- 자동화/머신 클라이언트에 불편하다.
  - 사람 눈으로 보고 클릭해야 하는 UI 중심 구조이기 때문에
  - API 클라이언트나 봇에게는 비효율적이다.
- 선호도/환경 정보 활용이 약하다.
  - 브라우저 설정을 기껏 해놔도 이것을 반영하지 못하고 매번 페이지에서 사람에게 물어보는 형식이 될 수 있다.

---

## 서버 주도 협상
클라이언트가 헤더로 선호 사항을 보내고, 서버가 그 정보로 알아서 골라주는 방식이다.

### 기본 아이디어
1. 클라이언트는 요청 헤더에 다음과 같은 것들을 넣어 보낸다.
   - `Accept` : 선호하는 미디어 타입 (HTML, JSON, 이미지 포맷 등)
   - `Accept-Language` : 선호 언어/지역 (ko-KR, en-US 등)
   - `Accept-Charset` : 선호 문자 집합 (UTF-8 등)
   - `Accept-Encoding` : 수용 가능한 콘텐츠 인코딩(gzip, br 등)
2. 서버는 현재 URL에 대한 모든 variant 목록을 가지고 있다.
3. 서버는 각 variant의 특성(언어, 타입, 인코딩 등)을 클라이언트 헤더와 비교하여 가중치 합산같은 정책으로 가장 적합한 것을 선택한다.
4. 선택한 variant를 그대로 응답한다.

---

## 내용 협상 헤더
서버 주도 협상을 위해 사용되는 대표적인 헤더들이다.
1. Accept
   - 이런 미디어 타입이 좋다는 선호를 표현
   - `Accept: text/html, application/json;q=0.9, */*;q=0.1`
   - 서버는 자신이 보낼 수 있는 타입 중에서 가장 잘 맞는것을 선택한다.
2. Accept-Language
   - 선호 언어/지역 정보
   - `Accept-Language: ko-KR, ko;q=0.9, en-US;q=0.8, en;q=0.7`
   - 서버는 제공 가능한 번역본 중 가장 높은 우선순위에 해당하는 것을 고른다.
3. Accept-Charset
   - 선호 문자 집합
   - `Accept-Charset: utf-8, iso-8859-1;q=0.5`
   - 현대 웹에서는 거의 모든 것이 utf-8이기 때문에 영향이 적다.
4. Accept-Encoding
   - 수용 가능한 콘텐츠 인코딩(압축 방식 등)
   - `Accept-Encoding: br, gzip;q=0.8, *;q=0.1`
   - 서버는 가능한 경우, 가장 선호되는 인코딩으로 압축 후 응답한다.

이 헤더들의 조합을 기반으로 서버는 어떤 variant를 줄지 결정한다.

---

## 품질값(q-value): 선호도 스코어

헤더 값 뒤에 붙는 `q=...` 가 바로 품질값(quality value, q-value) 이다.

### 의미
- 범위: 0.0 ~ 1.0
- 클수록 더 선호한다는 의미이다.
- 생략하면 기본값 1.0(최고 우선순위)
- 0은 이건 받지 않겠다에 가깝다.

`Accept-Language: ko-KR, ko;q=0.9, en-US;q=0.8, en;q=0.7`

서버는 
- 먼저 클라이언트가 요구한 언어/타입/인코딩 리스트를 q-value 순서대로 정렬하고
- 각 항목에 대해 지원 가능한 variant가 있는지 확인한 뒤
- 가장 높은 q-value가 매칭되는 표현을 선택한다.

### 왜 필요한가?
단순히 이 언어를 지원/미지원 하느냐가 아니라 한국어가 제일 좋고 그게 아니면 영어라도 그것도 안되면 뭐 다른것도 괜찮다. 라는 식의 **단계적 선호도**를 표현하기 위함이다.

---

## 그 외의 헤더들 및 정보
내용 협상 외에도 실제로 서버가 결정에 참고할 수 있는 다른 정보들도 존재한다.

- User-Agent
  - 브라우저/디바이스 종류에 따라
  - 데스크톱/모바일 전용 페이지, 특정 브라우저용 최적화 버전 등을 나눌 수 있음.
- 헤더 외 환경 정보
  - 클라이언트 IP 기반 지역 추정 (GeoIP)
  - 쿠키(사용자가 예전에 선택해 둔 언어/테마)
  - URL 패턴(/ko/, /en/ 등)

이들은 HTTP 스펙상 “정식 content negotiation 헤더”는 아니지만,
실무에서 서버 주도 협상 로직을 보완하는 신호로 자주 활용된다.

다만,
- User-Agent 기반 분기는 유지보수가 어렵고, UA 문자열이 자주 바뀌므로
캐시/프록시와의 궁합이 나빠질 수 있음.
- 언어/포맷/인코딩의 “표준 협상”은 되도록 Accept 계열 헤더 + q-value를 우선 사용하고, 나머지는 보조적인 힌트로 쓰는 것이 권장되는 방향.

---

